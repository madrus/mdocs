{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to My Personal Docs\n\n\nAbout this documentation\n\n\nCollecting tips and tricks is huge fun. I am doing it \nalong the way\n every time I get stuck and later find the solution. Every bit of information here has at some point proved to be useful to me. So, the documentation is never complete and finished. It is always \nwork in progress\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-my-personal-docs", 
            "text": "", 
            "title": "Welcome to My Personal Docs"
        }, 
        {
            "location": "/#about-this-documentation", 
            "text": "Collecting tips and tricks is huge fun. I am doing it  along the way  every time I get stuck and later find the solution. Every bit of information here has at some point proved to be useful to me. So, the documentation is never complete and finished. It is always  work in progress .", 
            "title": "About this documentation"
        }, 
        {
            "location": "/engine/technicalities/", 
            "text": "Installing prerequisites\n\n\nif you want to create your own project like this one, you need to have the latest version of \nPython 2.7\n installed, which can be downloaded from \nhere\n.\n\n\nAfter that, install \nmkdocs\n and related packages:\n\n\n1\n2\n3\npip install -U mkdocs mkdocs-material\npip install -U fontawesome-markdown\npip install -U pygments pymdown-extensions\n\n\n\n\n\n\n\n\nProject Layout\n\n\n1\n2\n3\n4\n5\nmkdocs.yml\n    \n# The configuration file.\n\n\ndocs/\n\n    \nindex.md\n  \n# The documentation homepage.\n\n    \n...\n       \n# Other markdown pages, and other files.\n\n    \n/images\n   \n# Images used in the documents\n\n\n\n\n\n\n\n\n\nRunning the project in DEV\n\n\nOpen the command prompt in the project root directory and type:\n\n\n1\nmkdocs serve\n\n\n\n\n\n\nOr, if you need to run it on a specific port, e.g. 8080, you can do one of the following:\n\n\n1\n2\nmkdocs serve --dev-addr:8080\nmkdocs serve -a :8080\n\n\n\n\n\n\nThen open your browser and navigate to \nhttp://localhost:8000\n or whatever port number you have configured.\n\n\nSome Useful Commands\n\n\n\n\nmkdocs new [dir-name]\n - Create a new project.\n\n\nmkdocs serve\n - Start the live-reloading docs server.\n\n\nmkdocs build\n - Build the documentation site.\n\n\nmkdocs help\n - Print this help message.\n\n\n\n\n\n\nFont Awesome\n\n\nFont Awesome\n gives you scalable vector icons that can instantly be customized \n size, color, drop shadow, and anything that can be done with the power of CSS. For more inpiration see these \nexamples\n.\n\n\nFont Awesome Markdown\n is a Markdown extension that looks for things like \n:fa-coffee:\n (\n) or \n:fa-refresh:\n (\n) and replaces them with the Font Awesome icon markup.\n\n\nExamples\n\n\nThis examples use the fontawesome_markdown extension:\n\n\n1\nWhat would you drink, :fa-coffee: or :fa-beer:?\n\n\n\n\n\n\nWhat would you drink, \n or \n?\n\n\nFor this example, you must install the \nfontawesome_markdown\n extension with \npip\n. Right now version \n0.2.5\n is the latest but it doesn\nt work out of the box. Instead, you have to install the latest version from the github repository. You can do that with the command below:\n\n\n1\npip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip\n\n\n\n\n\n\nYou may need to include \n-U\n in the above command if you already have this extension installed.\n\n\nThen add the below to your \nmkdocs.yml\n file.\n\n\n1\n2\nmarkdown_extensions\n:\n\n  \n-\n \nfontawesome_markdown\n\n\n\n\n\n\n\n\n\nDeployment\n\n\nDeployment to GitHub Pages directly\n\n\nTo publish the project to \nGitHub Pages\n as a subdomain, e.g. \n/mdocs\n of the main \nyour-github-login.github.io\n website, you need first to create a repository with that name, e.g. \nmdocs\n and add it to your project as a remote.\n\n\nNext make sure you have a \ngh-pages\n branch that exists. If it doesn\nt:\n\n\n1\n2\n3\ngit checkout -b gh-pages\ngit rm -rf .\ngit push --set-upstream origin gh-pages\n\n\n\n\n\n\nNow, open the command prompt in the root directory (on the \nmaster\n branch) and type:\n\n\n1\nmkdocs gh-deploy\n\n\n\n\n\n\nThis will push the \nmaster\n  branch to the remote \ngh-pages\n. After that, the project website is available at \nyour-github-login.github.io/mdocs\n.\n\n\nDeployment to GitHub pages via Travis CI\n\n\nGo to your GitHub account and create a new \nPersonal access token\n in your Developer settings. Copy the hash string.\n\n\n\n\nKeep well the hash string!\n\n\nYou will see it only once when you create it.\n\n\n\n\nIn the Travis CI settings of your project add a new \nGITHUB_TOKEN\n environment variable with the value of the hash string your have just copied. Don\nt forget to turn in \nON\n and to \nADD\n.\n\n\nConfigure the \n.travis.yml\n file. You may start with something like this:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\nsudo\n:\n \nfalse\n\n\nlanguage\n:\n \npython\n\n\npython\n:\n \n2.7\n\n\ninstall\n:\n\n\n-\n \npip install --upgrade pip\n\n\n-\n \npip install -r requirements.txt\n\n\n-\n \npip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip\n\n\nscript\n:\n\n\n-\n \ngit config credential.helper \nstore --file=.git/credentials\n\n\n-\n \necho \nhttps://${GITHUB_TOKEN}:@github.com\n \n .git/credentials\n\n\n-\n \nmkdocs build\n\n\n-\n \nif [ $TRAVIS_TEST_RESULT == 0 ]; then\n\n    \nmkdocs gh-deploy --force;\n\n  \nfi\n\n\n\n\n\n\n\nThe credentials here are necessary for the Travis agent to be able to connect to your Github repository and perform the necessary actions with it. Note that the credentials are based on the \nPersonal access token\n you have created.\n\n\nAlso, I have put deployment inside the \nscript\n fase instead of \nafter_success\n as a workaround (see the tip of Chronial on this \nTravis issue #758\n). Otherwise, the batch succeeds with a successful build even if deploy \nfails\n after it.\n\n\nNext, you need to have \ntravis\n Rubygem installed on your local machine. If not, install it:\n\n\n1\ngem install travis\n\n\n\n\n\n\nUsing \ntravis\n, add the encrypted token to \n.travis.yml\n:\n\n\n1\ntravis encrypt \nGITHUB_TOKEN\n=\nthe-token-from-github\n --add\n\n\n\n\n\n\nThis will add the following block at the end of the file:\n\n\n1\n2\n3\nenv\n:\n\n  \nglobal\n:\n\n  \n-\n \nsecure\n:\n \nlots-of-seemingly-random-characters\n\n\n\n\n\n\n\nNow, when you push your changes to the remote \nmaster\n, Travis CI should publish the compiled website to \nGitHub Pages\n if the build succeeds.", 
            "title": "Getting started"
        }, 
        {
            "location": "/engine/technicalities/#installing-prerequisites", 
            "text": "if you want to create your own project like this one, you need to have the latest version of  Python 2.7  installed, which can be downloaded from  here .  After that, install  mkdocs  and related packages:  1\n2\n3 pip install -U mkdocs mkdocs-material\npip install -U fontawesome-markdown\npip install -U pygments pymdown-extensions", 
            "title": "Installing prerequisites"
        }, 
        {
            "location": "/engine/technicalities/#project-layout", 
            "text": "1\n2\n3\n4\n5 mkdocs.yml      # The configuration file.  docs/ \n     index.md    # The documentation homepage. \n     ...         # Other markdown pages, and other files. \n     /images     # Images used in the documents", 
            "title": "Project Layout"
        }, 
        {
            "location": "/engine/technicalities/#running-the-project-in-dev", 
            "text": "Open the command prompt in the project root directory and type:  1 mkdocs serve   Or, if you need to run it on a specific port, e.g. 8080, you can do one of the following:  1\n2 mkdocs serve --dev-addr:8080\nmkdocs serve -a :8080   Then open your browser and navigate to  http://localhost:8000  or whatever port number you have configured.", 
            "title": "Running the project in DEV"
        }, 
        {
            "location": "/engine/technicalities/#some-useful-commands", 
            "text": "mkdocs new [dir-name]  - Create a new project.  mkdocs serve  - Start the live-reloading docs server.  mkdocs build  - Build the documentation site.  mkdocs help  - Print this help message.", 
            "title": "Some Useful Commands"
        }, 
        {
            "location": "/engine/technicalities/#font-awesome", 
            "text": "Font Awesome  gives you scalable vector icons that can instantly be customized   size, color, drop shadow, and anything that can be done with the power of CSS. For more inpiration see these  examples .  Font Awesome Markdown  is a Markdown extension that looks for things like  :fa-coffee:  ( ) or  :fa-refresh:  ( ) and replaces them with the Font Awesome icon markup.", 
            "title": "Font Awesome"
        }, 
        {
            "location": "/engine/technicalities/#examples", 
            "text": "This examples use the fontawesome_markdown extension:  1 What would you drink, :fa-coffee: or :fa-beer:?   What would you drink,   or  ?  For this example, you must install the  fontawesome_markdown  extension with  pip . Right now version  0.2.5  is the latest but it doesn t work out of the box. Instead, you have to install the latest version from the github repository. You can do that with the command below:  1 pip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip   You may need to include  -U  in the above command if you already have this extension installed.  Then add the below to your  mkdocs.yml  file.  1\n2 markdown_extensions : \n   -   fontawesome_markdown", 
            "title": "Examples"
        }, 
        {
            "location": "/engine/technicalities/#deployment", 
            "text": "", 
            "title": "Deployment"
        }, 
        {
            "location": "/engine/technicalities/#deployment-to-github-pages-directly", 
            "text": "To publish the project to  GitHub Pages  as a subdomain, e.g.  /mdocs  of the main  your-github-login.github.io  website, you need first to create a repository with that name, e.g.  mdocs  and add it to your project as a remote.  Next make sure you have a  gh-pages  branch that exists. If it doesn t:  1\n2\n3 git checkout -b gh-pages\ngit rm -rf .\ngit push --set-upstream origin gh-pages   Now, open the command prompt in the root directory (on the  master  branch) and type:  1 mkdocs gh-deploy   This will push the  master   branch to the remote  gh-pages . After that, the project website is available at  your-github-login.github.io/mdocs .", 
            "title": "Deployment to GitHub Pages directly"
        }, 
        {
            "location": "/engine/technicalities/#deployment-to-github-pages-via-travis-ci", 
            "text": "Go to your GitHub account and create a new  Personal access token  in your Developer settings. Copy the hash string.   Keep well the hash string!  You will see it only once when you create it.   In the Travis CI settings of your project add a new  GITHUB_TOKEN  environment variable with the value of the hash string your have just copied. Don t forget to turn in  ON  and to  ADD .  Configure the  .travis.yml  file. You may start with something like this:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14 sudo :   false  language :   python  python :   2.7  install :  -   pip install --upgrade pip  -   pip install -r requirements.txt  -   pip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip  script :  -   git config credential.helper  store --file=.git/credentials  -   echo  https://${GITHUB_TOKEN}:@github.com    .git/credentials  -   mkdocs build  -   if [ $TRAVIS_TEST_RESULT == 0 ]; then \n     mkdocs gh-deploy --force; \n   fi    The credentials here are necessary for the Travis agent to be able to connect to your Github repository and perform the necessary actions with it. Note that the credentials are based on the  Personal access token  you have created.  Also, I have put deployment inside the  script  fase instead of  after_success  as a workaround (see the tip of Chronial on this  Travis issue #758 ). Otherwise, the batch succeeds with a successful build even if deploy  fails  after it.  Next, you need to have  travis  Rubygem installed on your local machine. If not, install it:  1 gem install travis   Using  travis , add the encrypted token to  .travis.yml :  1 travis encrypt  GITHUB_TOKEN = the-token-from-github  --add   This will add the following block at the end of the file:  1\n2\n3 env : \n   global : \n   -   secure :   lots-of-seemingly-random-characters    Now, when you push your changes to the remote  master , Travis CI should publish the compiled website to  GitHub Pages  if the build succeeds.", 
            "title": "Deployment to GitHub pages via Travis CI"
        }, 
        {
            "location": "/engine/styling/", 
            "text": "Theme Customization\n\n\nA lot can be found on the \nmain website\n\n itself.\n\n\nThe color table to choose the main and accent colors can be found on the \nGetting Started\n page.\n\n\nThemes\n\n\n\n\nMkDocs Themes\n\n\n12 \nBootswatch\n themes\n\n\nCinder\n theme\n\n\nAlabaster\n theme (quite simple)\n\n\nBootstrap\n theme\n\n\n\n\nCustom Theme\n\n\n\n\nNote\n\n\nIf you are looking for third party themes, they are listed in the MkDocs\n\n\ncommunity wiki\n.\n\n\n\n\nIt is possible to add extra customization via a \nCustom Theme\n option.\n\n\n\n\ncreate \ncustom_theme\n and \ncustom_theme/css\n directories parallel to the \ndocs\n directory\n\n\ninside the \ncustom_theme/css\n directory create \nextra.less\n file with your styles\n\n\nuse any LESS compiler to compile the \nextra.less\n file to the minified \nextra.min.css\n and its map \nextra.min.css.map\n\n\nadd the following lines to \nmkdoc.yml\n under the \ntheme\n variable:\n\n\n\n\n1\n2\n3\n4\ntheme\n\n  \ntheme_dir\n:\n \ncustom_theme\n\n  \nextra_css\n:\n\n  \n-\n \ncss/extra.min.css\n\n\n\n\n\n\n\n\n\nnow when you build and serve the website, you should see the custom styling in action\n\n\n\n\nSimilarly, it is possible to add extra JavaScript inside the \ncustom_theme/js\n directory. You add the corresponding setting to the \nmkdocs.yml\n file:\n\n\n1\n2\n3\n4\ntheme\n\n  \ntheme_dir\n:\n \ncustom_theme\n\n  \nextra_javascript\n:\n\n  \n-\n \njs/your-js-file.min.js\n\n\n\n\n\n\n\nThe \n10 Tips for Writing JavaScript without jQuery\n article is a good read to write custom JavaScript without using jQuery.\n\n\n\n\nExtensions\n\n\nAdmonition extension\n\n\nAdmonition extension\n for the MkDocs Markdown provides for a way to draw attention of the reader. In order to use this extension\n\n\nSyntax\n\n\n1\n2\n!!! special_word \nsome text within double quotes\n\n    Any number of lines aligned with the special_word\n\n\n\n\n\n\n\n\n3 exclamation marks ( \n!!!\n ) at the beginning of the line\n\n\n1 space\n\n\n1 special word (see below)\n\n\n1 space\n\n\n(optional) some text within double quotes\n\n\n(optional) 1 empty line\n\n\n(optional) any number of lines beginning at pos. 4 (aligned with the special word after the exclamation marks)\n\n\n\n\nSpecial words\n\n\nThese special words result in a colored adminition blocks. It is nice to experiment with them.\n\n\n\n\nnote\n, \nseealso\n - light blue\n\n\nimportant\n, \nhint\n, \ntip\n - green\n\n\nwarning\n, \ncaution\n, \nattention\n - beige/brown\n\n\ndanger\n, \nerror\n - pink/red\n\n\n\n\n\n\nNote\n\n\nThe special word can be also any other word. In that case, the color will always be light blue.\n\n\n\n\nSome examples\n\n\nA custom text message on the first line\n\n\n1\n2\n3\n!!! note \nExplicit title within double quotes\n\n    Any number of other indented markdown elements.\n    And this is the second paragraph.\n\n\n\n\n\n\nreplaces the 1\nst\n word:\n\n\n\n\nExplicit title within double quotes\n\n\nAny number of other indented markdown elements.\n\nAnd this is the second paragraph.\n\n\n\n\nAny single word on the first line\n\n\n1\n2\n!!! hint\n    You should note that the title will be automatically capitalized.\n\n\n\n\n\n\nwill be capitalized:\n\n\n\n\nHint\n\n\nYou should note that the title will be automatically capitalized.\n\n\n\n\nThe empty custom title\n\n\n1\n2\n!!! warning \n\n    This is an admonition box without a title.\n\n\n\n\n\n\nresults in no title:\n\n\n\n\nThis is an admonition box without a title.\n\n\n\n\nThe word \ndanger\n plus custom title\n\n\n1\n2\n!!! danger \nDon\nt try this at home\n\n    Or you will regret it for the rest of your life!\n\n\n\n\n\n\nresults in the red background:\n\n\n\n\nDon\nt try this at home\n\n\nOr you will regret it for the rest of your life!\n\n\n\n\nSmartyPants extension\n\n\nAdding\n\n\n1\n2\n-\n \nsmarty\n:\n\n    \nsmart_angled_quotes\n:\n \ntrue\n\n\n\n\n\n\n\nto \nmarkdown_extentions\n gives you the possibility to print out nicely looking ASCII dashes, quotes and ellipes:\n\n\nYou write:\n\n\n1\n2\n3\n4\n5\n6\nsingle quotes\n\n\ndouble qoutes\n\n\nangled quotes\n\n... ellipsis\n-- ndash\n--- mdash\n\n\n\n\n\n\nYou get:\n\n\nsingle quotes\n\n\ndouble qoutes\n\n\nangled quotes\n\n\n ellipsis\n\n\n ndash\n\n\n mdash\n\n\n\n\nnl2br extension\n\n\nAdding\n\n\n1\n  \n-\n \nnl2br\n\n\n\n\n\n\n\nto \nmarkdown_extentions\n creates a newline within fences when you make a newline in Markdown. You type:\n\n\n1\n2\nline 1\nline 2\n\n\n\n\n\n\nWithout \nnl2br\n you see this:\n\n\n1\nline 1 line 2\n\n\n\n\n\n\nWith \nnl2br\n you see this:\n\n\n1\n2\nline 1\nline 2\n\n\n\n\n\n\n\n\nReferences\n\n\nHere are the most important links that have inspired me:\n\n\n\n\nLatest official MkDocs \ndocumentation\n\n\nMkDocs \nUser Guide\n\n\nMaterial theme\n for MkDocs\n\n\nMaterial Design \npallette colors", 
            "title": "Custom Styling"
        }, 
        {
            "location": "/engine/styling/#theme-customization", 
            "text": "A lot can be found on the  main website \n itself.  The color table to choose the main and accent colors can be found on the  Getting Started  page.", 
            "title": "Theme Customization"
        }, 
        {
            "location": "/engine/styling/#themes", 
            "text": "MkDocs Themes  12  Bootswatch  themes  Cinder  theme  Alabaster  theme (quite simple)  Bootstrap  theme", 
            "title": "Themes"
        }, 
        {
            "location": "/engine/styling/#custom-theme", 
            "text": "Note  If you are looking for third party themes, they are listed in the MkDocs  community wiki .   It is possible to add extra customization via a  Custom Theme  option.   create  custom_theme  and  custom_theme/css  directories parallel to the  docs  directory  inside the  custom_theme/css  directory create  extra.less  file with your styles  use any LESS compiler to compile the  extra.less  file to the minified  extra.min.css  and its map  extra.min.css.map  add the following lines to  mkdoc.yml  under the  theme  variable:   1\n2\n3\n4 theme \n   theme_dir :   custom_theme \n   extra_css : \n   -   css/extra.min.css     now when you build and serve the website, you should see the custom styling in action   Similarly, it is possible to add extra JavaScript inside the  custom_theme/js  directory. You add the corresponding setting to the  mkdocs.yml  file:  1\n2\n3\n4 theme \n   theme_dir :   custom_theme \n   extra_javascript : \n   -   js/your-js-file.min.js    The  10 Tips for Writing JavaScript without jQuery  article is a good read to write custom JavaScript without using jQuery.", 
            "title": "Custom Theme"
        }, 
        {
            "location": "/engine/styling/#extensions", 
            "text": "", 
            "title": "Extensions"
        }, 
        {
            "location": "/engine/styling/#admonition-extension", 
            "text": "Admonition extension  for the MkDocs Markdown provides for a way to draw attention of the reader. In order to use this extension", 
            "title": "Admonition extension"
        }, 
        {
            "location": "/engine/styling/#syntax", 
            "text": "1\n2 !!! special_word  some text within double quotes \n    Any number of lines aligned with the special_word    3 exclamation marks (  !!!  ) at the beginning of the line  1 space  1 special word (see below)  1 space  (optional) some text within double quotes  (optional) 1 empty line  (optional) any number of lines beginning at pos. 4 (aligned with the special word after the exclamation marks)", 
            "title": "Syntax"
        }, 
        {
            "location": "/engine/styling/#special-words", 
            "text": "These special words result in a colored adminition blocks. It is nice to experiment with them.   note ,  seealso  - light blue  important ,  hint ,  tip  - green  warning ,  caution ,  attention  - beige/brown  danger ,  error  - pink/red    Note  The special word can be also any other word. In that case, the color will always be light blue.", 
            "title": "Special words"
        }, 
        {
            "location": "/engine/styling/#some-examples", 
            "text": "A custom text message on the first line  1\n2\n3 !!! note  Explicit title within double quotes \n    Any number of other indented markdown elements.\n    And this is the second paragraph.   replaces the 1 st  word:   Explicit title within double quotes  Any number of other indented markdown elements. \nAnd this is the second paragraph.   Any single word on the first line  1\n2 !!! hint\n    You should note that the title will be automatically capitalized.   will be capitalized:   Hint  You should note that the title will be automatically capitalized.   The empty custom title  1\n2 !!! warning  \n    This is an admonition box without a title.   results in no title:   This is an admonition box without a title.   The word  danger  plus custom title  1\n2 !!! danger  Don t try this at home \n    Or you will regret it for the rest of your life!   results in the red background:   Don t try this at home  Or you will regret it for the rest of your life!", 
            "title": "Some examples"
        }, 
        {
            "location": "/engine/styling/#smartypants-extension", 
            "text": "Adding  1\n2 -   smarty : \n     smart_angled_quotes :   true    to  markdown_extentions  gives you the possibility to print out nicely looking ASCII dashes, quotes and ellipes:  You write:  1\n2\n3\n4\n5\n6 single quotes  double qoutes  angled quotes \n... ellipsis\n-- ndash\n--- mdash   You get:  single quotes  double qoutes  angled quotes   ellipsis   ndash   mdash", 
            "title": "SmartyPants extension"
        }, 
        {
            "location": "/engine/styling/#nl2br-extension", 
            "text": "Adding  1    -   nl2br    to  markdown_extentions  creates a newline within fences when you make a newline in Markdown. You type:  1\n2 line 1\nline 2   Without  nl2br  you see this:  1 line 1 line 2   With  nl2br  you see this:  1\n2 line 1\nline 2", 
            "title": "nl2br extension"
        }, 
        {
            "location": "/engine/styling/#references", 
            "text": "Here are the most important links that have inspired me:   Latest official MkDocs  documentation  MkDocs  User Guide  Material theme  for MkDocs  Material Design  pallette colors", 
            "title": "References"
        }, 
        {
            "location": "/engine/install/", 
            "text": "Installation\n\n\nTaken from \nthis website\n.\n\n\nInstalling MkDocs\n\n\nBefore installing \nMkDocs\n, you need to make sure you have \nPython\n and \npip\n \u2013 the Python package manager \u2013 up and running. You can verify if you\nre already good to go with the following commands:\n\n\n1\n2\n3\n4\npython --version\n\n# Python 2.7.13\n\npip --version\n\n# pip 9.0.1\n\n\n\n\n\n\n\nInstalling and verifying MkDocs is as simple as:\n\n\n1\n2\npip install mkdocs \n mkdocs --version\n\n# mkdocs, version 0.17.1\n\n\n\n\n\n\n\nMaterial requires MkDocs \n= 0.17.1.\n\n\nInstalling Material\n\n\nusing pip\n\n\nMaterial can be installed with pip:\n\n\n1\npip install mkdocs-material\n\n\n\n\n\n\nusing choco\n\n\nIf you\nre on Windows you can use \nChocolatey\n to install Material:\n\n\n1\nchoco install mkdocs-material\n\n\n\n\n\n\nThis will install all required dependencies like Python and MkDocs.\n\n\ncloning from GitHub\n\n\nMaterial can also be used without a system-wide installation by cloning the repository into a subfolder of your project\ns root directory:\n\n\n1\ngit clone https://github.com/squidfunk/mkdocs-material.git\n\n\n\n\n\n\nThis is especially useful if you want to \nextend the theme\n and \noverride some parts\n of the theme. The theme will reside in the folder \nmkdocs-material/material\n.\n\n\nTroubleshooting\n\n\n\n\nInstallation on macOS\n\n\nWhen you\nre running the pre-installed version of Python on macOS, pip tries to install packages in a folder for which your user might not have the adequate permissions. There are two possible solutions for this:\n\n\n\n\n\n\nInstalling in user space (recommended): Provide the \nuser flag to the install command and pip will install the package in a user-site location. This is the recommended way.\n\n\n\n\n\n\nSwitching to a homebrewed Python: Upgrade your Python installation to a self-contained solution by installing Python with Homebrew. This should eliminate a lot of problems you may be having with pip.\n\n\n\n\n\n\n\n\n\n\nError: unrecognized theme \nmaterial\n\n\nIf you run into this error, the most common reason is that you installed MkDocs through some package manager (e.g. Homebrew or apt-get) and the Material theme through pip, so both packages end up in different locations. MkDocs only checks its install location for themes.\n\n\n\n\nAlternative: Using Docker\n\n\nIf you\nre familiar with \nDocker\n, the official \nDocker image\n for Material comes with all dependencies pre-installed and ready-to-use with the latest version published on \nPyPI\n, packaged in a very small image. Pull it with:\n\n\n1\ndocker pull squidfunk/mkdocs-material\n\n\n\n\n\n\nThe mkdocs executable is provided as an entrypoint, serve is the default command. Start the development server in your project root with:\n\n\n1\ndocker run --rm -it -p 8000:8000 -v `pwd`:/docs squidfunk/mkdocs-material\n\n\n\n\n\n\n\n\nUsage\n\n\nIn order to enable the theme just add one of the following lines to your project\ns \nmkdocs.yml\n. If you installed Material using pip:\n\n\n1\n2\ntheme\n:\n\n  \nname\n:\n \nmaterial\n\n\n\n\n\n\n\nIf you cloned Material from GitHub:\n\n\n1\n2\n3\ntheme\n:\n\n  \nname\n:\n \nnull\n\n  \ncustom_dir\n:\n \nmkdocs-material/material\n\n\n\n\n\n\n\nMkDocs includes a development server, so you can review your changes as you go. The development server can be started with the following command:\n\n\n1\nmkdocs serve\n\n\n\n\n\n\nNow you can point your browser to \nhttp://localhost:8000\n and the Material theme should be visible. From here on, you can start writing your documentation, or read on and customize the theme.\n\n\n\n\nConfiguration\n\n\nColor palette\n\n\nA default hue is defined for every primary and accent color on Google\ns\n\nMaterial Design \ncolor palette\n, which makes it very easy to change the\n\noverall look of the theme. Just set the primary and accent colors using the\n\nfollowing variables:\n\n\n1\n2\n3\n4\ntheme\n:\n\n  \npalette\n:\n\n    \nprimary\n:\n \nindigo\n\n    \naccent\n:\n \nindigo\n\n\n\n\n\n\n\nColor names are case-insensitive, but must match the names of the Material\n\nDesign color palette. Valid values are: \nred\n, \npink\n, \npurple\n, \ndeep purple\n,\n\n\nindigo\n, \nblue\n, \nlight blue\n, \ncyan\n, \nteal\n, \ngreen\n, \nlight green\n, \nlime\n,\n\n\nyellow\n, \namber\n, \norange\n, \ndeep orange\n, \nbrown\n, \ngrey\n, \nblue grey\n and\n\n\nwhite\n. The last four colors can only be used as a primary color.\n\n\nIf the color is set via this configuration, an additional CSS file that\n\ndefines the color palette is automatically included. If you want to keep things\n\nlean, clone the repository and recompile the theme with your custom colors set.\n\n\nPrimary colors\n\n\n\n\nDefault: \nindigo\n\n\n\n\nClick on a tile to change the primary color of the theme:\n\n\nRed\n\n\nPink\n\n\nPurple\n\n\nDeep Purple\n\n\nIndigo\n\n\nBlue\n\n\nLight Blue\n\n\nCyan\n\n\nTeal\n\n\nGreen\n\n\nLight Green\n\n\nLime\n\n\nYellow\n\n\nAmber\n\n\nOrange\n\n\nDeep Orange\n\n\nBrown\n\n\nGrey\n\n\nBlue Grey\n\n\nWhite\n\n\n\n  var buttons = document.querySelectorAll(\"button[data-md-color-primary]\");\n  Array.prototype.forEach.call(buttons, function(button) {\n    button.addEventListener(\"click\", function() {\n      document.body.dataset.mdColorPrimary = this.dataset.mdColorPrimary;\n    })\n  })\n\n\n\n\nAccent colors\n\n\n\n\nDefault: \nindigo\n\n\n\n\nClick on a tile to change the accent color of the theme:\n\n\nRed\n\n\nPink\n\n\nPurple\n\n\nDeep Purple\n\n\nIndigo\n\n\nBlue\n\n\nLight Blue\n\n\nCyan\n\n\nTeal\n\n\nGreen\n\n\nLight Green\n\n\nLime\n\n\nYellow\n\n\nAmber\n\n\nOrange\n\n\nDeep Orange\n\n\n\n  var buttons = document.querySelectorAll(\"button[data-md-color-accent]\");\n  Array.prototype.forEach.call(buttons, function(button) {\n    button.addEventListener(\"click\", function() {\n      document.body.dataset.mdColorAccent = this.dataset.mdColorAccent;\n    })\n  })\n\n\n\n\nA default hue is defined for every primary and accent color on Google\ns Material Design color palette, which makes it very easy to change the overall look of the theme. Just set the primary and accent colors using the following variables:\n\n\n1\n2\n3\n4\ntheme\n:\n\n  \npalette\n:\n\n    \nprimary\n:\n \nindigo\n\n    \naccent\n:\n \nindigo\n\n\n\n\n\n\n\nColor names are case-insensitive, but must match the names of the Material Design color palette. Valid values are: \nred\n, \npink\n, \npurple\n, \ndeep purple\n, \nindigo\n, \nblue\n, \nlight blue\n, \ncyan\n, \nteal\n, \ngreen\n, \nlight green\n, \nlime\n, \nyellow\n, \namber\n, \norange\n, \ndeep orange\n, \nbrown\n, \ngrey\n, \nblue grey\n and \nwhite\n. The last four colors can only be used as a primary color.\n\n\n\n\nCompile your own custom color theme\n\n\nIf the color is set via this configuration, an additional CSS file that defines the color palette is automatically included. If you want to keep things lean, \nclone the repository and recompile the theme with your custom colors set\n. See the \nguide on customization\n for more information.\n\n\n\n\nFont family\n\n\n\n\nDefault: \nRoboto\n and \nRoboto Mono\n\n\n\n\nBy default the \nRoboto font family\n is included with the theme, specifically the regular sans-serif type for text and the monospaced type for code. Both fonts are loaded from \nGoogle Fonts\n and can be changed to other fonts, like for example the \nUbuntu font family\n:\n\n\n1\n2\n3\n4\ntheme\n:\n\n  \nfont\n:\n\n    \ntext\n:\n \nUbuntu\n\n    \ncode\n:\n \nUbuntu\n \nMono\n\n\n\n\n\n\n\nThe text font will be loaded in weights 400 and 700, the \nmonospaced\n font in regular weight. If you want to load fonts from other destinations or don\nt want to use the Google Fonts loading magic, just set \nfont\n to \nfalse\n:\n\n\n1\n2\ntheme\n:\n\n  \nfont\n:\n \nfalse\n\n\n\n\n\n\n\nLogo\n\n\n\n\nDefault icon: \nschool\n\n\n\n\nYour logo should have rectangular shape with a minimum resolution of 128x128, leave some room towards the edges and be composed of high contrast areas on a transparent ground, as it will be placed on the colored header bar and drawer. Simply create the folder \ndocs/images\n, add your logo and embed it with:\n\n\n1\n2\ntheme\n:\n\n  \nlogo\n:\n \nimages/logo.svg\n\n\n\n\n\n\n\nAdditionally, the default icon can be changed by setting an arbitrary ligature (or Unicode code point) from the \nMaterial Design icon font\n, e.g.\n\n\n1\n2\n3\ntheme\n:\n\n  \nlogo\n:\n\n    \nicon\n:\n \ncloud\n\n\n\n\n\n\n\nLanguage\n\n\nLocalization\n\n\n\n\nDefault: \nen\n\n\n\n\nMaterial for MkDocs supports \ninternationalization\n (\ni18n\n) and provides translations for all template variables and labels in English \nen\n, French \nfr\n, German \nde\n, Spanish \nes\n, Italian \nit\n, Danish \nda\n, Portugese \npt\n, Polish \npl\n, Norwegian \nno\n, Dutch \nnl\n, Swedish \nsv\n, Korean \nkr\n, Russian \nru\n, Japanese \nja\n, Chinese (Simplified) \nzh\n and Chinese (Traditional) \nzh-Hant\n. Specify the language with:\n\n\n1\n2\ntheme\n:\n\n  \nlanguage\n:\n \nen\n\n\n\n\n\n\n\n\n\nMake your own translations\n\n\nIf the language is not specified, Material falls back to English. To create a translation for another language, copy the localization file of an existing language, name the new file using the \n2-letter language code\n and adjust all translations:\n\n\n1\ncp partials/language/en.html partials/language/jp.html\n\n\n\n\n\n\n\nFeel free to contribute your localization to Material for MkDocs by opening a Pull Request.\n\n\n\n\nSite search\n\n\n\n\nDefault: \nen\n\n\n\n\nSite search is implemented using \nlunr.js\n, which includes stemmers for the English language by default, while stemmers for other languages are included with \nlunr-languages\n, both of which are integrated with this theme. Support for other languages and even multilingual search can be activated in your project\ns \nmkdocs.yml\n:\n\n\n1\n2\n3\nextra\n:\n\n  \nsearch\n:\n\n    \nlanguage\n:\n \nen,\n \nde,\n \nru\n\n\n\n\n\n\n\nAll defined languages are used only for stemming. This will automatically load the stemmers for the specified languages and set them up with site search.\n\n\nAt the time of writing, the following languages are supported: English \nen\n, French \nfr\n, German \nde\n, Spanish \nes\n, Italian \nit\n, Danish \nda\n, Portugese \npt\n, Finnish fi, Romanian ro, Hungarian hu, Russian \nru\n, Norwegian \nno\n, Swedish \nsv\n, Japanese \nja\n and Turkish \ntr\n.\n\n\n\n\nOnly specify the languages you really need\n\n\nBe aware that including support for other languages increases the general JavaScript payload by around 20kb (without gzip) and by another 15-30kb per language.\n\n\n\n\nThe separator for tokenization can be customized which makes it possible to index parts of words that are separated by \n-\n or \n.\n:\n\n\n1\n2\n3\nextra\n:\n\n  \nsearch\n:\n\n    \ntokenizer\n:\n \n[\\s\\-\\.]+\n\n\n\n\n\n\n\nFavicon\n\n\n\n\nDefault: \nassets/images/favicon.png\n\n\n\n\nThe default favicon can be changed by setting the \nfavicon\n variable to an \n.ico\n or image file:\n\n\n1\n2\ntheme\n:\n\n  \nfavicon\n:\n \nassets/images/favicon.ico\n\n\n\n\n\n\n\nFeatures\n\n\nTabs\n\n\n\n\nDefault: \nfalse\n\n\n\n\nMaterial supports another layer on top of the main navigation for larger screens in the form of tabs. This is especially useful for larger documentation projects with only few top-level sections. Tabs can be enabled by setting the respective feature flag to true:\n\n\n1\n2\n3\ntheme\n:\n\n  \nfeature\n:\n\n    \ntabs\n:\n \ntrue\n\n\n\n\n\n\n\n\n\nCustomization\n\n\nAdding a source repository\n\n\nTo include a link to the repository of your project within your documentation, set the following variables via your project\ns \nmkdocs.yml\n:\n\n\n1\n2\nrepo_name\n:\n \nsquidfunk/mkdocs-material\n\n\nrepo_url\n:\n \nhttps://github.com/squidfunk/mkdocs-material\n\n\n\n\n\n\n\nThe name of the repository will be rendered next to the search bar on big screens and as part of the main navigation drawer on smaller screen sizes. Furthermore, if \nrepo_url\n points to a \nGitHub\n, \nBitBucket\n or \nGitLab\n repository, the respective service logo will be shown next to the name of the repository. Additionally, for \nGitHub\n, the number of stars and forks is shown.\n\n\nIf the repository is hosted in a private environment, the service logo can be set explicitly by setting \nextra.repo_icon\n to \ngithub\n, \ngitlab\n or \nbitbucket\n.\n\n\n\n\nWhy is there an edit button at the top of every article?\n\n\nIf the \nrepo_url\n is set to a \nGitHub\n or \nBitBucket\n repository, and the \nrepo_name\n is set to \nGitHub\n or \nBitBucket\n (implied by default), an edit button will appear at the top of every article. This is the automatic behavior that MkDocs implements. Set \nedit_uri\n to an empty string to disable this automatic behavior.\n\n\nSee the \nMkDocs documentation\n on more guidance regarding the \nedit_uri\n attribute, which defines whether the edit button is shown or not.\n\n\n\n\nAdding social links\n\n\nSocial accounts can be linked in the footer of the documentation using the automatically included \nFontAwesome webfont\n. The \ntype\n must denote the name of the social service, e.g. \ngithub\n, \ntwitter\n or \nlinkedin\n and the \nlink\n must contain the URL you want to link to:\n\n\n1\n2\n3\n4\n5\n6\n7\n8\nextra\n:\n\n  \nsocial\n:\n\n    \n-\n \ntype\n:\n \ngithub\n\n      \nlink\n:\n \nhttps://github.com/squidfunk\n\n    \n-\n \ntype\n:\n \ntwitter\n\n      \nlink\n:\n \nhttps://twitter.com/squidfunk\n\n    \n-\n \ntype\n:\n \nlinkedin\n\n      \nlink\n:\n \nhttps://linkedin.com/in/squidfunk\n\n\n\n\n\n\n\nThe links are generated in order and the \ntype\n of the links must match the name of the FontAwesome glyph. The \nfa\n is automatically added, so \ngithub\n will result in \nfa fa-github\n.\n\n\nMore advanced customization\n\n\nIf you want to change the general appearance of the Material theme, see \nthis article\n for more information on advanced customization.\n\n\n\n\nIntegrations\n\n\nGoogle Analytics\n\n\nMkDocs makes it easy to integrate site tracking with Google Analytics. Besides basic tracking, clicks on all outgoing links can be tracked as well as how site search is used. Tracking can be activated in your project\ns \nmkdocs.yml\n:\n\n\n1\n2\n3\ngoogle_analytics\n:\n\n  \n-\n \nUA-XXXXXXXX-X\n\n  \n-\n \nauto\n\n\n\n\n\n\n\n\n\nDisqus\n\n\nMaterial for MkDocs is integrated with \nDisqus\n, so if you want to add a comments section to your documentation set the shortname of your Disqus project in your \nmkdocs.yml\n:\n\n\n1\n2\nextra\n:\n\n  \ndisqus\n:\n \nmkdocs-material\n\n\n\n\n\n\n\nThe comments section is inserted on every page, except the index page. Additionally, a new entry at the bottom of the table of contents is generated that is linking to the comments section. The necessary JavaScript is automatically included.\n\n\n\n\nRequirements\n\n\nsite_url\n value must be set in \nmkdocs.yml\n for the Disqus integration to load properly.\n\n\n\n\n\n\nExtensions\n\n\nMkDocs supports several \nMarkdown extensions\n. The following extensions are not enabled by default (see the link for which are enabled by default) but highly recommended, so they should be switched on at all times:\n\n\n1\n2\n3\n4\n5\n6\nmarkdown_extensions\n:\n\n  \n-\n \nadmonition\n\n  \n-\n \ncodehilite\n:\n\n      \nguess_lang\n:\n \nfalse\n\n  \n-\n \ntoc\n:\n\n      \npermalink\n:\n \ntrue\n\n\n\n\n\n\n\nFor more information, see the following list of extensions supported by the Material theme including more information regarding installation and usage:\n\n\n\n\nAdmonition\n\n\nCodehilite\n\n\nFootnotes\n\n\nMetadata\n\n\nPermalinks\n\n\nPyMdown Extensions\n\n\n\n\n\n\nFull example\n\n\nBelow is a full example configuration for a \nmkdocs.yml\n:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n# Project information\n\n\nsite_name\n:\n \nMaterial\n \nfor\n \nMkDocs\n\n\nsite_description\n:\n \nA\n \nMaterial\n \nDesign\n \ntheme\n \nfor\n \nMkDocs\n\n\nsite_author\n:\n \nMartin\n \nDonath\n\n\nsite_url\n:\n \nhttps://squidfunk.github.io/mkdocs-material/\n\n\n\n# Repository\n\n\nrepo_name\n:\n \nsquidfunk/mkdocs-material\n\n\nrepo_url\n:\n \nhttps://github.com/squidfunk/mkdocs-material\n\n\n\n# Copyright\n\n\ncopyright\n:\n \nCopyright\n \ncopy;\n \n2016\n \n-\n \n2017\n \nMartin\n \nDonath\n\n\n\n# Configuration\n\n\ntheme\n:\n\n  \nname\n:\n \nmaterial\n\n  \nlanguage\n:\n \nen\n\n  \npalette\n:\n\n    \nprimary\n:\n \nindigo\n\n    \naccent\n:\n \nindigo\n\n  \nfont\n:\n\n    \ntext\n:\n \nRoboto\n\n    \ncode\n:\n \nRoboto\n \nMono\n\n\n\n# Customization\n\n\nextra\n:\n\n  \nsocial\n:\n\n    \n-\n \ntype\n:\n \ngithub\n\n      \nlink\n:\n \nhttps://github.com/squidfunk\n\n    \n-\n \ntype\n:\n \ntwitter\n\n      \nlink\n:\n \nhttps://twitter.com/squidfunk\n\n    \n-\n \ntype\n:\n \nlinkedin\n\n      \nlink\n:\n \nhttps://linkedin.com/in/squidfunk\n\n\n\n# Google Analytics\n\n\ngoogle_analytics\n:\n\n  \n-\n \nUA-XXXXXXXX-X\n\n  \n-\n \nauto\n\n\n\n# Extensions\n\n\nmarkdown_extensions\n:\n\n  \n-\n \nadmonition\n\n  \n-\n \ncodehilite\n:\n\n      \nguess_lang\n:\n \nfalse\n\n  \n-\n \ntoc\n:\n\n      \npermalink\n:\n \ntrue", 
            "title": "More on MkDocs Material"
        }, 
        {
            "location": "/engine/install/#installation", 
            "text": "Taken from  this website .", 
            "title": "Installation"
        }, 
        {
            "location": "/engine/install/#installing-mkdocs", 
            "text": "Before installing  MkDocs , you need to make sure you have  Python  and  pip  \u2013 the Python package manager \u2013 up and running. You can verify if you re already good to go with the following commands:  1\n2\n3\n4 python --version # Python 2.7.13 \npip --version # pip 9.0.1    Installing and verifying MkDocs is as simple as:  1\n2 pip install mkdocs   mkdocs --version # mkdocs, version 0.17.1    Material requires MkDocs  = 0.17.1.", 
            "title": "Installing MkDocs"
        }, 
        {
            "location": "/engine/install/#installing-material", 
            "text": "", 
            "title": "Installing Material"
        }, 
        {
            "location": "/engine/install/#using-pip", 
            "text": "Material can be installed with pip:  1 pip install mkdocs-material", 
            "title": "using pip"
        }, 
        {
            "location": "/engine/install/#using-choco", 
            "text": "If you re on Windows you can use  Chocolatey  to install Material:  1 choco install mkdocs-material   This will install all required dependencies like Python and MkDocs.", 
            "title": "using choco"
        }, 
        {
            "location": "/engine/install/#cloning-from-github", 
            "text": "Material can also be used without a system-wide installation by cloning the repository into a subfolder of your project s root directory:  1 git clone https://github.com/squidfunk/mkdocs-material.git   This is especially useful if you want to  extend the theme  and  override some parts  of the theme. The theme will reside in the folder  mkdocs-material/material .", 
            "title": "cloning from GitHub"
        }, 
        {
            "location": "/engine/install/#troubleshooting", 
            "text": "Installation on macOS  When you re running the pre-installed version of Python on macOS, pip tries to install packages in a folder for which your user might not have the adequate permissions. There are two possible solutions for this:    Installing in user space (recommended): Provide the  user flag to the install command and pip will install the package in a user-site location. This is the recommended way.    Switching to a homebrewed Python: Upgrade your Python installation to a self-contained solution by installing Python with Homebrew. This should eliminate a lot of problems you may be having with pip.      Error: unrecognized theme  material  If you run into this error, the most common reason is that you installed MkDocs through some package manager (e.g. Homebrew or apt-get) and the Material theme through pip, so both packages end up in different locations. MkDocs only checks its install location for themes.", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/engine/install/#alternative-using-docker", 
            "text": "If you re familiar with  Docker , the official  Docker image  for Material comes with all dependencies pre-installed and ready-to-use with the latest version published on  PyPI , packaged in a very small image. Pull it with:  1 docker pull squidfunk/mkdocs-material   The mkdocs executable is provided as an entrypoint, serve is the default command. Start the development server in your project root with:  1 docker run --rm -it -p 8000:8000 -v `pwd`:/docs squidfunk/mkdocs-material", 
            "title": "Alternative: Using Docker"
        }, 
        {
            "location": "/engine/install/#usage", 
            "text": "In order to enable the theme just add one of the following lines to your project s  mkdocs.yml . If you installed Material using pip:  1\n2 theme : \n   name :   material    If you cloned Material from GitHub:  1\n2\n3 theme : \n   name :   null \n   custom_dir :   mkdocs-material/material    MkDocs includes a development server, so you can review your changes as you go. The development server can be started with the following command:  1 mkdocs serve   Now you can point your browser to  http://localhost:8000  and the Material theme should be visible. From here on, you can start writing your documentation, or read on and customize the theme.", 
            "title": "Usage"
        }, 
        {
            "location": "/engine/install/#configuration", 
            "text": "", 
            "title": "Configuration"
        }, 
        {
            "location": "/engine/install/#color-palette", 
            "text": "A default hue is defined for every primary and accent color on Google s \nMaterial Design  color palette , which makes it very easy to change the \noverall look of the theme. Just set the primary and accent colors using the \nfollowing variables:  1\n2\n3\n4 theme : \n   palette : \n     primary :   indigo \n     accent :   indigo    Color names are case-insensitive, but must match the names of the Material \nDesign color palette. Valid values are:  red ,  pink ,  purple ,  deep purple ,  indigo ,  blue ,  light blue ,  cyan ,  teal ,  green ,  light green ,  lime ,  yellow ,  amber ,  orange ,  deep orange ,  brown ,  grey ,  blue grey  and  white . The last four colors can only be used as a primary color.  If the color is set via this configuration, an additional CSS file that \ndefines the color palette is automatically included. If you want to keep things \nlean, clone the repository and recompile the theme with your custom colors set.", 
            "title": "Color palette"
        }, 
        {
            "location": "/engine/install/#primary-colors", 
            "text": "Default:  indigo   Click on a tile to change the primary color of the theme:  Red  Pink  Purple  Deep Purple  Indigo  Blue  Light Blue  Cyan  Teal  Green  Light Green  Lime  Yellow  Amber  Orange  Deep Orange  Brown  Grey  Blue Grey  White  \n  var buttons = document.querySelectorAll(\"button[data-md-color-primary]\");\n  Array.prototype.forEach.call(buttons, function(button) {\n    button.addEventListener(\"click\", function() {\n      document.body.dataset.mdColorPrimary = this.dataset.mdColorPrimary;\n    })\n  })", 
            "title": "Primary colors"
        }, 
        {
            "location": "/engine/install/#accent-colors", 
            "text": "Default:  indigo   Click on a tile to change the accent color of the theme:  Red  Pink  Purple  Deep Purple  Indigo  Blue  Light Blue  Cyan  Teal  Green  Light Green  Lime  Yellow  Amber  Orange  Deep Orange  \n  var buttons = document.querySelectorAll(\"button[data-md-color-accent]\");\n  Array.prototype.forEach.call(buttons, function(button) {\n    button.addEventListener(\"click\", function() {\n      document.body.dataset.mdColorAccent = this.dataset.mdColorAccent;\n    })\n  })  A default hue is defined for every primary and accent color on Google s Material Design color palette, which makes it very easy to change the overall look of the theme. Just set the primary and accent colors using the following variables:  1\n2\n3\n4 theme : \n   palette : \n     primary :   indigo \n     accent :   indigo    Color names are case-insensitive, but must match the names of the Material Design color palette. Valid values are:  red ,  pink ,  purple ,  deep purple ,  indigo ,  blue ,  light blue ,  cyan ,  teal ,  green ,  light green ,  lime ,  yellow ,  amber ,  orange ,  deep orange ,  brown ,  grey ,  blue grey  and  white . The last four colors can only be used as a primary color.   Compile your own custom color theme  If the color is set via this configuration, an additional CSS file that defines the color palette is automatically included. If you want to keep things lean,  clone the repository and recompile the theme with your custom colors set . See the  guide on customization  for more information.", 
            "title": "Accent colors"
        }, 
        {
            "location": "/engine/install/#font-family", 
            "text": "Default:  Roboto  and  Roboto Mono   By default the  Roboto font family  is included with the theme, specifically the regular sans-serif type for text and the monospaced type for code. Both fonts are loaded from  Google Fonts  and can be changed to other fonts, like for example the  Ubuntu font family :  1\n2\n3\n4 theme : \n   font : \n     text :   Ubuntu \n     code :   Ubuntu   Mono    The text font will be loaded in weights 400 and 700, the  monospaced  font in regular weight. If you want to load fonts from other destinations or don t want to use the Google Fonts loading magic, just set  font  to  false :  1\n2 theme : \n   font :   false", 
            "title": "Font family"
        }, 
        {
            "location": "/engine/install/#logo", 
            "text": "Default icon:  school   Your logo should have rectangular shape with a minimum resolution of 128x128, leave some room towards the edges and be composed of high contrast areas on a transparent ground, as it will be placed on the colored header bar and drawer. Simply create the folder  docs/images , add your logo and embed it with:  1\n2 theme : \n   logo :   images/logo.svg    Additionally, the default icon can be changed by setting an arbitrary ligature (or Unicode code point) from the  Material Design icon font , e.g.  1\n2\n3 theme : \n   logo : \n     icon :   cloud", 
            "title": "Logo"
        }, 
        {
            "location": "/engine/install/#language", 
            "text": "", 
            "title": "Language"
        }, 
        {
            "location": "/engine/install/#localization", 
            "text": "Default:  en   Material for MkDocs supports  internationalization  ( i18n ) and provides translations for all template variables and labels in English  en , French  fr , German  de , Spanish  es , Italian  it , Danish  da , Portugese  pt , Polish  pl , Norwegian  no , Dutch  nl , Swedish  sv , Korean  kr , Russian  ru , Japanese  ja , Chinese (Simplified)  zh  and Chinese (Traditional)  zh-Hant . Specify the language with:  1\n2 theme : \n   language :   en     Make your own translations  If the language is not specified, Material falls back to English. To create a translation for another language, copy the localization file of an existing language, name the new file using the  2-letter language code  and adjust all translations:  1 cp partials/language/en.html partials/language/jp.html    Feel free to contribute your localization to Material for MkDocs by opening a Pull Request.", 
            "title": "Localization"
        }, 
        {
            "location": "/engine/install/#site-search", 
            "text": "Default:  en   Site search is implemented using  lunr.js , which includes stemmers for the English language by default, while stemmers for other languages are included with  lunr-languages , both of which are integrated with this theme. Support for other languages and even multilingual search can be activated in your project s  mkdocs.yml :  1\n2\n3 extra : \n   search : \n     language :   en,   de,   ru    All defined languages are used only for stemming. This will automatically load the stemmers for the specified languages and set them up with site search.  At the time of writing, the following languages are supported: English  en , French  fr , German  de , Spanish  es , Italian  it , Danish  da , Portugese  pt , Finnish fi, Romanian ro, Hungarian hu, Russian  ru , Norwegian  no , Swedish  sv , Japanese  ja  and Turkish  tr .   Only specify the languages you really need  Be aware that including support for other languages increases the general JavaScript payload by around 20kb (without gzip) and by another 15-30kb per language.   The separator for tokenization can be customized which makes it possible to index parts of words that are separated by  -  or  . :  1\n2\n3 extra : \n   search : \n     tokenizer :   [\\s\\-\\.]+", 
            "title": "Site search"
        }, 
        {
            "location": "/engine/install/#favicon", 
            "text": "Default:  assets/images/favicon.png   The default favicon can be changed by setting the  favicon  variable to an  .ico  or image file:  1\n2 theme : \n   favicon :   assets/images/favicon.ico", 
            "title": "Favicon"
        }, 
        {
            "location": "/engine/install/#features", 
            "text": "", 
            "title": "Features"
        }, 
        {
            "location": "/engine/install/#tabs", 
            "text": "Default:  false   Material supports another layer on top of the main navigation for larger screens in the form of tabs. This is especially useful for larger documentation projects with only few top-level sections. Tabs can be enabled by setting the respective feature flag to true:  1\n2\n3 theme : \n   feature : \n     tabs :   true", 
            "title": "Tabs"
        }, 
        {
            "location": "/engine/install/#customization", 
            "text": "", 
            "title": "Customization"
        }, 
        {
            "location": "/engine/install/#adding-a-source-repository", 
            "text": "To include a link to the repository of your project within your documentation, set the following variables via your project s  mkdocs.yml :  1\n2 repo_name :   squidfunk/mkdocs-material  repo_url :   https://github.com/squidfunk/mkdocs-material    The name of the repository will be rendered next to the search bar on big screens and as part of the main navigation drawer on smaller screen sizes. Furthermore, if  repo_url  points to a  GitHub ,  BitBucket  or  GitLab  repository, the respective service logo will be shown next to the name of the repository. Additionally, for  GitHub , the number of stars and forks is shown.  If the repository is hosted in a private environment, the service logo can be set explicitly by setting  extra.repo_icon  to  github ,  gitlab  or  bitbucket .   Why is there an edit button at the top of every article?  If the  repo_url  is set to a  GitHub  or  BitBucket  repository, and the  repo_name  is set to  GitHub  or  BitBucket  (implied by default), an edit button will appear at the top of every article. This is the automatic behavior that MkDocs implements. Set  edit_uri  to an empty string to disable this automatic behavior.  See the  MkDocs documentation  on more guidance regarding the  edit_uri  attribute, which defines whether the edit button is shown or not.", 
            "title": "Adding a source repository"
        }, 
        {
            "location": "/engine/install/#adding-social-links", 
            "text": "Social accounts can be linked in the footer of the documentation using the automatically included  FontAwesome webfont . The  type  must denote the name of the social service, e.g.  github ,  twitter  or  linkedin  and the  link  must contain the URL you want to link to:  1\n2\n3\n4\n5\n6\n7\n8 extra : \n   social : \n     -   type :   github \n       link :   https://github.com/squidfunk \n     -   type :   twitter \n       link :   https://twitter.com/squidfunk \n     -   type :   linkedin \n       link :   https://linkedin.com/in/squidfunk    The links are generated in order and the  type  of the links must match the name of the FontAwesome glyph. The  fa  is automatically added, so  github  will result in  fa fa-github .", 
            "title": "Adding social links"
        }, 
        {
            "location": "/engine/install/#more-advanced-customization", 
            "text": "If you want to change the general appearance of the Material theme, see  this article  for more information on advanced customization.", 
            "title": "More advanced customization"
        }, 
        {
            "location": "/engine/install/#integrations", 
            "text": "", 
            "title": "Integrations"
        }, 
        {
            "location": "/engine/install/#google-analytics", 
            "text": "MkDocs makes it easy to integrate site tracking with Google Analytics. Besides basic tracking, clicks on all outgoing links can be tracked as well as how site search is used. Tracking can be activated in your project s  mkdocs.yml :  1\n2\n3 google_analytics : \n   -   UA-XXXXXXXX-X \n   -   auto", 
            "title": "Google Analytics"
        }, 
        {
            "location": "/engine/install/#disqus", 
            "text": "Material for MkDocs is integrated with  Disqus , so if you want to add a comments section to your documentation set the shortname of your Disqus project in your  mkdocs.yml :  1\n2 extra : \n   disqus :   mkdocs-material    The comments section is inserted on every page, except the index page. Additionally, a new entry at the bottom of the table of contents is generated that is linking to the comments section. The necessary JavaScript is automatically included.   Requirements  site_url  value must be set in  mkdocs.yml  for the Disqus integration to load properly.", 
            "title": "Disqus"
        }, 
        {
            "location": "/engine/install/#extensions", 
            "text": "MkDocs supports several  Markdown extensions . The following extensions are not enabled by default (see the link for which are enabled by default) but highly recommended, so they should be switched on at all times:  1\n2\n3\n4\n5\n6 markdown_extensions : \n   -   admonition \n   -   codehilite : \n       guess_lang :   false \n   -   toc : \n       permalink :   true    For more information, see the following list of extensions supported by the Material theme including more information regarding installation and usage:   Admonition  Codehilite  Footnotes  Metadata  Permalinks  PyMdown Extensions", 
            "title": "Extensions"
        }, 
        {
            "location": "/engine/install/#full-example", 
            "text": "Below is a full example configuration for a  mkdocs.yml :   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46 # Project information  site_name :   Material   for   MkDocs  site_description :   A   Material   Design   theme   for   MkDocs  site_author :   Martin   Donath  site_url :   https://squidfunk.github.io/mkdocs-material/  # Repository  repo_name :   squidfunk/mkdocs-material  repo_url :   https://github.com/squidfunk/mkdocs-material  # Copyright  copyright :   Copyright   copy;   2016   -   2017   Martin   Donath  # Configuration  theme : \n   name :   material \n   language :   en \n   palette : \n     primary :   indigo \n     accent :   indigo \n   font : \n     text :   Roboto \n     code :   Roboto   Mono  # Customization  extra : \n   social : \n     -   type :   github \n       link :   https://github.com/squidfunk \n     -   type :   twitter \n       link :   https://twitter.com/squidfunk \n     -   type :   linkedin \n       link :   https://linkedin.com/in/squidfunk  # Google Analytics  google_analytics : \n   -   UA-XXXXXXXX-X \n   -   auto  # Extensions  markdown_extensions : \n   -   admonition \n   -   codehilite : \n       guess_lang :   false \n   -   toc : \n       permalink :   true", 
            "title": "Full example"
        }, 
        {
            "location": "/aurelia/technicalities/", 
            "text": "Font Awesome in Aurelia project\n\n\nAdd new \nprepare-font-awesome.ts\n task file to \naurelia_project/tasks\n:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\nimport\n \n*\n \nas\n \ngulp\n \nfrom\n \ngulp\n;\n\n\nimport\n \n*\n \nas\n \nmerge\n \nfrom\n \nmerge-stream\n;\n\n\nimport\n \n*\n \nas\n \nchangedInPlace\n \nfrom\n \ngulp-changed-in-place\n;\n\n\nimport\n \n*\n \nas\n \nproject\n \nfrom\n \n../aurelia.json\n;\n\n\n\nexport\n \ndefault\n \nfunction\n \nprepareFontAwesome\n()\n \n{\n\n  \nconst\n \nsource\n \n=\n \nnode_modules/font-awesome\n;\n\n  \nconst\n \ncssSource\n \n=\n \n`\n${\nsource\n}\n/css/font-awesome.min.css`\n;\n\n  \nconst\n \ncssDest\n \n=\n \n`\n${\nproject\n.\nplatform\n.\noutput\n}\n/css`\n;\n\n  \nconst\n \nfontsSource\n \n=\n \n`\n${\nsource\n}\n/fonts/*`\n;\n\n  \nconst\n \nfontsDest\n \n=\n \n`\n${\nproject\n.\nplatform\n.\noutput\n}\n/fonts`\n;\n\n\n  \nconst\n \ntaskCss\n \n=\n \ngulp\n.\nsrc\n(\ncssSource\n)\n\n    \n.\npipe\n(\nchangedInPlace\n({\n \nfirstPass\n:\n \ntrue\n \n}))\n\n    \n.\npipe\n(\ngulp\n.\ndest\n(\ncssDest\n));\n\n\n  \nconst\n \ntaskFonts\n \n=\n \ngulp\n.\nsrc\n(\nfontsSource\n)\n\n    \n.\npipe\n(\nchangedInPlace\n({\n \nfirstPass\n:\n \ntrue\n \n}))\n\n    \n.\npipe\n(\ngulp\n.\ndest\n(\nfontsDest\n));\n\n\n  \nreturn\n \nmerge\n(\ntaskCss\n,\n \ntaskFonts\n);\n\n\n};\n\n\n\n\n\n\n\nAdd this new task to \naurelia_project/tasks/build.ts\n. You will get something like this:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\nimport\n \n*\n \nas\n \ngulp\n \nfrom\n \ngulp\n;\n\n\nimport\n \ntranspile\n \nfrom\n \n./transpile\n;\n\n\nimport\n \nprocessMarkup\n \nfrom\n \n./process-markup\n;\n\n\nimport\n \nprocessCSS\n \nfrom\n \n./process-css\n;\n\n\nimport\n \n{\n \nbuild\n \n}\n \nfrom\n \naurelia-cli\n;\n\n\nimport\n \n*\n \nas\n \nproject\n \nfrom\n \n../aurelia.json\n;\n\n\nimport\n \nprepareFontAwesome\n \nfrom\n \n./prepare-font-awesome\n;\n \n// our custom task\n\n\n\nexport\n \ndefault\n \ngulp\n.\nseries\n(\n\n  \nreadProjectConfiguration\n,\n\n  \ngulp\n.\nparallel\n(\n\n    \ntranspile\n,\n\n    \nprocessMarkup\n,\n\n    \nprocessCSS\n,\n\n    \nprepareFontAwesome\n \n// our custom task\n\n  \n),\n\n  \nwriteBundles\n\n\n);\n\n\n\nfunction\n \nreadProjectConfiguration\n()\n \n{\n\n  \nreturn\n \nbuild\n.\nsrc\n(\nproject\n);\n\n\n}\n\n\n\nfunction\n \nwriteBundles\n()\n \n{\n\n  \nreturn\n \nbuild\n.\ndest\n();\n\n\n}\n\n\n\n\n\n\n\nFinally, add\n\n\n1\nlink\n \nrel\n=\nstylesheet\n \nhref\n=\nscripts/css/font-awesome.min.css\n\n\n\n\n\n\n\nto \nwwwroot/index.html\n. Now, if you run \nau build\n, you will see two new directories created under \nwwwwroot/scripts\n:\n\n\n\n\ncss\n\n\nfonts\n\n\n\n\nand inside these folders the \nFont Awesome\n stylesheet and fonts.", 
            "title": "Some Technical Notes"
        }, 
        {
            "location": "/aurelia/technicalities/#font-awesome-in-aurelia-project", 
            "text": "Add new  prepare-font-awesome.ts  task file to  aurelia_project/tasks :   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22 import   *   as   gulp   from   gulp ;  import   *   as   merge   from   merge-stream ;  import   *   as   changedInPlace   from   gulp-changed-in-place ;  import   *   as   project   from   ../aurelia.json ;  export   default   function   prepareFontAwesome ()   { \n   const   source   =   node_modules/font-awesome ; \n   const   cssSource   =   ` ${ source } /css/font-awesome.min.css` ; \n   const   cssDest   =   ` ${ project . platform . output } /css` ; \n   const   fontsSource   =   ` ${ source } /fonts/*` ; \n   const   fontsDest   =   ` ${ project . platform . output } /fonts` ; \n\n   const   taskCss   =   gulp . src ( cssSource ) \n     . pipe ( changedInPlace ({   firstPass :   true   })) \n     . pipe ( gulp . dest ( cssDest )); \n\n   const   taskFonts   =   gulp . src ( fontsSource ) \n     . pipe ( changedInPlace ({   firstPass :   true   })) \n     . pipe ( gulp . dest ( fontsDest )); \n\n   return   merge ( taskCss ,   taskFonts );  };    Add this new task to  aurelia_project/tasks/build.ts . You will get something like this:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26 import   *   as   gulp   from   gulp ;  import   transpile   from   ./transpile ;  import   processMarkup   from   ./process-markup ;  import   processCSS   from   ./process-css ;  import   {   build   }   from   aurelia-cli ;  import   *   as   project   from   ../aurelia.json ;  import   prepareFontAwesome   from   ./prepare-font-awesome ;   // our custom task  export   default   gulp . series ( \n   readProjectConfiguration , \n   gulp . parallel ( \n     transpile , \n     processMarkup , \n     processCSS , \n     prepareFontAwesome   // our custom task \n   ), \n   writeBundles  );  function   readProjectConfiguration ()   { \n   return   build . src ( project );  }  function   writeBundles ()   { \n   return   build . dest ();  }    Finally, add  1 link   rel = stylesheet   href = scripts/css/font-awesome.min.css    to  wwwroot/index.html . Now, if you run  au build , you will see two new directories created under  wwwwroot/scripts :   css  fonts   and inside these folders the  Font Awesome  stylesheet and fonts.", 
            "title": "Font Awesome in Aurelia project"
        }, 
        {
            "location": "/git/gitflow/", 
            "text": "Introduction\n\n\nInstallation\n\n\nPrerequisites\n\n\nPrepare the GitFlow local repository\n\n\nInstall GitFlow\n\n\nTest GitFlow installation\n\n\n\n\n\n\n\n\n\n\nIntroduction\n\n\nGitFlow\n is a Git Workflow Extension. The following diagram gives a good idea how it works.\n\n\n\n\n\n\nInstallation\n\n\nPrerequisites\n\n\nMake sure you have \nGit\n installed. Note the path to the \nGit\n directory. In this manual, we will use \nC:\\Program Files\\Git\n.\n\n\nPrepare the GitFlow local repository\n\n\n\n\nExternal dependencies\n\n\n\n\nSubmodule dependency on \nshFlags\n\n\n3 files from the \nutil-linux-package\n\n\n\n\n\n\nGo to the \nutil-linux-ng for Windows\n website. Download the \nBinaries\n and \nDependencies\n in zip-format. Retrieve \ngetopt.exe\n file from the \nbin\n folder in the \nBinaries\n. Retrieve \nlibintl3.dll\n, and \nlibiconv2.dll\n from the \nbin\n folder in the \nDependencies\n packages. (This \nlink\n has them all in one place.)\n\n\nCopy all three files to the \nbin\n folder of your \nGit\n installation, e.g. \nC:\\Program Files\\Git\\bin\n.\n\n\nOpen an Administrator command window and run these commands (make sure you also get the right diagnostic messages):\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\ngit clone https://github.com/nvie/gitflow.git\n\n\ncd\n gitflow\n\ngit submodule\n-2fb06af13de884e9680f14a00c82e52a67c867f1 shFlags\n\ngit submodule init\nSubmodule \nshFlags\n \n(\ngit://github.com/nvie/shFlags.git\n)\n registered \nfor\n path \nshFlags\n\n\ngit submodule update\nCloning into \nshFlags\n...\nremote: Counting objects: \n454\n, \ndone\n.\nremote: Compressing objects: \n100\n% \n(\n55\n/55\n)\n, \ndone\n.\nremote: Total \n454\n \n(\ndelta \n389\n)\n, reused \n454\n \n(\ndelta \n389\n)\n\nReceiving objects: \n100\n% \n(\n454\n/454\n)\n, \n101\n.19 KiB, \ndone\n.\nResolving deltas: \n100\n% \n(\n389\n/389\n)\n, \ndone\n.\nSubmodule path \nshFlags\n: checked out \n2fb06af13de884e9680f14a00c82e52a67c867f1\n\n\ngit submodule status\n 2fb06af13de884e9680f14a00c82e52a67c867f1 shFlags \n(\n1\n.0.3\n)\n\n\n\n\n\n\n\nInstall GitFlow\n\n\nRun the following commands with the correct path to your \nGit\n installation:\n\n\n1\n2\ncd\n contrib\nmsysgit-install.cmd \nC:\\Program Files\\Git\n\n\n\n\n\n\n\nTest GitFlow installation\n\n\nTest the installation by running\n\n\n1\ngit flow \nhelp\n\n\n\n\n\n\n\nYou should see something like this:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\nusage: git flow \nsubcommand\n\n\nAvailable subcommands are:\n   init      Initialize a new git repo with support for the branching model.\n   feature   Manage your feature branches.\n   bugfix    Manage your bugfix branches.\n   release   Manage your release branches.\n   hotfix    Manage your hotfix branches.\n   support   Manage your support branches.\n   version   Shows version information.\n   config    Manage your git-flow configuration.\n   log       Show log deviating from base branch.\n\nTry \ngit flow \nsubcommand\n help\n for details.", 
            "title": "GitFlow"
        }, 
        {
            "location": "/git/gitflow/#introduction", 
            "text": "GitFlow  is a Git Workflow Extension. The following diagram gives a good idea how it works.", 
            "title": "Introduction"
        }, 
        {
            "location": "/git/gitflow/#installation", 
            "text": "", 
            "title": "Installation"
        }, 
        {
            "location": "/git/gitflow/#prerequisites", 
            "text": "Make sure you have  Git  installed. Note the path to the  Git  directory. In this manual, we will use  C:\\Program Files\\Git .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/git/gitflow/#prepare-the-gitflow-local-repository", 
            "text": "External dependencies   Submodule dependency on  shFlags  3 files from the  util-linux-package    Go to the  util-linux-ng for Windows  website. Download the  Binaries  and  Dependencies  in zip-format. Retrieve  getopt.exe  file from the  bin  folder in the  Binaries . Retrieve  libintl3.dll , and  libiconv2.dll  from the  bin  folder in the  Dependencies  packages. (This  link  has them all in one place.)  Copy all three files to the  bin  folder of your  Git  installation, e.g.  C:\\Program Files\\Git\\bin .  Open an Administrator command window and run these commands (make sure you also get the right diagnostic messages):   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21 git clone https://github.com/nvie/gitflow.git cd  gitflow\n\ngit submodule\n-2fb06af13de884e9680f14a00c82e52a67c867f1 shFlags\n\ngit submodule init\nSubmodule  shFlags   ( git://github.com/nvie/shFlags.git )  registered  for  path  shFlags \n\ngit submodule update\nCloning into  shFlags ...\nremote: Counting objects:  454 ,  done .\nremote: Compressing objects:  100 %  ( 55 /55 ) ,  done .\nremote: Total  454   ( delta  389 ) , reused  454   ( delta  389 ) \nReceiving objects:  100 %  ( 454 /454 ) ,  101 .19 KiB,  done .\nResolving deltas:  100 %  ( 389 /389 ) ,  done .\nSubmodule path  shFlags : checked out  2fb06af13de884e9680f14a00c82e52a67c867f1 \n\ngit submodule status\n 2fb06af13de884e9680f14a00c82e52a67c867f1 shFlags  ( 1 .0.3 )", 
            "title": "Prepare the GitFlow local repository"
        }, 
        {
            "location": "/git/gitflow/#install-gitflow", 
            "text": "Run the following commands with the correct path to your  Git  installation:  1\n2 cd  contrib\nmsysgit-install.cmd  C:\\Program Files\\Git", 
            "title": "Install GitFlow"
        }, 
        {
            "location": "/git/gitflow/#test-gitflow-installation", 
            "text": "Test the installation by running  1 git flow  help    You should see something like this:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14 usage: git flow  subcommand \n\nAvailable subcommands are:\n   init      Initialize a new git repo with support for the branching model.\n   feature   Manage your feature branches.\n   bugfix    Manage your bugfix branches.\n   release   Manage your release branches.\n   hotfix    Manage your hotfix branches.\n   support   Manage your support branches.\n   version   Shows version information.\n   config    Manage your git-flow configuration.\n   log       Show log deviating from base branch.\n\nTry  git flow  subcommand  help  for details.", 
            "title": "Test GitFlow installation"
        }, 
        {
            "location": "/git/styling/", 
            "text": "Powerline Fonts\n\n\nCmder\n\n\nMain Font\n\n\nColor Scheme\n\n\n\n\n\n\n\n\n\n\nPowerline Fonts\n\n\nTaken from the \nPowerline fonts\n repository. Start by cloning:\n\n\n1\n2\ngit clone https://github.com/powerline/fonts.git\n\ncd\n fonts\n\n\n\n\n\n\nIn \nbash\n prompt install the fonts like this:\n\n\n1\n./install.sh\n\n\n\n\n\n\nand in \nPowershell\n as Administrator like this:\n\n\n1\n./install.ps1\n\n\n\n\n\n\nInstall for Python:\n\n\n1\npip install powerline-status\n\n\n\n\n\n\nor just for the current user:\n\n\n1\npip install --user powerline-status\n\n\n\n\n\n\n\n\nCmder\n\n\nMain Font\n\n\nI like these fonts for the terminal:\n\n\n\n\nRoboto Mono for Powerline\n\n\nDroid Sans Mono Slashed for Powerline\n\n\nAnonymice Powerline\n\n\n\n\nColor Scheme\n\n\nI like \nMurena Scheme\n with some tweaks in \nFeatures/Colors\n:\n\n\n\n\n\n\n\n\nPosition\n\n\nColor Code\n\n\nRole\n\n\n\n\n\n\n\n\n\n\n0\n\n\n0 43 54\n\n\nscreen background color\n\n\n\n\n\n\nidem\n\n\n38 42 47\n\n\nidem\n\n\n\n\n\n\n\n\n0 65 100\n\n\npath background color\n\n\n\n\n\n\n2\n\n\n60 154 6\n\n\nclean branch - green\n\n\n\n\n\n\n6/3\n\n\n196 160 0\n\n\ndirty branch - yellow", 
            "title": "Git Prompt Styling"
        }, 
        {
            "location": "/git/styling/#powerline-fonts", 
            "text": "Taken from the  Powerline fonts  repository. Start by cloning:  1\n2 git clone https://github.com/powerline/fonts.git cd  fonts   In  bash  prompt install the fonts like this:  1 ./install.sh   and in  Powershell  as Administrator like this:  1 ./install.ps1   Install for Python:  1 pip install powerline-status   or just for the current user:  1 pip install --user powerline-status", 
            "title": "Powerline Fonts"
        }, 
        {
            "location": "/git/styling/#cmder", 
            "text": "", 
            "title": "Cmder"
        }, 
        {
            "location": "/git/styling/#main-font", 
            "text": "I like these fonts for the terminal:   Roboto Mono for Powerline  Droid Sans Mono Slashed for Powerline  Anonymice Powerline", 
            "title": "Main Font"
        }, 
        {
            "location": "/git/styling/#color-scheme", 
            "text": "I like  Murena Scheme  with some tweaks in  Features/Colors :     Position  Color Code  Role      0  0 43 54  screen background color    idem  38 42 47  idem     0 65 100  path background color    2  60 154 6  clean branch - green    6/3  196 160 0  dirty branch - yellow", 
            "title": "Color Scheme"
        }, 
        {
            "location": "/git/ssh/", 
            "text": "Requirements\n\n\nManage SSH keys on your local Windows machine\n\n\nAdd a new SSH key via PUTTYGEN\n\n\nAdd a new SSH key via SSH-KEYGEN\n\n\nAdd config file for SSH\n\n\nTest the connection\n\n\n\n\n\n\nHow to clone the remote private repo via SSH\n\n\n\n\n\n\nRequirements\n\n\n\n\nThe latest (full) version of \nGit Extenstions\n is installed\n\n\ngit --version\n shows no errors; if not, add the location of the \nGit\n folder to the \nPATH\n\n\nThere exists the \nGIT_SSH\n Windows environment variable (necessary for \nplink\n): \nC:\\Program Files (x86)\\GitExtensions\\PuTTY\n\n\nPuTTY\n directory is on the system \nPATH\n: \nC:\\Program Files (x86)\\GitExtensions\\PuTTY\n\n\nwhere ssh\n command shows the location of \nssh.exe\n; if not, add the location of the \nGit\\usr\\bin\n folder to the system \nPATH\n\n\n\n\n\n\nManage SSH keys on your local Windows machine\n\n\nSSH keys are stored locally in \n%USERPROFILE%/.ssh\n directory. If it does not exist, create one.\n\n\nAdd a new SSH key via PUTTYGEN\n\n\n\n\nOpen your command prompt and type \nputtygen\n. This will open the generator screen.\n\n\nClick \nGenerate\n to generate a new key and move your mouse across the white area.\n\n\nType in the passphrase (\nremember it wel!\n) and save the private key to \n%USERPROFILE%\\.ssh\n directory as \nid_rsa.ppk\n.\n\n\n\n\nAlso, save the \nOpenSSH\n version of the key as \nid_rsa\n file via the top menu \nConversions\n -\n \nExport OpenSSH key\n.\n\n\n\n\nAdd a new SSH key via SSH-KEYGEN\n\n\n\n\nAlternatively, you can generate the key via \nssh-keygen\n command\n\n\nSave the key as \nid_rsa\n file in \n.ssh\n directory\n\n\nOpen \nputtygen\n and load the generated key\n\n\nSave the corresponding private key as above for Puttygen\n\n\n\n\nAdd config file for SSH\n\n\n\n\nIn your \n.ssh\n directory create an empty \nconfig\n textfile (no extension)\n\n\nFor your remote host, e.g. BitBucket, add the configuration information. It will look something like this:\n\n\n1\n2\n3\n4\n5\n    Host BITBUCKET\n    Hostname bitbucket.org\n    User your-user-name-on-bitbucket\n    PubKeyAuthentication yes\n    IdentityFile id_rsa\n\n\n\n\n\n\n\nTest the connection\n\n\n\n\nrun \nssh -T git@bitbucket.org\n\n\nyou may see something like this:\n\n\n1\n2\n3\n4\n5\n    key_load_public: invalid format\n    Enter passphrase for key \n/c/Users/Andre/.ssh/id_rsa\n:\n    logged in as Madrusnl.\n\n    You can use git or hg to connect to Bitbucket. Shell access is disabled.\n\n\n\n\n\nyou may ignore the \ninvalid format\n error if you see the rest\n\n\notherwise you can do some \ntroubleshooting\n:\n\n\nuse \n-vvv\n option: \nssh -T git@bitbucket.org -vvv\n\n\nmake sure you have registered your PUBLIC key (.pub) on the (BitBucket) server\n\n\nmake sure your \nIdentiyFile\n variable in the \nconfig\n file points to your PRIVATE key (without extension).\n\n\n\n\n\n\n\n\n\n\nHow to clone the remote private repo via SSH\n\n\n\n\nmake sure you have the private key for the remote repo in \n.ssh\n folder, e.g. \nid_rsa.ppk\n (otherwise create it as described hereabove)\n\n\ncreate the local folder to which you wish to clone the remote repo\n\n\ninitialize the empty git repo in it by \ngit init\n\n\nopen the repo with \nGit Extensions\n\n\nin its menu, go to \nRepository\n, \nRemote repositories...\n and create a new remote repository. Call it \norigin\n (or any other name you like). \n\n\nCopy the SSH url of the BitBucket repo and paste it in the \nUrl\n field\n\n\nFor the \nPuTTY SSH\n field, browse to the private key in \n.ssh\n directory and pick it up\n\n\n\n\nClick on \nLoad SSH key\n and type in your passphrase for the private key\n\n\nTest connection with \nTest connection\n\n\nIf everything is ok, save changes and close\n\n\nClick on the light blue down arrow, choose \nPull\n, fill in the right remote branch, e.g. \nmaster\n and choose \nMerge remote branch into current branch\n\n\n\n\nClick the \nPull\n button\n\n\nIf everything went fine, you should now see the branch tree with all the commits", 
            "title": "Set up SSH"
        }, 
        {
            "location": "/git/ssh/#requirements", 
            "text": "The latest (full) version of  Git Extenstions  is installed  git --version  shows no errors; if not, add the location of the  Git  folder to the  PATH  There exists the  GIT_SSH  Windows environment variable (necessary for  plink ):  C:\\Program Files (x86)\\GitExtensions\\PuTTY  PuTTY  directory is on the system  PATH :  C:\\Program Files (x86)\\GitExtensions\\PuTTY  where ssh  command shows the location of  ssh.exe ; if not, add the location of the  Git\\usr\\bin  folder to the system  PATH", 
            "title": "Requirements"
        }, 
        {
            "location": "/git/ssh/#manage-ssh-keys-on-your-local-windows-machine", 
            "text": "SSH keys are stored locally in  %USERPROFILE%/.ssh  directory. If it does not exist, create one.", 
            "title": "Manage SSH keys on your local Windows machine"
        }, 
        {
            "location": "/git/ssh/#add-a-new-ssh-key-via-puttygen", 
            "text": "Open your command prompt and type  puttygen . This will open the generator screen.  Click  Generate  to generate a new key and move your mouse across the white area.  Type in the passphrase ( remember it wel! ) and save the private key to  %USERPROFILE%\\.ssh  directory as  id_rsa.ppk .   Also, save the  OpenSSH  version of the key as  id_rsa  file via the top menu  Conversions  -   Export OpenSSH key .", 
            "title": "Add a new SSH key via PUTTYGEN"
        }, 
        {
            "location": "/git/ssh/#add-a-new-ssh-key-via-ssh-keygen", 
            "text": "Alternatively, you can generate the key via  ssh-keygen  command  Save the key as  id_rsa  file in  .ssh  directory  Open  puttygen  and load the generated key  Save the corresponding private key as above for Puttygen", 
            "title": "Add a new SSH key via SSH-KEYGEN"
        }, 
        {
            "location": "/git/ssh/#add-config-file-for-ssh", 
            "text": "In your  .ssh  directory create an empty  config  textfile (no extension)  For your remote host, e.g. BitBucket, add the configuration information. It will look something like this:  1\n2\n3\n4\n5     Host BITBUCKET\n    Hostname bitbucket.org\n    User your-user-name-on-bitbucket\n    PubKeyAuthentication yes\n    IdentityFile id_rsa", 
            "title": "Add config file for SSH"
        }, 
        {
            "location": "/git/ssh/#test-the-connection", 
            "text": "run  ssh -T git@bitbucket.org  you may see something like this:  1\n2\n3\n4\n5     key_load_public: invalid format\n    Enter passphrase for key  /c/Users/Andre/.ssh/id_rsa :\n    logged in as Madrusnl.\n\n    You can use git or hg to connect to Bitbucket. Shell access is disabled.   you may ignore the  invalid format  error if you see the rest  otherwise you can do some  troubleshooting :  use  -vvv  option:  ssh -T git@bitbucket.org -vvv  make sure you have registered your PUBLIC key (.pub) on the (BitBucket) server  make sure your  IdentiyFile  variable in the  config  file points to your PRIVATE key (without extension).", 
            "title": "Test the connection"
        }, 
        {
            "location": "/git/ssh/#how-to-clone-the-remote-private-repo-via-ssh", 
            "text": "make sure you have the private key for the remote repo in  .ssh  folder, e.g.  id_rsa.ppk  (otherwise create it as described hereabove)  create the local folder to which you wish to clone the remote repo  initialize the empty git repo in it by  git init  open the repo with  Git Extensions  in its menu, go to  Repository ,  Remote repositories...  and create a new remote repository. Call it  origin  (or any other name you like).   Copy the SSH url of the BitBucket repo and paste it in the  Url  field  For the  PuTTY SSH  field, browse to the private key in  .ssh  directory and pick it up   Click on  Load SSH key  and type in your passphrase for the private key  Test connection with  Test connection  If everything is ok, save changes and close  Click on the light blue down arrow, choose  Pull , fill in the right remote branch, e.g.  master  and choose  Merge remote branch into current branch   Click the  Pull  button  If everything went fine, you should now see the branch tree with all the commits", 
            "title": "How to clone the remote private repo via SSH"
        }, 
        {
            "location": "/git/tools/", 
            "text": "ConEmu\n\n\nShow Branch Name on Command Line\n\n\nAdd ConEmu to the Windows context menu\n\n\n\n\n\n\nCmder\n\n\nEnvironment variables\n\n\nShortcut to open Cmder in a chosen folder\n\n\nConfiguring Tasks\n\n\nAliases\n\n\nStandard Aliases\n\n\nHow to update ConEmu within Cmder\n\n\nLinks\n\n\n\n\n\n\nFar Manager\n\n\nAdd Far Manager to the Windows context menu\n\n\n\n\n\n\nPOSH-GIT for PowerShell\n\n\nInstallation\n\n\nPowerShell\n\n\nChocolatey\n\n\nUpdates\n\n\n\n\n\n\nHow to use\n\n\nUse it with Integrated Terminal in VS Code\n\n\n\n\n\n\n\n\n\n\nConEmu\n\n\nHere is the main link to \nConemu\n website. \n\n\nShow Branch Name on Command Line\n\n\nRun \nGitShowBranch /i\n to install showing branch, \nGitShowBranch /u\n to uninstall.\n\n\nAlso, you may run your \ncmd\n as following (within Task contents or ConEmu\ns Command line)\n\n\n1\ncmd /k ver \n GitShowBranch /i\n\n\n\n\n\n\n\n\nDon\nt forget to recreate the console window!\n\n\nIf you changed the command line in the settings, you have to completely recreate the console window. Otherwise, you will not see the changes.\n\n\n\n\n\n\nAdd ConEmu to the Windows context menu\n\n\nIt is convenient to be able to open the \nConEmu\n console at the current location. You would then want to be able to either\n\n\n\n\nright click either on the folder itself, or \n\n\nright click inside the white area within the folder open in the \nWindows Explorer\n.\n\n\n\n\nCreate (if not already created by the \nConEmu\n installation itself) the same group of keys and string values in the \nWindows Registry\n in the following two locations respectively:\n\n\n\n\nHCR/Directory/shell\n\n\nHCR/Directory/Background/shell\n\n\n\n\nKey: \nConEmu Here\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nData\n\n\n\n\n\n\n\n\n\n\n(Default)\n\n\nREG_SZ\n\n\n(value not set)\n\n\n\n\n\n\nIcon\n\n\nREG_SZ\n\n\nC:\\Program Files\\ConEmu\\ConEmu64.exe,0\n\n\n\n\n\n\n\n\nSubkey: \ncommand\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nData\n\n\n\n\n\n\n\n\n\n\n(Default)\n\n\nREG_SZ\n\n\nC:\\Program Files\\ConEmu\\ConEmu64.exe\n -here -run {cmd}\n-cur_console:n\n\n\n\n\n\n\n\n\nYou can also create the \nAdmin\n version of the same command with minimal changes:\n\n\n\n\nKey: \nConEmu Here (Admin)\n\n\nreplace \n:n\n with \n:a\n at the end of the \ncommand\n \nData\n value: \n-cur_console:a\n\n\n\n\n\n\nTODO\n\n\nIt would also be nice to be able to open the \nConEmu\n folder from within the \nFar Manager\n window.\n\n\n\n\n\n\nCmder\n\n\nThis tool combines most of the features of \nConemu\n and \nClink\n.\n\n\nEnvironment variables\n\n\n\n\nNo spaces in the path names!\n\n\nMake sure there are no spaces in the path. If necessary, substitute those paths with their short versions. You can find them by running \ndir /X\n in their parent directory.\n\n\n\n\nAdd the following environment system variables to Windows according to your specific situation:\n\n\nCMDER_ROOT = C:\\PROGRA~1\\Cmder\n\n\nAdd the path to \nCmder.exe\n to the \nPATH\n variable:\n\n\nC:\\PROGRA~1\\Cmder\n\n\nShortcut to open Cmder in a chosen folder\n\n\n\n\nOpen a terminal as an \nAdministrator\n\n\nNavigate to the directory in which you have placed \nCmder\n\n\nExecute \n.\\cmder.exe /REGISTER ALL\n. If you get \nAccess Denied\n ensure you are executing the command in an \nAdministrator\n prompt\n\n\n\n\nIn the Windows explorer window right click in or on a directory to see \nCmder Here\n in the context menu.\n\n\nConfiguring Tasks\n\n\nHere is a good example of how to configure the environment for editing files not related to Visual Studio and .NET. Another neat functionality are customized Tasks. Use those to store different project workspaces. One task equals one workspace. Thanks to that it is possible to easily start another \nproject\n and initialize it by opening specific folders and specific files in Vim. It is a lot faster than doing everything manually.\n\n\nIn the Settings navigate to \nStartup -\n Tasks\n and create a new predefined task with a \n+\n sign. Then add this code:\n\n\n1\n2\n3\n4\n-new_console:d:C:\n\\U\nsers\n\\m\nfranc\n\\D\nropbox \n%ProgramFiles(x86)%\\Vim\\vim80\\vim.exe\n /k\n-new_console:d:D:\n\\ \n%ProgramFiles%\\Vim\\vim74\\vim.exe\n /k -cur_console:n\n-cur_console:d:D:\n\\ \n%ProgramFiles%\\Git\\bin\\sh.exe\n --login -i -cur_console:n:sT25V\n-cur_console:d:D:\n\\ \n%ProgramFiles%\\Git\\bin\\sh.exe\n --login -i cur_console:n:sT66H cmd.exe -new_console:d:D:\n\\ \n-i -cur_console:n:sT50H\n\n\n\n\n\n\nWhat does those commands do? \n\n\n\n\nCreates new screen and opens Vim in my Dropbox folder context\n\n\nCreates new screen with Vim pointing to D:\\\n\n\nInitializes shell in this new window and splits current screen into \n75%/25% horizontaly\n\n\nInitializes shell in new (25%) window and splits it up into \n33.3%/66.6% vertically\n. Then initializes shell in the new (66.6%) window and splits it up into \n50%/50% vertically\n.\n\n\n\n\nAliases\n\n\nYou can create an alias to any command by an \nalias\n command, e.g.:\n\n\n1\nalias\n \npush\n=\ngit push -u \n$*\n\n\n\n\n\n\n\n\n\nNo space in between!\n\n\nMake sure there is no space between the alias and the equality sign \n=\n\n\n\n\nUndo the alias by \nunalias push\n.\n\n\nThe aliases can be found in \nconfig\n subdirectory of the cmder install directory in the \nuser-aliases.cmd\n file or by running \nalias\n command with no parameters.\n\n\nStandard Aliases\n\n\n\n\ncmderr\n - open cmder window in the cmder install directory, e.g. \nC:\\Program Files\\Cmder\n\n\nhistory\n - show latest commands\n\n\n\n\nHow to update ConEmu within Cmder\n\n\nMaximus5\n, the author of Cmder, explains how to update ConEmu to a new version. Current Cmder can contain an older ConEmu version. To update ConEmu, get the new package from the \nConEmu website\n and copy its content to \nyour cmder installation\n/vendor/conemu-maximus5 folder.\n\n\nLinks\n\n\n\n\nCmder: Super Command Line Tool Window\n\n\n\n\n\n\nFar Manager\n\n\nAdd Far Manager to the Windows context menu\n\n\nIt is convenient to be able to open the \nFar Manager\n at the current location. You would then want to be able to either\n\n\n\n\nright click either on the folder itself, or \n\n\nright click inside the white area within the folder open in the \nWindows Explorer\n.\n\n\n\n\nCreate or rename (if already created by the \nFar Manager\n installation) the same group of keys and string values in the \nWindows Registry\n in the following two locations respectively:\n\n\n\n\nHCR/Directory/shell\n\n\nHCR/Directory/Background/shell\n\n\n\n\nKey: \nFar Here\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nData\n\n\n\n\n\n\n\n\n\n\n(Default)\n\n\nREG_SZ\n\n\n(value not set)\n\n\n\n\n\n\nIcon\n\n\nREG_SZ\n\n\nC:\\Program Files\\Far Manager\\Far.exe,0\n\n\n\n\n\n\n\n\nSubkey: \ncommand\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nData\n\n\n\n\n\n\n\n\n\n\n(Default)\n\n\nREG_SZ\n\n\nC:\\Program Files\\Far Manager\\Far.exe\n \n%\nX\n \n%\nX\n\n\n\n\n\n\n\n\n\n\nReplace X with a number!\n\n\nIn the \nshell\n, replace X with \n1\n and in the \nBackground/shell\n with \n2\n.\n\n\n\n\n\n\nPOSH-GIT for PowerShell\n\n\nPOSH-GIT\n is a PowerShell module that shows the current branch of the git repository and understands git commands.\n\n\nInstallation\n\n\nThe easiest way is to use PowerShell of Chocolatey.\n\n\nPowerShell\n\n\n1\nPowerShellGet\n\\\nInstall-Module\n \nposh-git\n \n-Scope\n \nCurrentUser\n\n\n\n\n\n\n\nNote:\n If you get an error message from \nInstall-Module\n about NuGet being required to interact with NuGet-based repositories, execute the following commands to bootstrap the NuGet provider:\n\n\n1\n2\nInstall-PackageProvider\n \nNuGet\n \n-Force\n\n\nImport-PackageProvider\n \nNuGet\n \n-Force\n\n\n\n\n\n\n\nThen retry the \nInstall-Module\n command above.\n\n\nChocolatey\n\n\n1\nchoco install poshgit\n\n\n\n\n\n\nUpdates\n\n\nUpdate to a newer version by executing the command:\n\n\n1\nUpdate-Module\n \nposh-git\n\n\n\n\n\n\n\nHow to use\n\n\nOpen the PowerShell command prompt and run:\n\n\n1\nImport-Module posh-git\n\n\n\n\n\n\nIf you are lazy to do it every time, add the command to your profile. Here is how.\n\n\n\n\nstart PowerShell command prompt and run \n$profile\n\n\nyou will see the path and name of your profile file, e.g. \nC:\\Users\\YourUserName\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1\n\n\nif this file does not exist, create it\n\n\nadd \nImport-Module posh-git\n to that file\n\n\n\n\nUse it with Integrated Terminal in VS Code\n\n\nAdd the following setting to the VS Code User Settings:\n\n\n1\nterminal.integrated.shell.windows\n:\n \nC:\\\\Windows\\\\System\n32\n\\\\WindowsPowerShell\\\\v\n1.0\n\\\\powershell.exe,\n\n\n\n\n\n\n\nToggle the Integrated Terminal window with \nCtrl\n+\n`\n.", 
            "title": "Git Command Line Tools"
        }, 
        {
            "location": "/git/tools/#conemu", 
            "text": "Here is the main link to  Conemu  website.", 
            "title": "ConEmu"
        }, 
        {
            "location": "/git/tools/#show-branch-name-on-command-line", 
            "text": "Run  GitShowBranch /i  to install showing branch,  GitShowBranch /u  to uninstall.  Also, you may run your  cmd  as following (within Task contents or ConEmu s Command line)  1 cmd /k ver   GitShowBranch /i    Don t forget to recreate the console window!  If you changed the command line in the settings, you have to completely recreate the console window. Otherwise, you will not see the changes.", 
            "title": "Show Branch Name on Command Line"
        }, 
        {
            "location": "/git/tools/#add-conemu-to-the-windows-context-menu", 
            "text": "It is convenient to be able to open the  ConEmu  console at the current location. You would then want to be able to either   right click either on the folder itself, or   right click inside the white area within the folder open in the  Windows Explorer .   Create (if not already created by the  ConEmu  installation itself) the same group of keys and string values in the  Windows Registry  in the following two locations respectively:   HCR/Directory/shell  HCR/Directory/Background/shell   Key:  ConEmu Here     Name  Type  Data      (Default)  REG_SZ  (value not set)    Icon  REG_SZ  C:\\Program Files\\ConEmu\\ConEmu64.exe,0     Subkey:  command     Name  Type  Data      (Default)  REG_SZ  C:\\Program Files\\ConEmu\\ConEmu64.exe  -here -run {cmd} -cur_console:n     You can also create the  Admin  version of the same command with minimal changes:   Key:  ConEmu Here (Admin)  replace  :n  with  :a  at the end of the  command   Data  value:  -cur_console:a    TODO  It would also be nice to be able to open the  ConEmu  folder from within the  Far Manager  window.", 
            "title": "Add ConEmu to the Windows context menu"
        }, 
        {
            "location": "/git/tools/#cmder", 
            "text": "This tool combines most of the features of  Conemu  and  Clink .", 
            "title": "Cmder"
        }, 
        {
            "location": "/git/tools/#environment-variables", 
            "text": "No spaces in the path names!  Make sure there are no spaces in the path. If necessary, substitute those paths with their short versions. You can find them by running  dir /X  in their parent directory.   Add the following environment system variables to Windows according to your specific situation:  CMDER_ROOT = C:\\PROGRA~1\\Cmder  Add the path to  Cmder.exe  to the  PATH  variable:  C:\\PROGRA~1\\Cmder", 
            "title": "Environment variables"
        }, 
        {
            "location": "/git/tools/#shortcut-to-open-cmder-in-a-chosen-folder", 
            "text": "Open a terminal as an  Administrator  Navigate to the directory in which you have placed  Cmder  Execute  .\\cmder.exe /REGISTER ALL . If you get  Access Denied  ensure you are executing the command in an  Administrator  prompt   In the Windows explorer window right click in or on a directory to see  Cmder Here  in the context menu.", 
            "title": "Shortcut to open Cmder in a chosen folder"
        }, 
        {
            "location": "/git/tools/#configuring-tasks", 
            "text": "Here is a good example of how to configure the environment for editing files not related to Visual Studio and .NET. Another neat functionality are customized Tasks. Use those to store different project workspaces. One task equals one workspace. Thanks to that it is possible to easily start another  project  and initialize it by opening specific folders and specific files in Vim. It is a lot faster than doing everything manually.  In the Settings navigate to  Startup -  Tasks  and create a new predefined task with a  +  sign. Then add this code:  1\n2\n3\n4 -new_console:d:C: \\U sers \\m franc \\D ropbox  %ProgramFiles(x86)%\\Vim\\vim80\\vim.exe  /k\n-new_console:d:D: \\  %ProgramFiles%\\Vim\\vim74\\vim.exe  /k -cur_console:n\n-cur_console:d:D: \\  %ProgramFiles%\\Git\\bin\\sh.exe  --login -i -cur_console:n:sT25V\n-cur_console:d:D: \\  %ProgramFiles%\\Git\\bin\\sh.exe  --login -i cur_console:n:sT66H cmd.exe -new_console:d:D: \\  -i -cur_console:n:sT50H   What does those commands do?    Creates new screen and opens Vim in my Dropbox folder context  Creates new screen with Vim pointing to D:\\  Initializes shell in this new window and splits current screen into  75%/25% horizontaly  Initializes shell in new (25%) window and splits it up into  33.3%/66.6% vertically . Then initializes shell in the new (66.6%) window and splits it up into  50%/50% vertically .", 
            "title": "Configuring Tasks"
        }, 
        {
            "location": "/git/tools/#aliases", 
            "text": "You can create an alias to any command by an  alias  command, e.g.:  1 alias   push = git push -u  $*     No space in between!  Make sure there is no space between the alias and the equality sign  =   Undo the alias by  unalias push .  The aliases can be found in  config  subdirectory of the cmder install directory in the  user-aliases.cmd  file or by running  alias  command with no parameters.", 
            "title": "Aliases"
        }, 
        {
            "location": "/git/tools/#standard-aliases", 
            "text": "cmderr  - open cmder window in the cmder install directory, e.g.  C:\\Program Files\\Cmder  history  - show latest commands", 
            "title": "Standard Aliases"
        }, 
        {
            "location": "/git/tools/#how-to-update-conemu-within-cmder", 
            "text": "Maximus5 , the author of Cmder, explains how to update ConEmu to a new version. Current Cmder can contain an older ConEmu version. To update ConEmu, get the new package from the  ConEmu website  and copy its content to  your cmder installation /vendor/conemu-maximus5 folder.", 
            "title": "How to update ConEmu within Cmder"
        }, 
        {
            "location": "/git/tools/#links", 
            "text": "Cmder: Super Command Line Tool Window", 
            "title": "Links"
        }, 
        {
            "location": "/git/tools/#far-manager", 
            "text": "", 
            "title": "Far Manager"
        }, 
        {
            "location": "/git/tools/#add-far-manager-to-the-windows-context-menu", 
            "text": "It is convenient to be able to open the  Far Manager  at the current location. You would then want to be able to either   right click either on the folder itself, or   right click inside the white area within the folder open in the  Windows Explorer .   Create or rename (if already created by the  Far Manager  installation) the same group of keys and string values in the  Windows Registry  in the following two locations respectively:   HCR/Directory/shell  HCR/Directory/Background/shell   Key:  Far Here     Name  Type  Data      (Default)  REG_SZ  (value not set)    Icon  REG_SZ  C:\\Program Files\\Far Manager\\Far.exe,0     Subkey:  command     Name  Type  Data      (Default)  REG_SZ  C:\\Program Files\\Far Manager\\Far.exe   % X   % X      Replace X with a number!  In the  shell , replace X with  1  and in the  Background/shell  with  2 .", 
            "title": "Add Far Manager to the Windows context menu"
        }, 
        {
            "location": "/git/tools/#posh-git-for-powershell", 
            "text": "POSH-GIT  is a PowerShell module that shows the current branch of the git repository and understands git commands.", 
            "title": "POSH-GIT for PowerShell"
        }, 
        {
            "location": "/git/tools/#installation", 
            "text": "The easiest way is to use PowerShell of Chocolatey.", 
            "title": "Installation"
        }, 
        {
            "location": "/git/tools/#powershell", 
            "text": "1 PowerShellGet \\ Install-Module   posh-git   -Scope   CurrentUser    Note:  If you get an error message from  Install-Module  about NuGet being required to interact with NuGet-based repositories, execute the following commands to bootstrap the NuGet provider:  1\n2 Install-PackageProvider   NuGet   -Force  Import-PackageProvider   NuGet   -Force    Then retry the  Install-Module  command above.", 
            "title": "PowerShell"
        }, 
        {
            "location": "/git/tools/#chocolatey", 
            "text": "1 choco install poshgit", 
            "title": "Chocolatey"
        }, 
        {
            "location": "/git/tools/#updates", 
            "text": "Update to a newer version by executing the command:  1 Update-Module   posh-git", 
            "title": "Updates"
        }, 
        {
            "location": "/git/tools/#how-to-use", 
            "text": "Open the PowerShell command prompt and run:  1 Import-Module posh-git   If you are lazy to do it every time, add the command to your profile. Here is how.   start PowerShell command prompt and run  $profile  you will see the path and name of your profile file, e.g.  C:\\Users\\YourUserName\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1  if this file does not exist, create it  add  Import-Module posh-git  to that file", 
            "title": "How to use"
        }, 
        {
            "location": "/git/tools/#use-it-with-integrated-terminal-in-vs-code", 
            "text": "Add the following setting to the VS Code User Settings:  1 terminal.integrated.shell.windows :   C:\\\\Windows\\\\System 32 \\\\WindowsPowerShell\\\\v 1.0 \\\\powershell.exe,    Toggle the Integrated Terminal window with  Ctrl + ` .", 
            "title": "Use it with Integrated Terminal in VS Code"
        }, 
        {
            "location": "/mac/nginx/", 
            "text": "Web Server on MacBook Pro\n\n\nIt is possible to run different web servers on a Mac. I prefer \nNGINX\n to Apache.\n\n\nNGINX\n\n\nInstallation\n\n\nPrep work:\n\n\n1\n2\n3\nbrew doctor\nbrew update\nbrew upgrade\n\n\n\n\n\n\nInstallation:\n\n\n1\n2\n3\nbrew install nginx\nbrew services start nginx\nbrew services stop nginx\n\n\n\n\n\n\nUse these commands to start, stop or restart the nginx server:\n\n\n1\n2\n3\nsudo nginx\nsudo nginx -s stop\nsudo nginx -s reload\n\n\n\n\n\n\nnginx.conf\n\n\nIn the root of the main HDD, create a new \nwww\n directory and inside it another two subdirectories: \nhome\n and \nsites\n.\n\n\nNow, we can edit the \nnginx.conf\n file to point the root server at \n/www/sites\n and listen on port \n80\n. We can use VI or NANO for that:\n\n\n1\n2\nsudo vi /usr/local/etc/nginx/nginx.conf\nsudo nano /usr/local/etc/nginx/nginx.conf\n\n\n\n\n\n\nScroll to the second screen and you will see something like this:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\nserver\n \n{\n\n        \nlisten\n       \n8080\n;\n\n        \nserver_name\n  \nlocalhost\n;\n\n\n        \n#charset koi8-r;\n\n\n        \n#access_log  logs/host.access.log  main;\n\n\n        \nlocation\n \n/\n \n{\n\n            \nroot\n   \nhtml\n;\n\n            \nindex\n  \nindex\n.\nhtml\n \nindex\n.\nhtm\n;\n\n        \n}\n\n        \n...\n\n\n}\n\n\n\n\n\n\n\nChange \n8080\n to \n80\n and \nroot html;\n to \n/www/sites\n or whatever other root path we created. \n\n\n\n\nErrors 500\n\n\nThere is another chunk of code after \nlocation\n, which deals with \n500\n errors that also has \nroot html\n setting. Possibly, it should also be changed in the same way.\n\n\n\n\nAnciliary Tools\n\n\ndsnmasq\n\n\nThis is a great little tool that allows us to use wildcard subdomain names. With the default apache settings, we can add as many sites as we like in subfolders of the web root, e.g.:\n\n\n\n\nhttp://home.dev/client1\n\n\nhttp://home.dev/client2\n\n\nhttp://home.dev/client3\n\n\n\n\nHowever, that creates a problem. When we have each site in a folder, it\u2019s more difficult to manage the settings for each site. Each one must then have a different absolute root. The solution is to create a subdomain for each site, and use URLs like these:\n\n\n\n\nhttp://client1.dev\n\n\nhttp://client2.dev\n\n\nhttp://client3.dev\n\n\n\n\nWe can accomplish this by placing all three sites in our \n/private/etc/hosts\n file, but then we need to keep adding entries every time we add a new site. \n\n\n\n\ndnsmasq\n allows us to do this by interrupting each request that ends with .dev and forwarding it to a designated IP address (127.0.0.1 in our case).\n\n\n\n\nThe following commands will install \ndnsmasq\n, configure it to point all requests to the .dev top-level domain to our local machine, and make sure it starts up and runs all of the time.\n\n\n1\n2\n3\n4\n5\n6\nbrew install dnsmasq\n\ncd\n \n$(\nbrew --prefix\n)\n;\n mkdir etc\n;\n \necho\n \naddress=/.dev/127.0.0.1\n \n etc/dnsmasq.conf\nsudo cp -v \n$(\nbrew --prefix dnsmasq\n)\n/homebrew.mxcl.dnsmasq.plist /Library/LaunchDaemons\nsudo launchctl load -w /Library/LaunchDaemons/homebrew.mxcl.dnsmasq.plist\nsudo mkdir /etc/resolver\nsudo bash -c \necho \nnameserver 127.0.0.1\n \n /etc/resolver/dev\n\n\n\n\n\n\n\nIf all goes well, we\u2019ll never need to think about it again.", 
            "title": "NGINX"
        }, 
        {
            "location": "/mac/nginx/#web-server-on-macbook-pro", 
            "text": "It is possible to run different web servers on a Mac. I prefer  NGINX  to Apache.", 
            "title": "Web Server on MacBook Pro"
        }, 
        {
            "location": "/mac/nginx/#nginx", 
            "text": "", 
            "title": "NGINX"
        }, 
        {
            "location": "/mac/nginx/#installation", 
            "text": "Prep work:  1\n2\n3 brew doctor\nbrew update\nbrew upgrade   Installation:  1\n2\n3 brew install nginx\nbrew services start nginx\nbrew services stop nginx   Use these commands to start, stop or restart the nginx server:  1\n2\n3 sudo nginx\nsudo nginx -s stop\nsudo nginx -s reload", 
            "title": "Installation"
        }, 
        {
            "location": "/mac/nginx/#nginxconf", 
            "text": "In the root of the main HDD, create a new  www  directory and inside it another two subdirectories:  home  and  sites .  Now, we can edit the  nginx.conf  file to point the root server at  /www/sites  and listen on port  80 . We can use VI or NANO for that:  1\n2 sudo vi /usr/local/etc/nginx/nginx.conf\nsudo nano /usr/local/etc/nginx/nginx.conf   Scroll to the second screen and you will see something like this:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14 server   { \n         listen         8080 ; \n         server_name    localhost ; \n\n         #charset koi8-r; \n\n         #access_log  logs/host.access.log  main; \n\n         location   /   { \n             root     html ; \n             index    index . html   index . htm ; \n         } \n         ...  }    Change  8080  to  80  and  root html;  to  /www/sites  or whatever other root path we created.    Errors 500  There is another chunk of code after  location , which deals with  500  errors that also has  root html  setting. Possibly, it should also be changed in the same way.", 
            "title": "nginx.conf"
        }, 
        {
            "location": "/mac/nginx/#anciliary-tools", 
            "text": "", 
            "title": "Anciliary Tools"
        }, 
        {
            "location": "/mac/nginx/#dsnmasq", 
            "text": "This is a great little tool that allows us to use wildcard subdomain names. With the default apache settings, we can add as many sites as we like in subfolders of the web root, e.g.:   http://home.dev/client1  http://home.dev/client2  http://home.dev/client3   However, that creates a problem. When we have each site in a folder, it\u2019s more difficult to manage the settings for each site. Each one must then have a different absolute root. The solution is to create a subdomain for each site, and use URLs like these:   http://client1.dev  http://client2.dev  http://client3.dev   We can accomplish this by placing all three sites in our  /private/etc/hosts  file, but then we need to keep adding entries every time we add a new site.    dnsmasq  allows us to do this by interrupting each request that ends with .dev and forwarding it to a designated IP address (127.0.0.1 in our case).   The following commands will install  dnsmasq , configure it to point all requests to the .dev top-level domain to our local machine, and make sure it starts up and runs all of the time.  1\n2\n3\n4\n5\n6 brew install dnsmasq cd   $( brew --prefix ) ;  mkdir etc ;   echo   address=/.dev/127.0.0.1    etc/dnsmasq.conf\nsudo cp -v  $( brew --prefix dnsmasq ) /homebrew.mxcl.dnsmasq.plist /Library/LaunchDaemons\nsudo launchctl load -w /Library/LaunchDaemons/homebrew.mxcl.dnsmasq.plist\nsudo mkdir /etc/resolver\nsudo bash -c  echo  nameserver 127.0.0.1    /etc/resolver/dev    If all goes well, we\u2019ll never need to think about it again.", 
            "title": "dsnmasq"
        }, 
        {
            "location": "/mac/ssh/", 
            "text": "SSH on Sierra\n\n\nThese are short notes on how you can set up an SSH connection for GitLab (or any other secure server).\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n# check if you already have an ssh key\n\ncat ~/.ssh/id_rsa.pub\n\n\n# if not, generate a new key\n\nssh-keygen -t rsa -C \nyour.email@yourprovider.com\n -b \n4096\n\n\n\n# copy the new key to clipboard\n\npbcopy \n ~/.ssh/id_rsa.pub\n\n\n\n\n\n\nGo to \nGitLab\n and add your new key as explained in their help documentation.\n\n\nTest your SSH configuration:\n\n\n1\n2\n3\n4\n5\n# test the key\n\nssh -T git@gitlab.com\n\n\n# debug the connection\n\nssh -Tv git@gitlab.com\n\n\n\n\n\n\nWhen using SSH on my Mac with High Sierra, I noticed that I am required to enter my SSH password every time.\n\nThis is a known issue on Sierra. I have found a good solution to it in \nthis article by Rob Allen\n. Here are the steps I have taken based on his advice:\n\n\n1\n2\n3\n4\n5\n# add your key to id_rsa\n\nssh-add -K ~/.ssh/id_rsa\n\n\n# make sure you see the saved key\n\nssh-add -l\n\n\n\n\n\n\nNow you can check you don\nt need to enter your password by running \ngit status\n on any GitLab repo.\n\n\nUpdate the SSH config by editing \n~/.ssh/config\n and adding:\n\n\n1\n2\n3\nHost *\n   AddKeysToAgent yes\n   UseKeychain yes\n\n\n\n\n\n\nAfter reboot of your PC, you should still be able to use SSH without having to type in your password.", 
            "title": "SSH on Sierra"
        }, 
        {
            "location": "/mac/ssh/#ssh-on-sierra", 
            "text": "These are short notes on how you can set up an SSH connection for GitLab (or any other secure server).  1\n2\n3\n4\n5\n6\n7\n8 # check if you already have an ssh key \ncat ~/.ssh/id_rsa.pub # if not, generate a new key \nssh-keygen -t rsa -C  your.email@yourprovider.com  -b  4096  # copy the new key to clipboard \npbcopy   ~/.ssh/id_rsa.pub   Go to  GitLab  and add your new key as explained in their help documentation.  Test your SSH configuration:  1\n2\n3\n4\n5 # test the key \nssh -T git@gitlab.com # debug the connection \nssh -Tv git@gitlab.com   When using SSH on my Mac with High Sierra, I noticed that I am required to enter my SSH password every time. \nThis is a known issue on Sierra. I have found a good solution to it in  this article by Rob Allen . Here are the steps I have taken based on his advice:  1\n2\n3\n4\n5 # add your key to id_rsa \nssh-add -K ~/.ssh/id_rsa # make sure you see the saved key \nssh-add -l   Now you can check you don t need to enter your password by running  git status  on any GitLab repo.  Update the SSH config by editing  ~/.ssh/config  and adding:  1\n2\n3 Host *\n   AddKeysToAgent yes\n   UseKeychain yes   After reboot of your PC, you should still be able to use SSH without having to type in your password.", 
            "title": "SSH on Sierra"
        }, 
        {
            "location": "/mac/tips/", 
            "text": "How to make file executable\n\n\nSuppose you have create a \nrun.sh\n file and you want to be able to run it with \nbash\n. In the file, the first line should be like this:\n\n\n1\n#!/bin/sh\n\n\n\n\n\n\nor like this:\n\n\n1\n#!/bin/bash\n\n\n\n\n\n\nThen in the folder with your file run this command to add execute rights to the file:\n\n\n1\nchmod u+x ./run.sh\n\n\n\n\n\n\nFinally, you can run this file like this:\n\n\n1\n./run.sh", 
            "title": "Tips & Tricks"
        }, 
        {
            "location": "/mac/tips/#how-to-make-file-executable", 
            "text": "Suppose you have create a  run.sh  file and you want to be able to run it with  bash . In the file, the first line should be like this:  1 #!/bin/sh   or like this:  1 #!/bin/bash   Then in the folder with your file run this command to add execute rights to the file:  1 chmod u+x ./run.sh   Finally, you can run this file like this:  1 ./run.sh", 
            "title": "How to make file executable"
        }, 
        {
            "location": "/dotnet/new_project/", 
            "text": "Workflow with an new ASP.NET Core MVC Project\n\n\n.NET Core Prerequisites\n\n\nIdeally, you have to have a number of components installed on your system (Windows | Linux | MacOS):\n\n\n\n\n.NET Core\n\n\n.NET Core SDK\n\n\nNode.js\n\n\n\n\n\n\nCreate a new minimal ASP.NET Core project\n\n\n\n\nIMPORTANT!\n\n\nWhen working with Visual Studio as IDE, make sure that - \nAT ALL TIMES!\n - you can run your application both from inside the Visual Studio by pressing \nCtrl + F5\n, and from the command prompt by executing \ndotnet run\n command.\n\n\n\n\nDotnet Command Line Version\n\n\n\n\nCreate a new project directory and CD to it:\n\n\n\n\nmkdir myproj \n cd myproj\n\n\n\n\nCreate the default initial project:\n\n\n\n\ndotnet new\n\n\n\n\nRestore the default dependencies:\n\n\n\n\ndotnet restore\n\n\n\n\nRun the project and see the \nHello World!\n message:\n\n\n\n\ndotnet run\n\n\nVisual Studio 2015 Version\n\n\nStart Visual Studio. Click on \nFile | New | Project\n. In the \nTemplates\n choose \nVisual C# | .NET Core\n and then \nASP.NET Core Web Application (.NET Core)\n. Browse to the root location for your new solution. Choose a nice name for it, e.g. \nMyGreatApp\n. Click the \nOK\n button. Choose now the empty ASP.NET Core template.\n\n\nThe solution is created. Wait for the dependencies to be installed. Build and run the solution with \nCtrl + F5\n. When the browser starts, you will see the \nHello World!\n message.\n\n\nYou can also start the command prompt in the \nMyGreatApp/Src/MyGreatApp\n folder. Run this command:\n\n\ndotnet restore \n dotnet run\n\n\nBrowse to the \nlocalhost:5000\n and you will see the \nHello World!\n message.\n\n\nDependencies\n\n\n\n\nVersions are constantly changing\n\n\nASP.NET Core is constantly being developed and new versions of different components are being released. Therefore, the versions stated below can get outdated at any moment. If you wish to upgrade a version, you have to install the referenced component first.\n\n\n\n\nProject.json\n\n\nYou can start with this configuration:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n{\n\n    \nversion\n:\n \n1.0.0-*\n,\n\n    \ndescription\n:\n \nYour best description of the application\n,\n\n    \nauthors\n:\n \n[\n \nYour Name\n \n],\n\n    \npackOptions\n:\n \n{\n\n        \ntags\n:\n \n[\n \n \n],\n\n        \nprojectUrl\n:\n \n,\n\n        \nlicenseUrl\n:\n \n\n    \n},\n\n\n    \ndependencies\n:\n \n{\n\n        \nMicrosoft.NETCore.App\n:\n \n{\n\n            \nversion\n:\n \n1.1.*\n,\n\n            \ntype\n:\n \nplatform\n\n        \n},\n\n        \nMicrosoft.AspNetCore.Diagnostics\n:\n \n1.1.0\n,\n\n        \nMicrosoft.AspNetCore.Mvc\n:\n \n1.1.0\n,\n\n        \nMicrosoft.AspNetCore.Razor.Tools\n:\n \n{\n\n            \nversion\n:\n \n1.1.0-preview4-final\n,\n\n            \ntype\n:\n \nbuild\n\n        \n},\n\n        \nMicrosoft.AspNetCore.Server.IISIntegration\n:\n \n1.1.0\n,\n\n        \nMicrosoft.AspNetCore.Server.Kestrel\n:\n \n1.1.0\n,\n\n        \nMicrosoft.AspNetCore.StaticFiles\n:\n \n1.1.0\n,\n\n        \nMicrosoft.Extensions.Logging.Console\n:\n \n1.1.0\n,\n\n        \nMicrosoft.VisualStudio.Web.BrowserLink.Loader\n:\n \n14.1.0\n,\n\n        \nSystem.Net.Http\n:\n \n4.3.0\n\n    \n},\n\n\n    \ntools\n:\n \n{\n\n        \nMicrosoft.AspNetCore.Server.IISIntegration.Tools\n:\n \n1.0.0-preview2-final\n\n    \n},\n\n\n    \nframeworks\n:\n \n{\n\n        \nnetcoreapp1.0\n:\n \n{\n\n            \nimports\n:\n \n[\n\n                \ndotnet5.6\n,\n\n                \nportable-net45+win8\n,\n\n                \ndnxcore50\n\n            \n]\n\n        \n}\n\n    \n},\n\n\n    \nbuildOptions\n:\n \n{\n\n        \nemitEntryPoint\n:\n \ntrue\n,\n\n        \npreserveCompilationContext\n:\n \ntrue\n\n    \n},\n\n\n    \nruntimes\n:\n \n{\n\n        \nwin81-x64\n:\n \n{},\n\n        \nwin7-x64\n:\n \n{},\n\n        \nosx.10.12-x64\n:\n \n{}\n\n    \n},\n\n\n    \nruntimeOptions\n:\n \n{\n\n        \nconfigProperties\n:\n \n{\n\n            \nSystem.GC.Server\n:\n \ntrue\n\n        \n}\n\n    \n},\n\n\n    \npublishOptions\n:\n \n{\n\n        \ninclude\n:\n \n[\n\n            \nwwwroot\n,\n\n            \nweb.config\n\n        \n]\n\n    \n},\n\n\n    \nscripts\n:\n \n{\n\n        \npostpublish\n:\n \n[\n\n          \ndotnet publish-iis --publish-folder %publish:OutputPath% --framework %publish:FullTargetFramework%\n\n        \n]\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\nGlobal.json\n\n\nWhen you install the .NET Core SDK on Windows, it shows up in \nC:\\Program Files\\dotnet\\sdk\n folder. Using the \nsdk\n option, we can override the default version.\n\n\n1\n2\n3\n4\n5\n6\n{\n\n  \nprojects\n:\n \n[\n \nsrc\n,\n \ntest\n \n],\n\n  \nsdk\n:\n \n{\n\n    \nversion\n:\n \n1.0.0-preview2-1-003177\n\n  \n}\n\n\n}\n\n\n\n\n\n\n\nBower.json\n\n\nIf you need \nBootstrap 3\n for the styling of your website, add this \nbower.json\n file in the project root.\n\n\n1\n2\n3\n4\n5\n6\n7\n{\n\n    \nname\n:\n \nasp.net\n,\n\n    \nprivate\n:\n \ntrue\n,\n\n    \ndependencies\n:\n \n{\n\n      \nbootstrap\n:\n \n3.3.*\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\nProgram.cs\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\nusing\n \nMicrosoft.AspNetCore.Hosting\n;\n\n\nusing\n \nSystem.IO\n;\n\n\n\nnamespace\n \nNNMeta\n\n\n{\n\n    \npublic\n \nclass\n \nProgram\n\n    \n{\n\n        \npublic\n \nstatic\n \nvoid\n \nMain\n(\nstring\n[]\n \nargs\n)\n\n        \n{\n\n            \nvar\n \nhost\n \n=\n \nnew\n \nWebHostBuilder\n()\n\n                \n.\nUseKestrel\n()\n\n                \n.\nUseContentRoot\n(\nDirectory\n.\nGetCurrentDirectory\n())\n\n                \n.\nUseIISIntegration\n()\n\n                \n.\nUseStartup\nStartup\n()\n\n                \n.\nBuild\n();\n\n\n            \nhost\n.\nRun\n();\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\nStartup.cs\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\nusing\n \nMicrosoft.AspNetCore.Builder\n;\n\n\nusing\n \nMicrosoft.AspNetCore.Hosting\n;\n\n\nusing\n \nMicrosoft.Extensions.DependencyInjection\n;\n\n\nusing\n \nMicrosoft.Extensions.Logging\n;\n\n\n\nnamespace\n \nNNMeta\n\n\n{\n\n    \npublic\n \nclass\n \nStartup\n\n    \n{\n\n        \npublic\n \nvoid\n \nConfigureServices\n(\nIServiceCollection\n \nservices\n)\n\n        \n{\n\n            \nservices\n.\nAddMvc\n();\n\n        \n}\n\n\n        \npublic\n \nvoid\n \nConfigure\n(\nIApplicationBuilder\n \napp\n,\n \nIHostingEnvironment\n \nenv\n,\n \nILoggerFactory\n \nloggerFactory\n)\n\n        \n{\n\n            \nif\n \n(\nenv\n.\nIsDevelopment\n())\n\n            \n{\n\n                \napp\n.\nUseDeveloperExceptionPage\n();\n\n            \n}\n\n\n            \napp\n.\nUseStaticFiles\n();\n\n            \napp\n.\nUseMvcWithDefaultRoute\n();\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\n\nControllers/HomeController.cs\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\nusing\n \nSystem.Collections.Generic\n;\n\n\nusing\n \nMicrosoft.AspNetCore.Mvc\n;\n\n\n\nnamespace\n \nNNMeta.Controllers\n\n\n{\n\n    \npublic\n \nclass\n \nHomeController\n \n:\n \nController\n\n    \n{\n\n        \npublic\n \nViewResult\n \nIndex\n()\n\n            \n=\n \nView\n(\nnew\n \nDictionary\nstring\n,\n \nstring\n\n            \n{\n\n\n                [\nMessage1\n]\n \n=\n \nThis is the first message from the Index action\n,\n\n\n                [\nMessage2\n]\n \n=\n \nThis is the second message from the Index action\n\n            \n});\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\nViews/_ViewImports.cshtml\n\n\n1\n@addTagHelper *, Microsoft.AspNetCore.Mvc.TagHelpers\n\n\n\n\n\n\nViews/Home/Index.cshtml\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n@model Dictionary\nstring\n,\n \nstring\n\n@{ Layout = null; }\n\n!DOCTYPE html\n\n\nhtml\n\n\nhead\n\n  \nmeta\n \nname\n=\nviewport\n \ncontent\n=\nwidth=device-width\n \n/\n\n  \nlink\n \nasp-href-include\n=\n~/lib/bootstrap/dist/css/*.min.css\n \nrel\n=\nstylesheet\n \n/\n\n  \ntitle\nResult\n/\ntitle\n\n\n/\nhead\n\n\nbody\n \nclass\n=\npanel-body\n\n  \ntable\n \nclass\n=\ntable table-condensed table-bordered table-striped\n\n    \ntr\n\n      @foreach (var kvp in Model)\n      {\n          \nth\n@kvp.Key\n/\nth\n\n      }\n    \n/\ntr\n\n    \ntr\n\n      @foreach (var kvp in Model)\n      {\n          \ntd\n@kvp.Value\n/\ntd\n\n      }\n    \n/\ntr\n\n  \n/\ntable\n\n\n/\nbody\n\n\n/\nhtml", 
            "title": "New Project"
        }, 
        {
            "location": "/dotnet/new_project/#workflow-with-an-new-aspnet-core-mvc-project", 
            "text": "", 
            "title": "Workflow with an new ASP.NET Core MVC Project"
        }, 
        {
            "location": "/dotnet/new_project/#net-core-prerequisites", 
            "text": "Ideally, you have to have a number of components installed on your system (Windows | Linux | MacOS):   .NET Core  .NET Core SDK  Node.js", 
            "title": ".NET Core Prerequisites"
        }, 
        {
            "location": "/dotnet/new_project/#create-a-new-minimal-aspnet-core-project", 
            "text": "IMPORTANT!  When working with Visual Studio as IDE, make sure that -  AT ALL TIMES!  - you can run your application both from inside the Visual Studio by pressing  Ctrl + F5 , and from the command prompt by executing  dotnet run  command.", 
            "title": "Create a new minimal ASP.NET Core project"
        }, 
        {
            "location": "/dotnet/new_project/#dotnet-command-line-version", 
            "text": "Create a new project directory and CD to it:   mkdir myproj   cd myproj   Create the default initial project:   dotnet new   Restore the default dependencies:   dotnet restore   Run the project and see the  Hello World!  message:   dotnet run", 
            "title": "Dotnet Command Line Version"
        }, 
        {
            "location": "/dotnet/new_project/#visual-studio-2015-version", 
            "text": "Start Visual Studio. Click on  File | New | Project . In the  Templates  choose  Visual C# | .NET Core  and then  ASP.NET Core Web Application (.NET Core) . Browse to the root location for your new solution. Choose a nice name for it, e.g.  MyGreatApp . Click the  OK  button. Choose now the empty ASP.NET Core template.  The solution is created. Wait for the dependencies to be installed. Build and run the solution with  Ctrl + F5 . When the browser starts, you will see the  Hello World!  message.  You can also start the command prompt in the  MyGreatApp/Src/MyGreatApp  folder. Run this command:  dotnet restore   dotnet run  Browse to the  localhost:5000  and you will see the  Hello World!  message.", 
            "title": "Visual Studio 2015 Version"
        }, 
        {
            "location": "/dotnet/new_project/#dependencies", 
            "text": "Versions are constantly changing  ASP.NET Core is constantly being developed and new versions of different components are being released. Therefore, the versions stated below can get outdated at any moment. If you wish to upgrade a version, you have to install the referenced component first.", 
            "title": "Dependencies"
        }, 
        {
            "location": "/dotnet/new_project/#projectjson", 
            "text": "You can start with this configuration:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73 { \n     version :   1.0.0-* , \n     description :   Your best description of the application , \n     authors :   [   Your Name   ], \n     packOptions :   { \n         tags :   [     ], \n         projectUrl :   , \n         licenseUrl :   \n     }, \n\n     dependencies :   { \n         Microsoft.NETCore.App :   { \n             version :   1.1.* , \n             type :   platform \n         }, \n         Microsoft.AspNetCore.Diagnostics :   1.1.0 , \n         Microsoft.AspNetCore.Mvc :   1.1.0 , \n         Microsoft.AspNetCore.Razor.Tools :   { \n             version :   1.1.0-preview4-final , \n             type :   build \n         }, \n         Microsoft.AspNetCore.Server.IISIntegration :   1.1.0 , \n         Microsoft.AspNetCore.Server.Kestrel :   1.1.0 , \n         Microsoft.AspNetCore.StaticFiles :   1.1.0 , \n         Microsoft.Extensions.Logging.Console :   1.1.0 , \n         Microsoft.VisualStudio.Web.BrowserLink.Loader :   14.1.0 , \n         System.Net.Http :   4.3.0 \n     }, \n\n     tools :   { \n         Microsoft.AspNetCore.Server.IISIntegration.Tools :   1.0.0-preview2-final \n     }, \n\n     frameworks :   { \n         netcoreapp1.0 :   { \n             imports :   [ \n                 dotnet5.6 , \n                 portable-net45+win8 , \n                 dnxcore50 \n             ] \n         } \n     }, \n\n     buildOptions :   { \n         emitEntryPoint :   true , \n         preserveCompilationContext :   true \n     }, \n\n     runtimes :   { \n         win81-x64 :   {}, \n         win7-x64 :   {}, \n         osx.10.12-x64 :   {} \n     }, \n\n     runtimeOptions :   { \n         configProperties :   { \n             System.GC.Server :   true \n         } \n     }, \n\n     publishOptions :   { \n         include :   [ \n             wwwroot , \n             web.config \n         ] \n     }, \n\n     scripts :   { \n         postpublish :   [ \n           dotnet publish-iis --publish-folder %publish:OutputPath% --framework %publish:FullTargetFramework% \n         ] \n     }  }", 
            "title": "Project.json"
        }, 
        {
            "location": "/dotnet/new_project/#globaljson", 
            "text": "When you install the .NET Core SDK on Windows, it shows up in  C:\\Program Files\\dotnet\\sdk  folder. Using the  sdk  option, we can override the default version.  1\n2\n3\n4\n5\n6 { \n   projects :   [   src ,   test   ], \n   sdk :   { \n     version :   1.0.0-preview2-1-003177 \n   }  }", 
            "title": "Global.json"
        }, 
        {
            "location": "/dotnet/new_project/#bowerjson", 
            "text": "If you need  Bootstrap 3  for the styling of your website, add this  bower.json  file in the project root.  1\n2\n3\n4\n5\n6\n7 { \n     name :   asp.net , \n     private :   true , \n     dependencies :   { \n       bootstrap :   3.3.* \n     }  }", 
            "title": "Bower.json"
        }, 
        {
            "location": "/dotnet/new_project/#programcs", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20 using   Microsoft.AspNetCore.Hosting ;  using   System.IO ;  namespace   NNMeta  { \n     public   class   Program \n     { \n         public   static   void   Main ( string []   args ) \n         { \n             var   host   =   new   WebHostBuilder () \n                 . UseKestrel () \n                 . UseContentRoot ( Directory . GetCurrentDirectory ()) \n                 . UseIISIntegration () \n                 . UseStartup Startup () \n                 . Build (); \n\n             host . Run (); \n         } \n     }  }", 
            "title": "Program.cs"
        }, 
        {
            "location": "/dotnet/new_project/#startupcs", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26 using   Microsoft.AspNetCore.Builder ;  using   Microsoft.AspNetCore.Hosting ;  using   Microsoft.Extensions.DependencyInjection ;  using   Microsoft.Extensions.Logging ;  namespace   NNMeta  { \n     public   class   Startup \n     { \n         public   void   ConfigureServices ( IServiceCollection   services ) \n         { \n             services . AddMvc (); \n         } \n\n         public   void   Configure ( IApplicationBuilder   app ,   IHostingEnvironment   env ,   ILoggerFactory   loggerFactory ) \n         { \n             if   ( env . IsDevelopment ()) \n             { \n                 app . UseDeveloperExceptionPage (); \n             } \n\n             app . UseStaticFiles (); \n             app . UseMvcWithDefaultRoute (); \n         } \n     }  }", 
            "title": "Startup.cs"
        }, 
        {
            "location": "/dotnet/new_project/#controllershomecontrollercs", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15 using   System.Collections.Generic ;  using   Microsoft.AspNetCore.Mvc ;  namespace   NNMeta.Controllers  { \n     public   class   HomeController   :   Controller \n     { \n         public   ViewResult   Index () \n             =   View ( new   Dictionary string ,   string \n             {                  [ Message1 ]   =   This is the first message from the Index action ,                  [ Message2 ]   =   This is the second message from the Index action \n             }); \n     }  }", 
            "title": "Controllers/HomeController.cs"
        }, 
        {
            "location": "/dotnet/new_project/#views_viewimportscshtml", 
            "text": "1 @addTagHelper *, Microsoft.AspNetCore.Mvc.TagHelpers", 
            "title": "Views/_ViewImports.cshtml"
        }, 
        {
            "location": "/dotnet/new_project/#viewshomeindexcshtml", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26 @model Dictionary string ,   string \n@{ Layout = null; } !DOCTYPE html  html  head \n   meta   name = viewport   content = width=device-width   / \n   link   asp-href-include = ~/lib/bootstrap/dist/css/*.min.css   rel = stylesheet   / \n   title Result / title  / head  body   class = panel-body \n   table   class = table table-condensed table-bordered table-striped \n     tr \n      @foreach (var kvp in Model)\n      {\n           th @kvp.Key / th \n      }\n     / tr \n     tr \n      @foreach (var kvp in Model)\n      {\n           td @kvp.Value / td \n      }\n     / tr \n   / table  / body  / html", 
            "title": "Views/Home/Index.cshtml"
        }, 
        {
            "location": "/dotnet/notes/", 
            "text": "Notes on ASP.NET Core\n\n\nI have written these notes while working on a couple of great books on the subject. See \nSources used\n.\n\n\nModels\n - the \nM\n in \nMVC\n - contain the data that users work with. There are two broad types of model:\n\n\n\n\nview models\n, which represent just data passed from the controller to the view, and\n\n\ndomain models\n, which contain the data in a business domain, along with the operations, transformations, and rules for creating, storing, and manipulating that data, collectively referred to as the model logic.\n\n\n\n\nIn ASP.NET Core MVC, \ncontrollers\n are C# classes, usually derived from the \nMicrosoft.AspNetCore.Mvc.Controller\n class. Each \npublic\n method in a class derived from \nController\n is an \naction method\n, which is associated with a \nURL\n.\n\n\n\n\n\n\nConventions\n\n\n\n\nput the third-party JavaScript and CSS packages you rely on in the \nwwwroot/lib\n folder.\n\n\nconvention over configuration\n\n\nthe controller for \n/product\n uri should have the name \nProductController.cs\n and reside in the \n/Controllers\n folder; from other parts in the project, such as when using an HTML helper method, you specify the first part of the name (\nProduct\n), and MVC automatically appends \nController\n to the name and starts looking for the controller class.\n\n\nviews for \n/product\n uri associated with \nProductController\n should all reside in the \n/Views/Product\n folder.\n\n\nMVC expects that the \ndefault view\n for an \naction method\n should be named after that method. For example, the default view associated with an action method called \nList\n should be called \nList.cshtml\n. Thus, for the \nList action method\n in the \nProductController\n class, the \ndefault view\n is expected to be \n/Views/Product/List.cshtml\n. The \ndefault view\n is used when you return the result of calling the \nView\n method in an action method, like this:\n\n\n\n\n1\n  \nreturn\n \nView\n();\n\n\n\n\n\n\n\nYou can specify a different view by name, like this:\n\n\n1\n  \nreturn\n \nView\n(\nMyOtherView\n);\n\n\n\n\n\n\n\n\n\nWhen looking for a \nview\n, MVC looks in the folder named after the controller and then in the \n/Views/Shared\n folder. This means that I can put views that will be used by more than one controller in the \n/Views/Shared\n folder and MVC will find them.\n\n\nThe naming convention for \nlayouts\n is to prefix the file with an underscore (\n_\n) character, and layout files are placed in the \n/Views/Shared\n folder. This layout is applied to all views by default through the \n/Views/_ViewStart.cshtml\n file. If you do not want the default layout applied to views, you can change the settings in \nViewStart.cshtml\n (or delete the file entirely) to specify another layout in the view, like this:\n\n\n\n\n1\n2\n3\n  \n@\n{\n\n    \nLayout\n \n=\n \n~/_MyLayout.cshtml\n;\n\n  \n}\n\n\n\n\n\n\n\n\n\nOr you can disable any layout for a given view, like this:\n\n\n\n\n1\n2\n3\n  \n@\n{\n\n    \nLayout\n \n=\n \nnull\n;\n\n  \n}\n\n\n\n\n\n\n\n\n\nExtension methods\n\n\nClass extensions\n\n\nSuppose we have a simple class:\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nusing\n \nSystem.Collections.Generic\n;\n\n\n\nnamespace\n \nLanguageFeatures.Models\n\n\n{\n\n    \npublic\n \nclass\n \nShoppingCart\n\n    \n{\n\n        \npublic\n \nIEnumerable\nProduct\n \nProducts\n \n{\n \nget\n;\n \nset\n;\n \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\nWe want to extend its functionality with a new method to calculate the total amount:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\npublic\n \nstatic\n \ndecimal\n \nTotalPrices\n(\nthis\n \nShoppingCart\n \ncartParam\n)\n\n\n{\n\n    \ndecimal\n \ntotal\n \n=\n \n0\n;\n\n\n    \nforeach\n \n(\nProduct\n \nprod\n \nin\n \ncartParam\n.\nProducts\n)\n\n    \n{\n\n        \ntotal\n \n+=\n \nprod\n?.\nPrice\n \n??\n \n0\n;\n\n    \n}\n\n    \nreturn\n \ntotal\n;\n\n\n}\n\n\n\n\n\n\n\nWe can then use this extension method like this:\n\n\n1\n2\nShoppingCart\n \ncart\n \n=\n \nnew\n \nShoppingCart\n \n{\n \nProducts\n \n=\n \nProduct\n.\nGetProducts\n()\n \n};\n\n\ndecimal\n \ncartTotal\n \n=\n \ncart\n.\nTotalPrices\n();\n\n\n\n\n\n\n\nInterface extensions\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\nusing\n \nSystem.Collections\n;\n\n\nusing\n \nSystem.Collections.Generic\n;\n\n\n\nnamespace\n \nLanguageFeatures.Models\n\n\n{\n\n    \npublic\n \nclass\n \nShoppingCart\n \n:\n \nIEnumerable\nProduct\n\n    \n{\n\n        \npublic\n \nIEnumerable\nProduct\n \nProducts\n \n{\n \nget\n;\n \nset\n;\n \n}\n\n\n        \npublic\n \nIEnumerator\nProduct\n \nGetEnumerator\n()\n\n        \n{\n\n           \nreturn\n \nProducts\n.\nGetEnumerator\n();\n\n        \n}\n\n\n        \nIEnumerator\n \nIEnumerable\n.\nGetEnumerator\n()\n\n        \n{\n\n            \nreturn\n \nGetEnumerator\n();\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\nWe can rewrite our extension method like this:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\npublic\n \nstatic\n \ndecimal\n \nTotalPrices\n(\nthis\n \nIEnumerable\nProduct\n \nproducts\n)\n\n\n{\n\n    \ndecimal\n \ntotal\n \n=\n \n0\n;\n\n\n    \nforeach\n \n(\nProduct\n \nprod\n \nin\n \nproducts\n)\n\n    \n{\n\n        \ntotal\n \n+=\n \nprod\n?.\nPrice\n \n??\n \n0\n;\n\n    \n}\n\n    \nreturn\n \ntotal\n;\n\n\n}\n\n\n\n\n\n\n\nand use it with any object of type \nIEnumerable\nProduct\n like \nShoppingCart\n and \nProduct\n array:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nShoppingCart\n \ncart\n \n=\n \nnew\n \nShoppingCart\n \n{\n \nProducts\n \n=\n \nProduct\n.\nGetProducts\n()\n \n};\n\n\n\nProduct\n[]\n \nproductArray\n \n=\n\n\n{\n\n    \nnew\n \nProduct\n \n{\nName\n \n=\n \nKayak\n,\n \nPrice\n \n=\n \n275\nM\n},\n\n    \nnew\n \nProduct\n \n{\nName\n \n=\n \nLifejacket\n,\n \nPrice\n \n=\n \n48.95\nM\n}\n\n\n};\n\n\n\ndecimal\n \ncartTotal\n \n=\n \ncart\n.\nTotalPrices\n();\n\n\ndecimal\n \narrayTotal\n \n=\n \nproductArray\n.\nTotalPrices\n();\n\n\n\n\n\n\n\nFiltering\n\n\nExtension methods can be used to \nfilter\n collections of objects. An extension method that operates on an \nIEnumerable\nT\n and that also returns an \nIEnumerable\nT\n can use the \nyield\n keyword to apply selection criteria to items in the source data to produce a reduced set of results.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\nusing\n \nSystem.Collections.Generic\n;\n\n\n\nnamespace\n \nLanguageFeatures.Models\n\n\n{\n\n    \npublic\n \nstatic\n \nclass\n \nMyExtensionMethods\n\n    \n{\n\n        \npublic\n \nstatic\n \nIEnumerable\nProduct\n \nFilterByPrice\n(\n\n            \nthis\n \nIEnumerable\nProduct\n \nproductEnum\n,\n\n            \ndecimal\n \nminimumPrice\n)\n\n        \n{\n\n            \nforeach\n \n(\nProduct\n \nprod\n \nin\n \nproductEnum\n)\n\n            \n{\n\n                \nif\n \n((\nprod\n?.\nPrice\n \n??\n \n0\n)\n \n=\n \nminimumPrice\n)\n\n                \n{\n\n                    \nyield\n \nreturn\n \nprod\n;\n\n                \n}\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\n\nLambda anonymous functions\n\n\nWe can repeat this process indefinitely and create a different filter method for every property and every combination of properties that we are interested in. A more elegant approach is to separate out the code that processes the enumeration from the selection criteria. C# makes this easy by allowing functions to be passed around as objects. We can then create a single extension method that filters an enumeration of Product objects but that delegates the decision about which ones are included in the results to a separate function.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\npublic\n \nstatic\n \nIEnumerable\nProduct\n \nFilter\n(\n\n    \nthis\n \nIEnumerable\nProduct\n \nproductEnum\n,\n\n    \nFunc\nProduct\n,\n \nbool\n \nselector\n)\n\n\n{\n\n    \nforeach\n \n(\nProduct\n \nprod\n \nin\n \nproductEnum\n)\n\n    \n{\n\n        \nif\n \n(\nselector\n(\nprod\n))\n\n        \n{\n\n            \nyield\n \nreturn\n \nprod\n;\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\nNow, we can use this \nFilter\n function as follows:\n\n\n1\n2\n3\n4\n5\n6\ndecimal\n \npriceFilterTotal\n \n=\n \nproductArray\n\n    \n.\nFilter\n(\np\n \n=\n \n(\np\n?.\nPrice\n \n??\n \n0\n)\n \n=\n \n20\n)\n\n    \n.\nTotalPrices\n();\n\n\ndecimal\n \nnameFilterTotal\n \n=\n \nproductArray\n\n    \n.\nFilter\n(\np\n \n=\n \np\n?.\nName\n?[\n0\n]\n \n==\n \nS\n)\n\n    \n.\nTotalPrices\n();\n\n\n\n\n\n\n\nLambdas\n can also be used in class properties, e.g.:\n\n\n1\npublic\n \nbool\n \nNameBeginsWithS\n \n=\n \nName\n?[\n0\n]\n \n==\n \nS\n;\n\n\n\n\n\n\n\n\n\nAsynchronous methods\n\n\nAdd \nSystem.Net.Http\n: \n4.1.0\n dependency in \nproject.json\n.\n\n\nHere is how we could make an asynchronous call \nthe hard way\n:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\npublic\n \nstatic\n \nTask\nlong?\n \nGetPageLengthWithoutAsyncAwait\n()\n\n\n{\n\n    \nHttpClient\n \nclient\n \n=\n \nnew\n \nHttpClient\n();\n\n    \nvar\n \nhttpTask\n \n=\n \nclient\n.\nGetAsync\n(\nhttp://apress.com\n);\n\n    \n// we could do other things here while the HTTP request is performed\n\n    \nreturn\n \nhttpTask\n.\nContinueWith\n((\nTask\nHttpResponseMessage\n \nantecedent\n)\n \n=\n\n    \n{\n\n        \nreturn\n \nantecedent\n.\nResult\n.\nContent\n.\nHeaders\n.\nContentLength\n;\n\n    \n});\n\n\n}\n\n\n\n\n\n\n\nAnd here is the clever way:\n\n\n1\n2\n3\n4\n5\n6\n7\npublic\n \nstatic\n \nasync\n \nTask\nlong?\n \nGetPageLength\n()\n\n\n{\n\n    \nHttpClient\n \nclient\n \n=\n \nnew\n \nHttpClient\n();\n\n    \nvar\n \nhttpMessage\n \n=\n \nawait\n \nclient\n.\nGetAsync\n(\nhttp://apress.com\n);\n\n    \n// we could do other things here while the HTTP request is performed\n\n    \nreturn\n \nhttpMessage\n.\nContent\n.\nHeaders\n.\nContentLength\n;\n\n\n}\n\n\n\n\n\n\n\nAnd we could use this in our controller:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\nusing\n \nLanguageFeatures.Models\n;\n\n\nusing\n \nMicrosoft.AspNetCore.Mvc\n;\n\n\nusing\n \nSystem.Threading.Tasks\n;\n\n\n\nnamespace\n \nLanguageFeatures.Controllers\n\n\n{\n\n    \npublic\n \nclass\n \nHomeController\n \n:\n \nController\n\n    \n{\n\n        \npublic\n \nasync\n \nTask\nViewResult\n \nIndex\n()\n\n        \n{\n\n            \nlong?\n \nlength\n \n=\n \nawait\n \nMyAsyncMethods\n.\nGetPageLength\n();\n\n            \nreturn\n \nView\n(\nnew\n \nstring\n[]\n \n{\n \n$\nLength: {length}\n \n});\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\n\nGetting property names with nameof\n\n\nIf we use lambdas the classic way:\n\n\n1\nproducts\n.\nSelect\n(\np\n \n=\n \n$\nName: {p.Name}, Price: {p.Price}\n)\n\n\n\n\n\n\n\nwe of course get no intellisense on \nName:\n and \nPrice:\n. So, if we change the property name in the class and forget to change these strings here, we get a mismatch.\n\n\nFortunately, we can now rewrite the same code like this:\n\n\n1\nproducts\n.\nSelect\n(\np\n \n=\n \n$\n{nameof(p.Name)}: {p.Name}, {nameof(p.Price)}: {p.Price}\n)\n\n\n\n\n\n\n\nbut then we will get intellisense and type safety.\n\n\n\n\nWorkflow with an empty project\n\n\n\n\ncreate a new empty ASP.NET Core project\n\n\nadd \nMicrosoft.AspNetCore.Mvc\n: \n1.0.1\n dependency in \nproject.json\n\n\nadd \nSystem.Net.Http\n: \n4.1.0\n dependency in \nproject.json\n\n\nadd \nMvc\n to \nStartup.cs\n:\n\n\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\nusing\n \nMicrosoft.AspNetCore.Builder\n;\n\n\nusing\n \nMicrosoft.AspNetCore.Hosting\n;\n\n\nusing\n \nMicrosoft.Extensions.DependencyInjection\n;\n\n\nusing\n \nMicrosoft.Extensions.Logging\n;\n\n\n\nnamespace\n \nLanguageFeatures\n\n\n{\n\n    \npublic\n \nclass\n \nStartup\n\n    \n{\n\n        \npublic\n \nvoid\n \nConfigureServices\n(\nIServiceCollection\n \nservices\n)\n\n        \n{\n\n            \nservices\n.\nAddMvc\n();\n\n        \n}\n\n\n        \npublic\n \nvoid\n \nConfigure\n(\nIApplicationBuilder\n \napp\n,\n \nIHostingEnvironment\n \nenv\n,\n \nILoggerFactory\n \nloggerFactory\n)\n\n        \n{\n\n            \napp\n.\nUseMvcWithDefaultRoute\n();\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\n\nThe JSON Configuration Files\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nglobal.json\n\n\nThis file, which is found in the Solution Items folder, is responsible for telling Visual Studio where to find the projects in the solution and which version of the .NET execution environment should be used to run the application.\n\n\n\n\n\n\nlaunchSettings.json\n\n\nThis file, which is revealed by expanding the Properties item in the MVC application project, is used to specify how the application is started.\n\n\n\n\n\n\nappsettings.json\n\n\nThis file is used to define application-specific settings.\n\n\n\n\n\n\nbower.json\n\n\nThis file is used by Bower to list the client-side packages that are installed into the project.\n\n\n\n\n\n\nbundleconfig.json\n\n\nThis file is used to bundle and minify JavaScript and CSS files.\n\n\n\n\n\n\nproject.json\n\n\nThis file is used to specify the NuGet packages that are installed into the application. This file is also used for other project settings.\n\n\n\n\n\n\nproject.lock.json\n\n\nThis file, which is revealed by expanding the project.json item in the Solution Explorer, contains detailed dependencies between packages installed in the project. It is generated automatically and should not be edited manually.\n\n\n\n\n\n\n\n\n\n\nRazor\n\n\nView Imports File\n\n\nUse \n_ViewImports.cshtml\n file in the \nViews\n folder to specify the standard include namespaces. Then you can omit them in the individual views.\n\n\nView Start File\n\n\nNormally, we have to specify the layout file we want in every view. Therefore, if we need to rename the layout file, we are going to have to find every view that refers to it and make a change, which will be an error-prone process and counter to the general theme of easy maintenance that runs through MVC development.\n\n\nWe can resolve this by using a \nview start file\n. When it renders a view, MVC will look for a file called \n_ViewStart.cshtml\n and we can put it in the \nViews\n folder. The contents of this file will be treated as though they were contained in the view file itself, and we can use this feature to automatically set a value for the Layout property.\n\n\n1\n2\n3\n@\n{\n\n    \nLayout\n \n=\n \n_BasicLayout\n;\n\n\n}\n\n\n\n\n\n\n\nNow, in the views that should use this \n_BasicLayout\n, we can omit the layout line.\n\n\nWe do not have to specify that we want to use the view start file. MVC will locate the file and use its contents automatically. The values defined in the view file take precedence, which makes it easy to override the view start file.\n\n\nWe can also use \nmultiple view start files\n to set defaults for different parts of the application. Razor looks for the closest view start file to the view that it being processed, which means that you can override the default setting by adding a view start file to the \nViews/Home\n or \nViews/Shared\n folders, for example.\n\n\n\n\nCaution\n\n\nIt is important to understand the difference between \nomitting the Layout property\n from the view file and \nsetting it to null\n. If your view is self-contained and you do not want to use a layout, then set the Layout property to null. If you omit the Layout property, then MVC will assume that you do want a layout and that it should use the value it finds in the view start file.\n\n\n\n\nViewBag property\n\n\nThe \nViewBag\n property returns a \ndynamic object\n that can be used to define arbitrary properties. Since the \nViewBag\n is dynamic, we don\u2019t have to declare the property names in advance, but it does mean that Visual Studio is unable to provide autocomplete suggestions for view bag properties.\n\n\nAttribute values\n\n\nWe can also use Razor expressions to set the value of \nelement attributes\n, not only on the content.\n\n\n1\n2\n3\n4\n5\ndiv data-productid=\n@Model.ProductID\n data-stocklevel=\n@ViewBag.StockLevel\n\n    \np\nProduct Name: @Model.Name\n/p\n\n    \np\nProduct Price: @($\n{Model.Price:C2}\n)\n/p\n\n    \np\nStock Level: @ViewBag.StockLevel\n/p\n\n\n/div\n\n\n\n\n\n\n\nSwitch statement\n\n\nWe have to cast the dynamic ViewBag properties to the right type once, inside the condition:\n\n\n1\n@switch ((int)ViewBag.StockLevel) {...}\n\n\n\n\n\n\nAfter that, inside the body, we dont need to do it any more:\n\n\n1\n2\n3\ndefault:\n    @: @ViewBag.StockLevel in Stock\n    break;\n\n\n\n\n\n\nWe do not have to put the elements or expressions in quotes or denote them in any special way\u2014the Razor engine will interpret these as output to be processed. However, if we want to insert literal text into the view when it is not contained in an HTML element, then we need to give Razor a helping hand and prefix the line with an \n@\n character (see above).\n\n\n\n\nVisual Studio tips and tricks\n\n\nEnable Developer Exception Page\n\n\nIn \nStartup.cs\n add this line to the \nConfigure\n method:\n\n\n1\napp\n.\nUseDeveloperExceptionPage\n();\n\n\n\n\n\n\n\n\n\nBrowser Link Loader\n\n\nAdd\n\n\n1\nMicrosoft.VisualStudio.Web.BrowserLink.Loader\n:\n \n14.0.0\n\n\n\n\n\n\n\nto \nproject.json\n dependencies list. Also add\n\n\n1\napp\n.\nUseBrowserLink\n();\n\n\n\n\n\n\n\nto the \nConfigure\n method of \nStartup.cs\n.\n\n\nRun the project without debugging (Ctrl + F5) and you see this kind of code added to the HTML:\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n!-- Visual Studio Browser Link --\n\n\nscript\n \ntype\n=\napplication/json\n \nid\n=\n__browserLink_initializationData\n\n    \n{\nrequestId\n:\n497a61f26544432a857e06ab5d501b7f\n,\nrequestMappingFromServer\n:\nfalse\n}\n\n\n/\nscript\n\n\nscript\n \ntype\n=\ntext/javascript\n\n        \nsrc\n=\nhttp://localhost:2701/029471b4ee954e43adc0d452954d080f/browserLink\n\n        \nasync\n=\nasync\n\n\n/\nscript\n\n\n!-- End Browser Link --\n\n\n\n\n\n\n\n\n\nAlas\n\n\nI still see no added value to it. :( Unless it is just the synchronized browsing using multiple browsers. I also see this error in the browser console:\n\n\n[14:07:17 GMT+0200 (West-Europa (zomertijd))] Browser Link: Failed to invoke return value\n\n\ncallback: TypeError: Cannot read property 'files' of null\n\n\n\n\n\n\nStatic files\n\n\nASP.NET Core includes support for delivering \nstatic files\n from the wwwroot folder to clients but it isn\u2019t enabled by default when the Empty template is used to create the project. To enable static file support, add\n\n\n1\nMicrosoft.AspNetCore.StaticFiles\n:\n \n1.0.0\n\n\n\n\n\n\n\nto \nproject.json\n dependencies list. Also add\n\n\n1\napp\n.\nUseStaticFiles\n();\n\n\n\n\n\n\n\nto the \nConfigure\n method of \nStartup.cs\n.\n\n\n\n\nBundling and minifying\n\n\nInstall \nBundler and Minifier\n extension for the Visual Studio. After that it is possible to add \ncss\n or \njs\n files to the bundle by selecting them one by one and choosing \nBundler \n Minifier | Bundle and Minify Files (Shift + Alt + F)\n from the right mouse button menu.\n\n\nThis will create a \nbundle.css\n or \nbundle.js\n file and also \nbundleconfig.json\n in the project root folder. Make sure the order of the files is what you need as \nloading order\n.\n\n\n\n\nUnit Testing with xUnit Framework\n\n\nPreparation\n\n\n\n\ncreate \ntest\n folder inside the solution folder next to \nsrc\n folder\n\n\nadd new \n.NET Core | Class Library (.NET Core)\n project inside the \ntest\n folder\n\n\nadd this code to its \nproject.json\n file (check the latest versions):\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n  \n{\n\n      \nversion\n:\n \n1.0.0-*\n,\n\n      \ntestRunner\n:\n \nxunit\n,\n\n\n      \ndependencies\n:\n \n{\n\n          \nMicrosoft.NETCore.App\n:\n \n{\n\n              \ntype\n:\n \nplatform\n,\n\n              \nversion\n:\n \n1.0.1\n\n          \n},\n\n          \nxunit\n:\n \n2.1.0\n,\n\n          \ndotnet-test-xunit\n:\n \n2.2.0-preview2-build1029\n\n      \n},\n\n\n      \nframeworks\n:\n \n{\n\n          \nnetcoreapp1.0\n:\n \n{\n\n              \nimports\n:\n \n[\ndotnet5.6\n,\n \nportable-net45+win8\n]\n\n          \n}\n\n      \n}\n\n  \n}\n\n\n\n\n\n\nthis configuration tells Visual Studio that three packages are required:\n\n\nthe \nMicrosoft.NETCore.App\n package provides the \n.NET Core API\n.\n\n\nthe \nxunit\n package provides the testing framework.\n\n\nthe \ndotnet-test-xunit\n package provides the integration between \nxUnit\n and \nVisual Studio\n.\n\n\n\n\n\n\nadd the main project reference to the dependencies, e.g.\n\n\n1\n2\n3\n4\n5\n6\n7\n  \n{\n\n      \ndependencies\n:\n \n{\n\n          \n...\n\n          \nWorkingWithVisualStudio\n:\n \n1.0.0\n\n          \n...\n\n      \n}\n\n  \n}\n\n\n\n\n\n\n\n\nFact and Theory\n\n\n\n\nIn the \nxUnit\n framework, a \nFact\n is one single unit test. Example:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n  [Fact]\n\n  \npublic\n \nvoid\n \nIndexActionModelIsComplete\n()\n \n{\n\n      \n// Arrange\n\n      \nvar\n \ncontroller\n \n=\n \nnew\n \nHomeController\n();\n\n      \ncontroller\n.\nRepository\n \n=\n \nnew\n \nModelCompleteFakeRepository\n();\n\n\n      \n// Act\n\n      \nvar\n \nmodel\n \n=\n \n(\ncontroller\n.\nIndex\n()\n \nas\n \nViewResult\n)?.\nViewData\n.\nModel\n\n      \nas\n \nIEnumerable\nProduct\n;\n\n\n      \n// Assert\n\n      \nAssert\n.\nEqual\n(\ncontroller\n.\nRepository\n.\nProducts\n,\n \nmodel\n,\n\n          \nComparer\n.\nGet\nProduct\n((\np1\n,\n \np2\n)\n \n=\n \np1\n.\nName\n \n==\n \np2\n.\nName\n\n              \n \np1\n.\nPrice\n \n==\n \np2\n.\nPrice\n));\n\n  \n}\n\n\n\n\n\n\nA \nTheory\n is a way to parametrize the unit test in such a way that it becomes possible to run the same test multiple times, each time with a different set of parameter values. Example:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n  [Theory]\n\n\n  [InlineData(275, 48.95, 19.50, 24.95)]\n\n\n  [InlineData(5, 48.95, 19.50, 24.95)]\n\n  \npublic\n \nvoid\n \nIndexActionModelIsComplete\n(\ndecimal\n \nprice1\n,\n \ndecimal\n \nprice2\n,\n\n  \ndecimal\n \nprice3\n,\n \ndecimal\n \nprice4\n)\n \n{\n\n      \n// Arrange\n\n      \nvar\n \ncontroller\n \n=\n \nnew\n \nHomeController\n();\n\n      \ncontroller\n.\nRepository\n \n=\n \nnew\n \nModelCompleteFakeRepository\n \n{\n\n          \nProducts\n \n=\n \nnew\n \nProduct\n[]\n \n{\n\n              \nnew\n \nProduct\n \n{\nName\n \n=\n \nP1\n,\n \nPrice\n \n=\n \nprice1\n \n},\n\n              \nnew\n \nProduct\n \n{\nName\n \n=\n \nP2\n,\n \nPrice\n \n=\n \nprice2\n \n},\n\n              \nnew\n \nProduct\n \n{\nName\n \n=\n \nP3\n,\n \nPrice\n \n=\n \nprice3\n \n},\n\n              \nnew\n \nProduct\n \n{\nName\n \n=\n \nP4\n,\n \nPrice\n \n=\n \nprice4\n \n},\n\n          \n}\n\n      \n};\n\n\n      \n// Act\n\n      \nvar\n \nmodel\n \n=\n \n(\ncontroller\n.\nIndex\n()\n \nas\n \nViewResult\n)?.\nViewData\n.\nModel\n\n                      \nas\n \nIEnumerable\nProduct\n;\n\n\n      \n// Assert\n\n      \nAssert\n.\nEqual\n(\ncontroller\n.\nRepository\n.\nProducts\n,\n \nmodel\n,\n\n          \nComparer\n.\nGet\nProduct\n((\np1\n,\n \np2\n)\n \n=\n \np1\n.\nName\n \n==\n \np2\n.\nName\n\n              \n \np1\n.\nPrice\n \n==\n \np2\n.\nPrice\n));\n\n  \n}\n\n\n\n\n\n\n\n\nGetting Test Data from a Method or Property\n\n\nWe can create methods or properties giving us the enumerations for the test parameter values in a separate class, e.g. \nProductTestData.cs\n. Then we can use \nMemberData\n attribute to specify it for the unit test to use. Example:\n\n\n1\n2\n3\n[Theory]\n\n\n[ClassData(typeof(ProductTestData))]\n\n\npublic\n \nvoid\n \nIndexActionModelIsComplete\n(\nProduct\n[]\n \nproducts\n \n)\n \n{...}\n\n\n\n\n\n\n\nIf we want to include the test data in the same class as the unit tests, then you can use the \nMemberData\n attribute instead of \nClassData\n. The \nMemberData\n attribute is configured using a string that specifies the name of a static method that will provide an \nIEnumerable\nobject[]\n, where each object array in the sequence is a set of arguments for the test method. Example:\n\n\n1\n2\n3\n[Theory]\n\n\n[MemberData(\nGetData\n)]\n\n\npublic\n \nvoid\n \nIndexActionModelIsComplete\n(\nProduct\n[]\n \nproducts\n \n)\n \n{...}\n\n\n\n\n\n\n\nand the \nGetData\n should look something like this\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\npublic\n \nstatic\n \nIEnumerable\nobject\n[]\n \nGetData\n\n\n{\n\n    \nget\n\n    \n{\n\n        \n// ...\n\n        \nyield\n \nreturn\n \nnew\n \nobject\n[]\n \n{\n \n8\n,\n \n21\n \n};\n\n        \nyield\n \nreturn\n \nnew\n \nobject\n[]\n \n{\n \n16\n,\n \n987\n \n};\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\nEvery \nyield\n statement should return an array of objects to substitute for the Product properties. And the method itself should be of type \nIEnumerable\nobject[]\n.\n\n\n\n\nMocking with MOQ\n\n\nMicrosoft\n created a special fork of the \nMoq\n project and ported it to work with \n.NET Core\n.\n\n\nIn order to be able to install the \nMoq NuGet package\n, we need first to configure the \nNuGet Options\n. Open \nTools | Options | NuGet Package Manager\n, click on \nPackage Sources\n and then on the green plus sign. Configure the new package source as follows:\n\n\n\n\nName: ASP.NET Contrib\n\n\nSource: https://www.myget.org/F/aspnet-contrib/api/v3/index.json\n\n\n\n\nAdd these two packages to the \npackage.json\n in the test project:\n\n\n1\n2\nmoq.netcore\n:\n \n4.4.0-beta8\n\n\nSystem.Diagnostics.TraceSource\n:\n \n4.0.0\n\n\n\n\n\n\n\nUsage example:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n[Fact]\n\n\npublic\n \nvoid\n \nRepositoryPropertyCalledOnce\n()\n\n\n{\n\n    \n// Arrange\n\n    \nvar\n \nmock\n \n=\n \nnew\n \nMock\nIRepository\n();\n\n    \nmock\n.\nSetupGet\n(\nm\n \n=\n \nm\n.\nProducts\n)\n\n        \n.\nReturns\n(\nnew\n[]\n \n{\n \nnew\n \nProduct\n \n{\n \nName\n \n=\n \nP1\n,\n \nPrice\n \n=\n \n100\n \n}\n \n});\n\n    \nvar\n \ncontroller\n \n=\n \nnew\n \nHomeController\n \n{\n \nRepository\n \n=\n \nmock\n.\nObject\n \n};\n\n\n    \n// Act\n\n    \nvar\n \nresult\n \n=\n \ncontroller\n.\nIndex\n();\n\n\n    \n// Assert\n\n    \nmock\n.\nVerifyGet\n(\nm\n \n=\n \nm\n.\nProducts\n,\n \nTimes\n.\nOnce\n);\n\n\n}\n\n\n\n\n\n\n\nExplanation:\n\n\n\n\nvar mock = new Mock\nIRepository\n();\n - define the interface to be mocked\n\n\nSetupGet(m =\n m.Products)\n - specify the property to be tested\n\n\n.Returns(...)\n - specify the test value to be returned\n\n\nRepository = mock.Object\n - \nObject\n is the special property that gives back the object we mock for this test\n\n\nmock.VerifyGet(m =\n m.Products, Times.Once);\n - one of the verify methods to inspect the getter property\n\n\n\n\n\n\nSportsStore\n\n\n\n\nCreate a new empty \nASP.NET Core Web Application (.NET Core)\n project/solution.\n\n\nAdd these packages/tools to the \nproject.json\n file:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n  \ndependencies\n:\n \n{\n\n      \n...\n\n      \nMicrosoft.AspNetCore.Razor.Tools\n:\n \n{\n\n          \nversion\n:\n \n1.0.0-preview2-final\n,\n\n          \ntype\n:\n \nbuild\n\n      \n},\n\n      \nMicrosoft.AspNetCore.StaticFiles\n:\n \n1.0.0\n,\n\n      \nMicrosoft.AspNetCore.Mvc\n:\n \n1.0.1\n\n  \n}\n,\n\n  \ntools\n:\n \n{\n\n      \nMicrosoft.AspNetCore.Razor.Tools\n:\n \n1.0.0-preview2-final\n,\n\n      \n...\n\n  \n}\n,\n\n\n\n\n\n\nIn addition to the packages in the \ndependencies\n section, there is an addition to the \ntools\n section of the \nproject.json\n file that configures the \nMicrosoft.AspNetCore.Razor.Tools\n package for use in Visual Studio and enables IntelliSense for the built-in tag helpers, which are used to create HTML content that is tailored to the configuration of the MVC application.\n\n\nHere is the \nStartup.cs\n:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n  \nusing\n \nMicrosoft.AspNetCore.Builder\n;\n\n  \nusing\n \nMicrosoft.AspNetCore.Hosting\n;\n\n  \nusing\n \nMicrosoft.AspNetCore.Http\n;\n\n  \nusing\n \nMicrosoft.Extensions.DependencyInjection\n;\n\n  \nusing\n \nMicrosoft.Extensions.Logging\n;\n\n\n  \nnamespace\n \nSportsStore\n\n  \n{\n\n      \npublic\n \nclass\n \nStartup\n\n      \n{\n\n          \npublic\n \nvoid\n \nConfigureServices\n(\nIServiceCollection\n \nservices\n)\n\n          \n{\n\n              \nservices\n.\nAddMvc\n();\n\n          \n}\n\n\n          \npublic\n \nvoid\n \nConfigure\n(\nIApplicationBuilder\n \napp\n,\n\n          \nIHostingEnvironment\n \nenv\n,\n \nILoggerFactory\n \nloggerFactory\n)\n\n          \n{\n\n              \napp\n.\nUseDeveloperExceptionPage\n();\n\n              \napp\n.\nUseStatusCodePages\n();\n\n              \napp\n.\nUseStaticFiles\n();\n\n              \napp\n.\nUseMvcWithDefaultRoute\n();\n\n          \n}\n\n      \n}\n\n  \n}\n\n\n\n\n\n\nThe \nConfigureServices\n method is used to set up shared objects that can be used throughout the application through the \ndependency injection\n feature. The \nAddMvc\n method that is called in the \nConfigureServices\n method is an extension method that sets up the shared objects used in MVC applications.\n\n\nThe \nConfigure\n method is used to set up the features that receive and process \nHTTP requests\n.\n\n\nadd these folders: \nModels\n, \nControllers\n, \nViews\n\n\nin the \nViews\n folder add \n_ViewImports.cshtml\n file:\n\n\n1\n2\n  \n@using\n \nSportsStore\n.\nModels\n\n  \n@addTagHelper\n \n*,\n \nMicrosoft\n.\nAspNetCore\n.\nMvc\n.\nTagHelpers\n\n\n\n\n\n\ncreate the unit test project \nSportsStore.Tests\n in the \ntest\n folder.\n\n\nConfigure its \nproject .json\n as follows:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n  \n{\n\n      \nversion\n:\n \n1.0.0-*\n,\n\n      \ntestRunner\n:\n \nxunit\n,\n\n      \ndependencies\n:\n \n{\n\n          \nMicrosoft.NETCore.App\n:\n \n{\n\n              \ntype\n:\n \nplatform\n,\n\n              \nversion\n:\n \n1.0.1\n\n          \n},\n\n          \nxunit\n:\n \n2.1.0\n,\n\n          \ndotnet-test-xunit\n:\n \n2.2.0-preview2-build1029\n,\n\n          \nmoq.netcore\n:\n \n4.4.0-beta8\n,\n\n          \nSystem.Diagnostics.TraceSource\n:\n \n4.0.0\n,\n\n          \nSportsStore\n:\n \n1.0.0\n\n      \n},\n\n      \nframeworks\n:\n \n{\n\n          \nnetcoreapp1.0\n:\n \n{\n\n              \nimports\n:\n \n[\n \ndotnet5.6\n,\n \nportable-net45+win8\n \n]\n\n          \n}\n\n      \n}\n\n  \n}\n\n\n\n\n\n\nMake sure that both \nproject.json\n files refer to the same \nASP.NET Core MVC\n version.\n\n\nAdd your model class \nProduct.cs\n, repository interface \nIProductRepository\n and a simple fake repository \nFakeProductRepository\n\n\nRegister the fake repository as a service in \nStartup.cs\n:\n\n\n1\n2\n3\n4\n5\n  \npublic\n \nvoid\n \nConfigureServices\n(\nIServiceCollection\n \nservices\n)\n\n  \n{\n\n      \nservices\n.\nAddTransient\nIProductRepository\n,\n \nFakeProductRepository\n();\n\n      \n...\n\n  \n}\n\n\n\n\n\n\nAdd the following standard views:\n\n\nViews/Shared/_Layout.cshtml\n\n\nViews/_ViewStart.cshtml\n refering to \n_Layout.cshtml\n by default\n\n\nExample of setting up the default route in \nStartup.cs\n. Substitute\n\n\n1\n  \napp\n.\nUseMvcWithDefaultRoute\n();\n\n\n\n\n\n\nwith\n\n\n1\n2\n3\n4\n5\n6\n  \napp\n.\nUseMvc\n(\nroutes\n \n=\n\n  \n{\n\n      \nroutes\n.\nMapRoute\n(\n\n          \nname\n:\n \ndefault\n,\n\n          \ntemplate\n:\n \n{controller=Product}/{action=List}/{id?}\n);\n\n  \n});\n\n\n\n\n\n\n\n\n\n\nScaffolding\n\n\nSome people prefer to have certain features automatically created when they create new controller or views. That is called \nscaffolding\n. If you want that, add the following packages to the \nproject.json\n file:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n...\n\n\ndependencies\n:\n \n{\n\n    \n...\n\n    \nMicrosoft.AspNetCore.StaticFiles\n:\n \n1.0.0\n,\n\n    \nMicrosoft.AspNetCore.Mvc\n:\n \n1.0.0\n,\n\n    \nMicrosoft.VisualStudio.Web.CodeGeneration.Tools\n:\n \n{\n\n        \nversion\n:\n \n1.0.0-preview2-final\n,\n\n        \ntype\n:\n \nbuild\n\n    \n},\n\n    \nMicrosoft.VisualStudio.Web.CodeGenerators.Mvc\n:\n \n{\n\n        \nversion\n:\n \n1.0.0-preview2-final\n,\n\n        \ntype\n:\n \nbuild\n\n    \n}\n\n\n}\n\n\n...\n\n\ntools\n:\n \n{\n\n    \n...\n\n    \nMicrosoft.VisualStudio.Web.CodeGeneration.Tools\n:\n \n{\n\n        \nversion\n:\n \n1.0.0-preview2-final\n,\n\n        \nimports\n:\n \n[\n\n            \nportable-net45+win8+dnxcore50\n,\n\n            \nportable-net45+win8\n\n        \n]\n\n    \n}\n\n\n}\n\n\n...\n\n\n\n\n\n\n\n\n\nSetup the database\n\n\n\n\nadd \nEntityFramework\n packages to \npackage.json\n:\n\n\n1\n2\n3\n4\n5\n  \ndependencies\n:\n \n{\n\n      \n...\n\n      \nMicrosoft.EntityFrameworkCore.SqlServer\n:\n \n1.0.1\n,\n\n      \nMicrosoft.EntityFrameworkCore.Tools\n:\n \n1.0.0-preview2-final\n\n  \n}\n\n\n\n\n\n\nand the tools:\n\n\n1\n2\n3\n4\n5\n6\n7\n  \ntools\n:\n \n{\n\n      \n...\n\n      \nMicrosoft.EntityFrameworkCore.Tools\n:\n \n{\n\n          \nversion\n:\n \n1.0.0-preview2-final\n,\n\n          \nimports\n:\n \n[\n \nportable-net45+win8+dnxcore50\n,\n \nportable-net45+win8\n \n]\n\n      \n}\n\n  \n}\n\n\n\n\n\n\nThe \ndatabase context class\n is the bridge between the \napplication\n and the \nEF Core\n and provides access to the application\u2019s data using model objects. To create the database context class for the \nSportsStore\n application, we add a class file called \nApplicationDbContext.cs\n to the \nModels\n folder:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n  \nusing\n \nMicrosoft.EntityFrameworkCore\n;\n\n\n  \nnamespace\n \nSportsStore.Models\n\n  \n{\n\n      \npublic\n \nclass\n \nApplicationDbContext\n \n:\n \nDbContext\n\n      \n{\n\n          \npublic\n \nApplicationDbContext\n(\nDbContextOptions\nApplicationDbContext\n \noptions\n)\n\n              \n:\n \nbase\n(\noptions\n)\n \n{\n \n}\n\n          \npublic\n \nDbSet\nProduct\n \nProducts\n \n{\n \nget\n;\n \nset\n;\n \n}\n\n      \n}\n\n  \n}\n\n\n\n\n\n\nTo populate the database initially with some data, we use \nSeedData.cs\n class:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n  \nusing\n \nSystem.Linq\n;\n\n  \nusing\n \nMicrosoft.AspNetCore.Builder\n;\n\n  \nusing\n \nMicrosoft.Extensions.DependencyInjection\n;\n\n  \nnamespace\n \nSportsStore.Models\n\n  \n{\n\n      \npublic\n \nstatic\n \nclass\n \nSeedData\n\n      \n{\n\n          \npublic\n \nstatic\n \nvoid\n \nEnsurePopulated\n(\nIApplicationBuilder\n \napp\n)\n\n          \n{\n\n              \nApplicationDbContext\n \ncontext\n \n=\n\n                  \napp\n.\nApplicationServices\n.\nGetRequiredService\nApplicationDbContext\n();\n\n\n              \nif\n \n(!\ncontext\n.\nProducts\n.\nAny\n())\n\n              \n{\n\n                  \ncontext\n.\nProducts\n.\nAddRange\n(\n\n                  \nnew\n \nProduct\n\n                  \n{\n\n                      \nName\n \n=\n \nKayak\n,\n\n                      \nDescription\n \n=\n \nA boat for one person\n,\n\n                      \nCategory\n \n=\n \nWatersports\n,\n\n                      \nPrice\n \n=\n \n275\n\n                  \n},\n\n                  \n...\n\n\n                  \ncontext\n.\nSaveChanges\n();\n\n              \n}\n\n          \n}\n\n      \n}\n\n  \n}\n\n\n\n\n\n\nThe static \nEnsurePopulated\n method receives an \nIApplicationBuilder\n argument, which is the class used in the \nConfigure\n method of the \nStartup\n class to register middleware classes to handle HTTP requests, which is where we ensure that the database has content.\n\n\nThe \nEnsurePopulated\n method obtains an \nApplicationDbContext\n object through the \nIApplicationBuilder\n interface and uses it to check whether there are any \nProduct\n objects in the database. If there are no objects, then the database is populated using a collection of \nProduct\n objects using the \nAddRange\n method and then written to the database using the \nSaveChanges\n method.\n\n\nThe next step is to create a class that implements the \nIProductRepository\n interface and gets its data using \nEntity Framework Core\n from the \nApplicationDbContext\n.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n  \nusing\n \nSystem.Collections.Generic\n;\n\n\n  \nnamespace\n \nSportsStore.Models\n\n  \n{\n\n      \npublic\n \nclass\n \nEFProductRepository\n \n:\n \nIProductRepository\n\n      \n{\n\n          \nprivate\n \nApplicationDbContext\n \ncontext\n;\n\n          \npublic\n \nEFProductRepository\n(\nApplicationDbContext\n \nctx\n)\n\n          \n{\n\n              \ncontext\n \n=\n \nctx\n;\n\n          \n}\n\n          \npublic\n \nIEnumerable\nProduct\n \nProducts\n \n=\n \ncontext\n.\nProducts\n;\n\n      \n}\n\n  \n}\n\n\n\n\n\n\ncreate \nappsettings.json\n file in the project root folder based on the \nASP.NET Configuration File\n template and configure the connection string:\n\n\n1\n2\n3\n4\n5\n6\n7\n  \n{\n\n      \nData\n:\n \n{\n\n          \nSportStoreProducts\n:\n \n{\n\n              \nConnectionString\n:\n \nServer=(localdb)\\\\MSSQLLocalDB;Database=SportsStore;Trusted_Connection=True;MultipleActiveResultSets=true\n\n          \n}\n\n      \n}\n\n  \n}\n\n\n\n\n\n\nadd a new dependency to read the \njson\n configuration file:\n\n\n1\n2\n3\n4\n  \ndependencies\n:\n \n{\n\n      \n...\n\n      \nMicrosoft.Extensions.Configuration.Json\n:\n \n1.0.0\n\n  \n}\n,\n\n\n\n\n\n\nconfigure the \nStartup.cs\n:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n  \n...\n\n  \nusing\n \nMicrosoft.EntityFrameworkCore\n;\n\n  \nusing\n \nMicrosoft.Extensions.Configuration\n;\n\n\n  \nnamespace\n \nSportsStore\n\n  \n{\n\n      \npublic\n \nclass\n \nStartup\n\n      \n{\n\n          \nIConfigurationRoot\n \nConfiguration\n;\n\n\n          \npublic\n \nStartup\n(\nIHostingEnvironment\n \nenv\n)\n\n          \n{\n\n              \nConfiguration\n \n=\n \nnew\n \nConfigurationBuilder\n()\n\n                  \n.\nSetBasePath\n(\nenv\n.\nContentRootPath\n)\n\n                  \n.\nAddJsonFile\n(\nappsettings.json\n).\nBuild\n();\n\n          \n}\n\n\n          \npublic\n \nvoid\n \nConfigureServices\n(\nIServiceCollection\n \nservices\n)\n\n          \n{\n\n              \nservices\n.\nAddDbContext\nApplicationDbContext\n(\noptions\n \n=\n\n                  \noptions\n.\nUseSqlServer\n(\nConfiguration\n[\nData:SportStoreProducts:ConnectionString\n]));\n\n              \nservices\n.\nAddTransient\nIProductRepository\n,\n \nEFProductRepository\n();\n\n              \n...\n\n          \n}\n\n\n          \npublic\n \nvoid\n \nConfigure\n(\n\n              \nIApplicationBuilder\n \napp\n,\n\n              \nIHostingEnvironment\n \nenv\n,\n\n              \nILoggerFactory\n \nloggerFactory\n)\n\n          \n{\n\n              \n...\n\n              \nSeedData\n.\nEnsurePopulated\n(\napp\n);\n\n          \n}\n\n      \n}\n\n  \n}\n\n\n\n\n\n\nopen \nTools | Nuget Package Manager | Package Manager Console\n to create and apply database migrations:\n\n\n1\n2\n  Add-Migration Initial\n  Update-Database\n\n\n\n\n\nrebuild the solution and run - we will see the list of products loaded from the database.\n\n\n\n\n\n\nViewModels and TagHelpers\n\n\n\n\nIf we want to customize the information to be used in the view, we can do that with \nViewModels\n. For that we create a \nViewModels\n subfolder inside the \nModels\n folder. They can \nbe registered\n in \n_ViewImports.cshtml\n.\n\n\nTagHelpers\n are one of the most useful ways that you can introduce C# logic into your views. The code for a tag helper can look tortured because C# and HTML don\u2019t mix easily. But using tag helpers is preferable to including blocks of C# code in a view because a tag helper can be easily \nunit tested\n. Most MVC components, such as controllers and views, are discovered automatically, but tag helpers \nhave to be registered\n in \n_ViewImports.cshtml\n.\n\n\nTo test the \ntag helper\n class, I call the \nProcess\n method with test data and provide a \nTagHelperOutput\n object that is inspected to see the HTML that was generated.\n\n\nWhen we pass the data to the view via a view model, we need to replace the type. E.g. it can become \n@model ProductsListViewModel\n and \nModel.Products\n instead of \n@model IEnumerable\nProduct\n and \nModel\n.\n\n\n\n\n\n\nInstalling Bootstrap package\n\n\nAdd \nbower.json\n file to the project root:\n\n\n1\n2\n3\n4\n5\n6\n7\n{\n\n    \nname\n:\n \nasp.net\n,\n\n    \nprivate\n:\n \ntrue\n,\n\n    \ndependencies\n:\n \n{\n\n        \nbootstrap\n:\n \n3.3.7\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\nThis will add \nwwwroot/lib\n folder and inside it \nbootstrap\n and \njquery\n sources.\n\n\n\n\nImproving the URLs\n\n\nNormally, the page links look like this:\n\n\nhttp://localhost/?page=2\n\n\nBut we can make them more user friendly by creating a scheme that follows the pattern of \ncomposable URLs\n, which look like this:\n\n\nhttp://localhost/Page2\n\n\nTo do that we register a new route in our MVC middleware (\nConfigure\n method in \nStartup.cs\n):\n\n\n1\n2\n3\n4\nroutes\n.\nMapRoute\n(\n\n    \nname\n:\n \npagination\n,\n\n    \ntemplate\n:\n \nProducts/Page{page}\n,\n\n    \ndefaults\n:\n \nnew\n \n{\n \nController\n \n=\n \nProduct\n,\n \naction\n \n=\n \nList\n \n});\n\n\n\n\n\n\n\nIt is important that this route is added \nbefore\n the default route.\n\n\n\n\nEnabling Sessions\n\n\nAdd these new packages to the \npackage.json\n:\n\n\n1\n2\n3\nMicrosoft.AspNetCore.Session\n:\n \n1.0.0\n,\n\n\nMicrosoft.Extensions.Caching.Memory\n:\n \n1.0.0\n,\n\n\nMicrosoft.AspNetCore.Http.Extensions\n:\n \n1.0.0\n\n\n\n\n\n\n\nRegister new services and middleware to the \nStartup.cs\n:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\npublic\n \nvoid\n \nConfigureServices\n(\nIServiceCollection\n \nservices\n)\n \n{\n\n    \n...\n\n    \nservices\n.\nAddMemoryCache\n();\n\n    \nservices\n.\nAddSession\n();\n\n    \nservices\n.\nAddMvc\n();\n\n\n}\n\n\n\npublic\n \nvoid\n \nConfigure\n(\nIApplicationBuilder\n \napp\n,\n\n    \n...\n\n    \napp\n.\nUseSession\n();\n\n    \napp\n.\nUseMvc\n(...);\n\n\n}\n\n\n\n\n\n\n\n\n\nAddMemoryCache\n\n\nThe \nAddMemoryCache\n method call sets up the in-memory data store. The \nAddSession\n method registers the services used to access session data, and the \nUseSession\n method allows the session system to automatically associate requests with sessions when they arrive from the client.\n\n\n\n\n\n\nAnnotations\n\n\n\n\nBindNever\n attribute prevents the user supplying values for these properties in an HTTP request.\n\n\n\n\nAdding migrations\n\n\nSuppose we add a new \nDbSet\n to our \nApplicationDbContext.cs\n:\n\n\n1\n2\n3\n4\n5\n6\n7\npublic\n \nclass\n \nApplicationDbContext\n \n:\n \nDbContext\n\n\n{\n\n    \npublic\n \nApplicationDbContext\n(\nDbContextOptions\nApplicationDbContext\n \noptions\n)\n\n        \n:\n \nbase\n(\noptions\n)\n \n{\n \n}\n\n    \n...\n\n    \npublic\n \nDbSet\nOrder\n \nOrders\n \n{\n \nget\n;\n \nset\n;\n \n}\n\n\n}\n\n\n\n\n\n\n\nTo create the \nmigration\n, open the NuGet \nPackage Manger Console\n from the \nTools \u27a4 NuGet Package Manage\n menu and run the following command :\n\n\nAdd-Migration Orders\n\n\nThis command tells EF Core to take a new snapshot of the application, work out how it differs from the previous database version, and generate a new migration called \nOrders\n. The name \nOrders\n here is arbitrary but it is handy to let it reflect the change.\n\n\nTo update the database schema, run the following command:\n\n\nUpdate-Database\n\n\n\n\nResetting the Database\n\n\nWhen you are making frequent changes to the model, there will come a point when your migrations and your database schema get out of sync. The easiest thing to do is delete the database and start over. However, this applies \nonly during development\n, of course, because you will lose any data you have stored.\n\n\n\n\nSelect the \nSQL Server Object Explorer\n item from the Visual Studio \nView\n menu and click the \nAdd Sql Server\n button.\n\n\nEnter \n(localdb)\\mssqllocaldb\n into the \nServer Name\n field and click the \nConnect\n button. A new item will appear in the \nSQL Server Object Explorer\n window, which you can expand to see the \nLocalDB\n databases that have been created.\n\n\nRight-click the database you want to remove and select \nDelete\n from the pop-up menu. \nCheck the option to close the existing connections\n and then click the \nOK\n button to delete the database.\n\n\nOnce the database has been removed, run the following command from the \nPackage Manager Console\n to create the database and apply the migrations you have created by running the following command:\n\n\n\n\nUpdate-Database\n\n\n\n\nThis will reset the database so that it accurately reflects your model and allow you to return to developing your application.\n\n\n\n\n\n\nUsing TempData\n\n\nWe are using TempData in the POST method in a controller:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n[HttpPost]\n\n\npublic\n \nIActionResult\n \nEdit\n(\nProduct\n \nproduct\n)\n\n\n{\n\n    \nif\n \n(\nModelState\n.\nIsValid\n)\n\n    \n{\n\n        \n_repository\n.\nSaveProduct\n(\nproduct\n);\n\n        \nTempData\n[\nmessage\n]\n \n=\n \n$\n{product.Name} has been saved\n;\n\n        \nreturn\n \nRedirectToAction\n(\nIndex\n);\n\n    \n}\n\n    \nelse\n\n    \n{\n\n        \n// there is something wrong with the data values\n\n        \nreturn\n \nView\n(\nproduct\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\nWe check that the model binding process has been able to validate the data submitted to the user by reading the value of the \nModelState.IsValid\n property. If everything is OK, we save the changes to the repository and redirect the user to the \nIndex\n action so they see the modified list of products. If there is a problem with the data, we render the default view again so that the user can make corrections.\n\n\nAfter we have saved the changes in the repository, we store a message using the \nTempData\n feature, which is part of the \nASP.NET Core session state\n feature. This is a \nkey/value\n dictionary similar to the \nsession data\n and \nview bag\n features we used previously.\n\n\nThe key difference from \nsession data\n is that \ntemp data\n persists until it is read. We cannot use \nViewBag\n in this situation because \nViewBag\n passes data between the \ncontroller\n and \nview\n, and it cannot hold data for longer than \nthe current HTTP request\n. When an edit succeeds, the browser is redirected to a new URL, so the \nViewBag\n data is lost.\n\n\nWe could use the \nsession data\n feature, but then the message would be persistent until we explicitly removed it, which we would rather not have to do.\n\n\nSo, the \ntemp data\n feature is the perfect fit. The data is restricted to a \nsingle user\u2019s session\n (so that users do not see each other\u2019s \nTempData\n) and will persist long enough for us to read it. We will read the data in the \nview\n rendered by the \naction method\n to which we redirect the user\n\n\nThe message will be displayed once and disappear if you reload the screen with the template using this \ntemp data\n, because \nTempData\n is deleted when it is read. That is convenient since we do not want old messages hanging around.\n\n\n\n\nLocalization hell\n\n\nBy the time we get to editing with validation, something bad happens. It looks that by default the \njQuery-validation\n (client side validation) expects \nen-US\n as its culture and the server side validation expects \nnl-NL\n. Therefore, when I see \n\u20ac\n as currency and \n,\n as decimal separator, I cannot change the price. Neither \n,\n nor \n.\n are accepted. One is rejected by the client side and the other by the server side validation.\n\n\nTemporary workaround was to configure \nen-US\n as the default culture, so that \n$\n and \n.\n are displayed on the screen. Then the validation works.\n\n\n\n\nAdding Identity\n\n\nAdd a new dependency to \nproject.json\n:\n\n\n1\n2\n3\n4\ndependencies\n:\n \n{\n\n    \n...\n\n    \nMicrosoft.AspNetCore.Identity.EntityFrameworkCore\n:\n \n1.0.0\n\n\n}\n\n\n\n\n\n\n\nAdd a new \nAppIdentityDbContext\n class to \nModels\n folder:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\nusing\n \nMicrosoft.AspNetCore.Identity.EntityFrameworkCore\n;\n\n\nusing\n \nMicrosoft.EntityFrameworkCore\n;\n\n\n\nnamespace\n \nSportsStore.Models\n\n\n{\n\n    \npublic\n \nclass\n \nAppIdentityDbContext\n \n:\n \nIdentityDbContext\nIdentityUser\n\n    \n{\n\n        \npublic\n \nAppIdentityDbContext\n(\nDbContextOptions\nAppIdentityDbContext\n \noptions\n)\n\n            \n:\n \nbase\n(\noptions\n)\n \n{\n \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\nand a new connection string in \nappsettings.json\n file:\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n{\n\n    \nData\n:\n \n{\n\n        \n...\n\n        \nSportStoreIdentity\n:\n \n{\n\n            \nConnectionString\n:\n \nServer=(localdb)\\\\MSSQLLocalDB;Database=Identity;Trusted_Connection=True;MultipleActiveResultSets=true\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\nAdd new services to \nConfigureServices\n in \nStartup.cs\n:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\npublic\n \nvoid\n \nConfigureServices\n(\nIServiceCollection\n \nservices\n)\n\n\n{\n\n    \n...\n\n    \nservices\n.\nAddDbContext\nAppIdentityDbContext\n(\noptions\n \n=\n\n        \noptions\n.\nUseSqlServer\n(\nConfiguration\n[\nData:SportStoreIdentity:ConnectionString\n]));\n\n\n    \nservices\n.\nAddIdentity\nIdentityUser\n,\n \nIdentityRole\n()\n\n        \n.\nAddEntityFrameworkStores\nAppIdentityDbContext\n();\n\n    \n...\n\n\n}\n\n\n\n\n\n\n\nand new entries in \nConfigure\n:\n\n\n1\n2\n3\n4\n5\n6\npublic\n \nvoid\n \nConfigure\n()\n\n    \napp\n.\nUseIdentity\n();\n\n    \napp\n.\nUseMvc\n();\n\n    \nSeedData\n.\nEnsurePopulated\n(\napp\n);\n\n    \nIdentitySeedData\n.\nEnsurePopulated\n(\napp\n);\n\n\n}\n\n\n\n\n\n\n\nIdentitySeedData\n should be created in the \nModels\n folder to create an administrative account.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\nusing\n \nMicrosoft.AspNetCore.Builder\n;\n\n\nusing\n \nMicrosoft.AspNetCore.Identity\n;\n\n\nusing\n \nMicrosoft.AspNetCore.Identity.EntityFrameworkCore\n;\n\n\nusing\n \nMicrosoft.Extensions.DependencyInjection\n;\n\n\n\nnamespace\n \nSportsStore.Models\n\n\n{\n\n    \npublic\n \nstatic\n \nclass\n \nIdentitySeedData\n\n    \n{\n\n        \nprivate\n \nconst\n \nstring\n \nadminUser\n \n=\n \nAdmin\n;\n\n        \nprivate\n \nconst\n \nstring\n \nadminPassword\n \n=\n \nSecret123$\n;\n\n\n        \npublic\n \nstatic\n \nasync\n \nvoid\n \nEnsurePopulated\n(\nIApplicationBuilder\n \napp\n)\n\n        \n{\n\n            \nUserManager\nIdentityUser\n \nuserManager\n \n=\n \napp\n.\nApplicationServices\n\n                \n.\nGetRequiredService\nUserManager\nIdentityUser\n();\n\n\n            \nIdentityUser\n \nuser\n \n=\n \nawait\n \nuserManager\n.\nFindByIdAsync\n(\nadminUser\n);\n\n\n            \nif\n \n(\nuser\n \n==\n \nnull\n)\n\n            \n{\n\n                \nuser\n \n=\n \nnew\n \nIdentityUser\n(\nAdmin\n);\n\n                \nawait\n \nuserManager\n.\nCreateAsync\n(\nuser\n,\n \nadminPassword\n);\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\n\nAdding Identity migrations\n\n\n\n\nAdd-Migration Initial -Context AppIdentityDbContext\n\n\nUpdate-Database -Context AppIdentityDbContext\n\n\n\n\nThis will create the new database and add the \nAspNetUsers\n and \nAspNetRoles\n in it.\n\n\n\n\nAdding Authorization\n\n\nWhen \nASP.NET Core Identity\n is in place, we can apply \nAuthorization\n. We don\u2019t want to stop unauthenticated users from accessing the other action methods in the \nOrder\n controller, so we have applied the \nAuthorize\n attribute only to the \nList\n and \nMarkShipped\n methods.\n\n\n1\n2\n3\n4\n5\n6\n7\n[Authorize]\n\n\npublic\n \nViewResult\n \nList\n()\n \n=\n\n    \nView\n(\n_repository\n.\nOrders\n.\nWhere\n(\no\n \n=\n \n!\no\n.\nShipped\n));\n\n\n\n[HttpPost]\n\n\n[Authorize]\n\n\npublic\n \nIActionResult\n \nMarkShipped\n(\nint\n \norderID\n)\n \n{...}\n\n\n\n\n\n\n\nWe want to protect \nall of the action methods\n defined by the \nAdmin\n controller, and we can do this by applying the \nAuthorize\nattribute to the controller class, which then applies the authorization policy to all the action methods it contains.\n\n\n1\n2\n3\n[Authorize]\n\n\npublic\n \nclass\n \nAdminController\n \n:\n \nController\n\n\n{...}\n\n\n\n\n\n\n\n\n\nCaution\n\n\nIn general, using client-side data validation is a good idea. It offloads some of the work from your server and gives users immediate feedback about the data they are providing. However, you should not be tempted to perform authentication at the client, as this would typically involve sending valid credentials to the client so they can be used to check the username and password that the user has entered, or at least trusting the client\u2019s report of whether they have successfully authenticated. Authentication should always be done at the server.\n\n\n\n\n\n\nSources used\n\n\n\n\nAdam Freeman - Pro ASP.NET Core MVC (2016)\n\n\nChristian Nagel - Professional C# 6 and .NET Core 1.0 (2016)", 
            "title": "Notes"
        }, 
        {
            "location": "/dotnet/notes/#notes-on-aspnet-core", 
            "text": "I have written these notes while working on a couple of great books on the subject. See  Sources used .  Models  - the  M  in  MVC  - contain the data that users work with. There are two broad types of model:   view models , which represent just data passed from the controller to the view, and  domain models , which contain the data in a business domain, along with the operations, transformations, and rules for creating, storing, and manipulating that data, collectively referred to as the model logic.   In ASP.NET Core MVC,  controllers  are C# classes, usually derived from the  Microsoft.AspNetCore.Mvc.Controller  class. Each  public  method in a class derived from  Controller  is an  action method , which is associated with a  URL .", 
            "title": "Notes on ASP.NET Core"
        }, 
        {
            "location": "/dotnet/notes/#conventions", 
            "text": "put the third-party JavaScript and CSS packages you rely on in the  wwwroot/lib  folder.  convention over configuration  the controller for  /product  uri should have the name  ProductController.cs  and reside in the  /Controllers  folder; from other parts in the project, such as when using an HTML helper method, you specify the first part of the name ( Product ), and MVC automatically appends  Controller  to the name and starts looking for the controller class.  views for  /product  uri associated with  ProductController  should all reside in the  /Views/Product  folder.  MVC expects that the  default view  for an  action method  should be named after that method. For example, the default view associated with an action method called  List  should be called  List.cshtml . Thus, for the  List action method  in the  ProductController  class, the  default view  is expected to be  /Views/Product/List.cshtml . The  default view  is used when you return the result of calling the  View  method in an action method, like this:   1    return   View ();    You can specify a different view by name, like this:  1    return   View ( MyOtherView );     When looking for a  view , MVC looks in the folder named after the controller and then in the  /Views/Shared  folder. This means that I can put views that will be used by more than one controller in the  /Views/Shared  folder and MVC will find them.  The naming convention for  layouts  is to prefix the file with an underscore ( _ ) character, and layout files are placed in the  /Views/Shared  folder. This layout is applied to all views by default through the  /Views/_ViewStart.cshtml  file. If you do not want the default layout applied to views, you can change the settings in  ViewStart.cshtml  (or delete the file entirely) to specify another layout in the view, like this:   1\n2\n3    @ { \n     Layout   =   ~/_MyLayout.cshtml ; \n   }     Or you can disable any layout for a given view, like this:   1\n2\n3    @ { \n     Layout   =   null ; \n   }", 
            "title": "Conventions"
        }, 
        {
            "location": "/dotnet/notes/#extension-methods", 
            "text": "", 
            "title": "Extension methods"
        }, 
        {
            "location": "/dotnet/notes/#class-extensions", 
            "text": "Suppose we have a simple class:  1\n2\n3\n4\n5\n6\n7\n8\n9 using   System.Collections.Generic ;  namespace   LanguageFeatures.Models  { \n     public   class   ShoppingCart \n     { \n         public   IEnumerable Product   Products   {   get ;   set ;   } \n     }  }    We want to extend its functionality with a new method to calculate the total amount:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 public   static   decimal   TotalPrices ( this   ShoppingCart   cartParam )  { \n     decimal   total   =   0 ; \n\n     foreach   ( Product   prod   in   cartParam . Products ) \n     { \n         total   +=   prod ?. Price   ??   0 ; \n     } \n     return   total ;  }    We can then use this extension method like this:  1\n2 ShoppingCart   cart   =   new   ShoppingCart   {   Products   =   Product . GetProducts ()   };  decimal   cartTotal   =   cart . TotalPrices ();", 
            "title": "Class extensions"
        }, 
        {
            "location": "/dotnet/notes/#interface-extensions", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20 using   System.Collections ;  using   System.Collections.Generic ;  namespace   LanguageFeatures.Models  { \n     public   class   ShoppingCart   :   IEnumerable Product \n     { \n         public   IEnumerable Product   Products   {   get ;   set ;   } \n\n         public   IEnumerator Product   GetEnumerator () \n         { \n            return   Products . GetEnumerator (); \n         } \n\n         IEnumerator   IEnumerable . GetEnumerator () \n         { \n             return   GetEnumerator (); \n         } \n     }  }    We can rewrite our extension method like this:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 public   static   decimal   TotalPrices ( this   IEnumerable Product   products )  { \n     decimal   total   =   0 ; \n\n     foreach   ( Product   prod   in   products ) \n     { \n         total   +=   prod ?. Price   ??   0 ; \n     } \n     return   total ;  }    and use it with any object of type  IEnumerable Product  like  ShoppingCart  and  Product  array:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 ShoppingCart   cart   =   new   ShoppingCart   {   Products   =   Product . GetProducts ()   };  Product []   productArray   =  { \n     new   Product   { Name   =   Kayak ,   Price   =   275 M }, \n     new   Product   { Name   =   Lifejacket ,   Price   =   48.95 M }  };  decimal   cartTotal   =   cart . TotalPrices ();  decimal   arrayTotal   =   productArray . TotalPrices ();", 
            "title": "Interface extensions"
        }, 
        {
            "location": "/dotnet/notes/#filtering", 
            "text": "Extension methods can be used to  filter  collections of objects. An extension method that operates on an  IEnumerable T  and that also returns an  IEnumerable T  can use the  yield  keyword to apply selection criteria to items in the source data to produce a reduced set of results.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20 using   System.Collections.Generic ;  namespace   LanguageFeatures.Models  { \n     public   static   class   MyExtensionMethods \n     { \n         public   static   IEnumerable Product   FilterByPrice ( \n             this   IEnumerable Product   productEnum , \n             decimal   minimumPrice ) \n         { \n             foreach   ( Product   prod   in   productEnum ) \n             { \n                 if   (( prod ?. Price   ??   0 )   =   minimumPrice ) \n                 { \n                     yield   return   prod ; \n                 } \n             } \n         } \n     }  }", 
            "title": "Filtering"
        }, 
        {
            "location": "/dotnet/notes/#lambda-anonymous-functions", 
            "text": "We can repeat this process indefinitely and create a different filter method for every property and every combination of properties that we are interested in. A more elegant approach is to separate out the code that processes the enumeration from the selection criteria. C# makes this easy by allowing functions to be passed around as objects. We can then create a single extension method that filters an enumeration of Product objects but that delegates the decision about which ones are included in the results to a separate function.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 public   static   IEnumerable Product   Filter ( \n     this   IEnumerable Product   productEnum , \n     Func Product ,   bool   selector )  { \n     foreach   ( Product   prod   in   productEnum ) \n     { \n         if   ( selector ( prod )) \n         { \n             yield   return   prod ; \n         } \n     }  }    Now, we can use this  Filter  function as follows:  1\n2\n3\n4\n5\n6 decimal   priceFilterTotal   =   productArray \n     . Filter ( p   =   ( p ?. Price   ??   0 )   =   20 ) \n     . TotalPrices ();  decimal   nameFilterTotal   =   productArray \n     . Filter ( p   =   p ?. Name ?[ 0 ]   ==   S ) \n     . TotalPrices ();    Lambdas  can also be used in class properties, e.g.:  1 public   bool   NameBeginsWithS   =   Name ?[ 0 ]   ==   S ;", 
            "title": "Lambda anonymous functions"
        }, 
        {
            "location": "/dotnet/notes/#asynchronous-methods", 
            "text": "Add  System.Net.Http :  4.1.0  dependency in  project.json .  Here is how we could make an asynchronous call  the hard way :   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 public   static   Task long?   GetPageLengthWithoutAsyncAwait ()  { \n     HttpClient   client   =   new   HttpClient (); \n     var   httpTask   =   client . GetAsync ( http://apress.com ); \n     // we could do other things here while the HTTP request is performed \n     return   httpTask . ContinueWith (( Task HttpResponseMessage   antecedent )   = \n     { \n         return   antecedent . Result . Content . Headers . ContentLength ; \n     });  }    And here is the clever way:  1\n2\n3\n4\n5\n6\n7 public   static   async   Task long?   GetPageLength ()  { \n     HttpClient   client   =   new   HttpClient (); \n     var   httpMessage   =   await   client . GetAsync ( http://apress.com ); \n     // we could do other things here while the HTTP request is performed \n     return   httpMessage . Content . Headers . ContentLength ;  }    And we could use this in our controller:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15 using   LanguageFeatures.Models ;  using   Microsoft.AspNetCore.Mvc ;  using   System.Threading.Tasks ;  namespace   LanguageFeatures.Controllers  { \n     public   class   HomeController   :   Controller \n     { \n         public   async   Task ViewResult   Index () \n         { \n             long?   length   =   await   MyAsyncMethods . GetPageLength (); \n             return   View ( new   string []   {   $ Length: {length}   }); \n         } \n     }  }", 
            "title": "Asynchronous methods"
        }, 
        {
            "location": "/dotnet/notes/#getting-property-names-with-nameof", 
            "text": "If we use lambdas the classic way:  1 products . Select ( p   =   $ Name: {p.Name}, Price: {p.Price} )    we of course get no intellisense on  Name:  and  Price: . So, if we change the property name in the class and forget to change these strings here, we get a mismatch.  Fortunately, we can now rewrite the same code like this:  1 products . Select ( p   =   $ {nameof(p.Name)}: {p.Name}, {nameof(p.Price)}: {p.Price} )    but then we will get intellisense and type safety.", 
            "title": "Getting property names with nameof"
        }, 
        {
            "location": "/dotnet/notes/#workflow-with-an-empty-project", 
            "text": "create a new empty ASP.NET Core project  add  Microsoft.AspNetCore.Mvc :  1.0.1  dependency in  project.json  add  System.Net.Http :  4.1.0  dependency in  project.json  add  Mvc  to  Startup.cs :    1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20 using   Microsoft.AspNetCore.Builder ;  using   Microsoft.AspNetCore.Hosting ;  using   Microsoft.Extensions.DependencyInjection ;  using   Microsoft.Extensions.Logging ;  namespace   LanguageFeatures  { \n     public   class   Startup \n     { \n         public   void   ConfigureServices ( IServiceCollection   services ) \n         { \n             services . AddMvc (); \n         } \n\n         public   void   Configure ( IApplicationBuilder   app ,   IHostingEnvironment   env ,   ILoggerFactory   loggerFactory ) \n         { \n             app . UseMvcWithDefaultRoute (); \n         } \n     }  }", 
            "title": "Workflow with an empty project"
        }, 
        {
            "location": "/dotnet/notes/#the-json-configuration-files", 
            "text": "Name  Description      global.json  This file, which is found in the Solution Items folder, is responsible for telling Visual Studio where to find the projects in the solution and which version of the .NET execution environment should be used to run the application.    launchSettings.json  This file, which is revealed by expanding the Properties item in the MVC application project, is used to specify how the application is started.    appsettings.json  This file is used to define application-specific settings.    bower.json  This file is used by Bower to list the client-side packages that are installed into the project.    bundleconfig.json  This file is used to bundle and minify JavaScript and CSS files.    project.json  This file is used to specify the NuGet packages that are installed into the application. This file is also used for other project settings.    project.lock.json  This file, which is revealed by expanding the project.json item in the Solution Explorer, contains detailed dependencies between packages installed in the project. It is generated automatically and should not be edited manually.", 
            "title": "The JSON Configuration Files"
        }, 
        {
            "location": "/dotnet/notes/#razor", 
            "text": "", 
            "title": "Razor"
        }, 
        {
            "location": "/dotnet/notes/#view-imports-file", 
            "text": "Use  _ViewImports.cshtml  file in the  Views  folder to specify the standard include namespaces. Then you can omit them in the individual views.", 
            "title": "View Imports File"
        }, 
        {
            "location": "/dotnet/notes/#view-start-file", 
            "text": "Normally, we have to specify the layout file we want in every view. Therefore, if we need to rename the layout file, we are going to have to find every view that refers to it and make a change, which will be an error-prone process and counter to the general theme of easy maintenance that runs through MVC development.  We can resolve this by using a  view start file . When it renders a view, MVC will look for a file called  _ViewStart.cshtml  and we can put it in the  Views  folder. The contents of this file will be treated as though they were contained in the view file itself, and we can use this feature to automatically set a value for the Layout property.  1\n2\n3 @ { \n     Layout   =   _BasicLayout ;  }    Now, in the views that should use this  _BasicLayout , we can omit the layout line.  We do not have to specify that we want to use the view start file. MVC will locate the file and use its contents automatically. The values defined in the view file take precedence, which makes it easy to override the view start file.  We can also use  multiple view start files  to set defaults for different parts of the application. Razor looks for the closest view start file to the view that it being processed, which means that you can override the default setting by adding a view start file to the  Views/Home  or  Views/Shared  folders, for example.   Caution  It is important to understand the difference between  omitting the Layout property  from the view file and  setting it to null . If your view is self-contained and you do not want to use a layout, then set the Layout property to null. If you omit the Layout property, then MVC will assume that you do want a layout and that it should use the value it finds in the view start file.", 
            "title": "View Start File"
        }, 
        {
            "location": "/dotnet/notes/#viewbag-property", 
            "text": "The  ViewBag  property returns a  dynamic object  that can be used to define arbitrary properties. Since the  ViewBag  is dynamic, we don\u2019t have to declare the property names in advance, but it does mean that Visual Studio is unable to provide autocomplete suggestions for view bag properties.", 
            "title": "ViewBag property"
        }, 
        {
            "location": "/dotnet/notes/#attribute-values", 
            "text": "We can also use Razor expressions to set the value of  element attributes , not only on the content.  1\n2\n3\n4\n5 div data-productid= @Model.ProductID  data-stocklevel= @ViewBag.StockLevel \n     p Product Name: @Model.Name /p \n     p Product Price: @($ {Model.Price:C2} ) /p \n     p Stock Level: @ViewBag.StockLevel /p  /div", 
            "title": "Attribute values"
        }, 
        {
            "location": "/dotnet/notes/#switch-statement", 
            "text": "We have to cast the dynamic ViewBag properties to the right type once, inside the condition:  1 @switch ((int)ViewBag.StockLevel) {...}   After that, inside the body, we dont need to do it any more:  1\n2\n3 default:\n    @: @ViewBag.StockLevel in Stock\n    break;   We do not have to put the elements or expressions in quotes or denote them in any special way\u2014the Razor engine will interpret these as output to be processed. However, if we want to insert literal text into the view when it is not contained in an HTML element, then we need to give Razor a helping hand and prefix the line with an  @  character (see above).", 
            "title": "Switch statement"
        }, 
        {
            "location": "/dotnet/notes/#visual-studio-tips-and-tricks", 
            "text": "", 
            "title": "Visual Studio tips and tricks"
        }, 
        {
            "location": "/dotnet/notes/#enable-developer-exception-page", 
            "text": "In  Startup.cs  add this line to the  Configure  method:  1 app . UseDeveloperExceptionPage ();", 
            "title": "Enable Developer Exception Page"
        }, 
        {
            "location": "/dotnet/notes/#browser-link-loader", 
            "text": "Add  1 Microsoft.VisualStudio.Web.BrowserLink.Loader :   14.0.0    to  project.json  dependencies list. Also add  1 app . UseBrowserLink ();    to the  Configure  method of  Startup.cs .  Run the project without debugging (Ctrl + F5) and you see this kind of code added to the HTML:  1\n2\n3\n4\n5\n6\n7\n8\n9 !-- Visual Studio Browser Link --  script   type = application/json   id = __browserLink_initializationData \n     { requestId : 497a61f26544432a857e06ab5d501b7f , requestMappingFromServer : false }  / script  script   type = text/javascript \n         src = http://localhost:2701/029471b4ee954e43adc0d452954d080f/browserLink \n         async = async  / script  !-- End Browser Link --     Alas  I still see no added value to it. :( Unless it is just the synchronized browsing using multiple browsers. I also see this error in the browser console:  [14:07:17 GMT+0200 (West-Europa (zomertijd))] Browser Link: Failed to invoke return value  callback: TypeError: Cannot read property 'files' of null", 
            "title": "Browser Link Loader"
        }, 
        {
            "location": "/dotnet/notes/#static-files", 
            "text": "ASP.NET Core includes support for delivering  static files  from the wwwroot folder to clients but it isn\u2019t enabled by default when the Empty template is used to create the project. To enable static file support, add  1 Microsoft.AspNetCore.StaticFiles :   1.0.0    to  project.json  dependencies list. Also add  1 app . UseStaticFiles ();    to the  Configure  method of  Startup.cs .", 
            "title": "Static files"
        }, 
        {
            "location": "/dotnet/notes/#bundling-and-minifying", 
            "text": "Install  Bundler and Minifier  extension for the Visual Studio. After that it is possible to add  css  or  js  files to the bundle by selecting them one by one and choosing  Bundler   Minifier | Bundle and Minify Files (Shift + Alt + F)  from the right mouse button menu.  This will create a  bundle.css  or  bundle.js  file and also  bundleconfig.json  in the project root folder. Make sure the order of the files is what you need as  loading order .", 
            "title": "Bundling and minifying"
        }, 
        {
            "location": "/dotnet/notes/#unit-testing-with-xunit-framework", 
            "text": "", 
            "title": "Unit Testing with xUnit Framework"
        }, 
        {
            "location": "/dotnet/notes/#preparation", 
            "text": "create  test  folder inside the solution folder next to  src  folder  add new  .NET Core | Class Library (.NET Core)  project inside the  test  folder  add this code to its  project.json  file (check the latest versions):   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19    { \n       version :   1.0.0-* , \n       testRunner :   xunit , \n\n       dependencies :   { \n           Microsoft.NETCore.App :   { \n               type :   platform , \n               version :   1.0.1 \n           }, \n           xunit :   2.1.0 , \n           dotnet-test-xunit :   2.2.0-preview2-build1029 \n       }, \n\n       frameworks :   { \n           netcoreapp1.0 :   { \n               imports :   [ dotnet5.6 ,   portable-net45+win8 ] \n           } \n       } \n   }    this configuration tells Visual Studio that three packages are required:  the  Microsoft.NETCore.App  package provides the  .NET Core API .  the  xunit  package provides the testing framework.  the  dotnet-test-xunit  package provides the integration between  xUnit  and  Visual Studio .    add the main project reference to the dependencies, e.g.  1\n2\n3\n4\n5\n6\n7    { \n       dependencies :   { \n           ... \n           WorkingWithVisualStudio :   1.0.0 \n           ... \n       } \n   }", 
            "title": "Preparation"
        }, 
        {
            "location": "/dotnet/notes/#fact-and-theory", 
            "text": "In the  xUnit  framework, a  Fact  is one single unit test. Example:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15   [Fact] \n   public   void   IndexActionModelIsComplete ()   { \n       // Arrange \n       var   controller   =   new   HomeController (); \n       controller . Repository   =   new   ModelCompleteFakeRepository (); \n\n       // Act \n       var   model   =   ( controller . Index ()   as   ViewResult )?. ViewData . Model \n       as   IEnumerable Product ; \n\n       // Assert \n       Assert . Equal ( controller . Repository . Products ,   model , \n           Comparer . Get Product (( p1 ,   p2 )   =   p1 . Name   ==   p2 . Name \n                 p1 . Price   ==   p2 . Price )); \n   }    A  Theory  is a way to parametrize the unit test in such a way that it becomes possible to run the same test multiple times, each time with a different set of parameter values. Example:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25   [Theory]    [InlineData(275, 48.95, 19.50, 24.95)]    [InlineData(5, 48.95, 19.50, 24.95)] \n   public   void   IndexActionModelIsComplete ( decimal   price1 ,   decimal   price2 , \n   decimal   price3 ,   decimal   price4 )   { \n       // Arrange \n       var   controller   =   new   HomeController (); \n       controller . Repository   =   new   ModelCompleteFakeRepository   { \n           Products   =   new   Product []   { \n               new   Product   { Name   =   P1 ,   Price   =   price1   }, \n               new   Product   { Name   =   P2 ,   Price   =   price2   }, \n               new   Product   { Name   =   P3 ,   Price   =   price3   }, \n               new   Product   { Name   =   P4 ,   Price   =   price4   }, \n           } \n       }; \n\n       // Act \n       var   model   =   ( controller . Index ()   as   ViewResult )?. ViewData . Model \n                       as   IEnumerable Product ; \n\n       // Assert \n       Assert . Equal ( controller . Repository . Products ,   model , \n           Comparer . Get Product (( p1 ,   p2 )   =   p1 . Name   ==   p2 . Name \n                 p1 . Price   ==   p2 . Price )); \n   }", 
            "title": "Fact and Theory"
        }, 
        {
            "location": "/dotnet/notes/#getting-test-data-from-a-method-or-property", 
            "text": "We can create methods or properties giving us the enumerations for the test parameter values in a separate class, e.g.  ProductTestData.cs . Then we can use  MemberData  attribute to specify it for the unit test to use. Example:  1\n2\n3 [Theory]  [ClassData(typeof(ProductTestData))]  public   void   IndexActionModelIsComplete ( Product []   products   )   {...}    If we want to include the test data in the same class as the unit tests, then you can use the  MemberData  attribute instead of  ClassData . The  MemberData  attribute is configured using a string that specifies the name of a static method that will provide an  IEnumerable object[] , where each object array in the sequence is a set of arguments for the test method. Example:  1\n2\n3 [Theory]  [MemberData( GetData )]  public   void   IndexActionModelIsComplete ( Product []   products   )   {...}    and the  GetData  should look something like this  1\n2\n3\n4\n5\n6\n7\n8\n9 public   static   IEnumerable object []   GetData  { \n     get \n     { \n         // ... \n         yield   return   new   object []   {   8 ,   21   }; \n         yield   return   new   object []   {   16 ,   987   }; \n     }  }    Every  yield  statement should return an array of objects to substitute for the Product properties. And the method itself should be of type  IEnumerable object[] .", 
            "title": "Getting Test Data from a Method or Property"
        }, 
        {
            "location": "/dotnet/notes/#mocking-with-moq", 
            "text": "Microsoft  created a special fork of the  Moq  project and ported it to work with  .NET Core .  In order to be able to install the  Moq NuGet package , we need first to configure the  NuGet Options . Open  Tools | Options | NuGet Package Manager , click on  Package Sources  and then on the green plus sign. Configure the new package source as follows:   Name: ASP.NET Contrib  Source: https://www.myget.org/F/aspnet-contrib/api/v3/index.json   Add these two packages to the  package.json  in the test project:  1\n2 moq.netcore :   4.4.0-beta8  System.Diagnostics.TraceSource :   4.0.0    Usage example:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15 [Fact]  public   void   RepositoryPropertyCalledOnce ()  { \n     // Arrange \n     var   mock   =   new   Mock IRepository (); \n     mock . SetupGet ( m   =   m . Products ) \n         . Returns ( new []   {   new   Product   {   Name   =   P1 ,   Price   =   100   }   }); \n     var   controller   =   new   HomeController   {   Repository   =   mock . Object   }; \n\n     // Act \n     var   result   =   controller . Index (); \n\n     // Assert \n     mock . VerifyGet ( m   =   m . Products ,   Times . Once );  }    Explanation:   var mock = new Mock IRepository ();  - define the interface to be mocked  SetupGet(m =  m.Products)  - specify the property to be tested  .Returns(...)  - specify the test value to be returned  Repository = mock.Object  -  Object  is the special property that gives back the object we mock for this test  mock.VerifyGet(m =  m.Products, Times.Once);  - one of the verify methods to inspect the getter property", 
            "title": "Mocking with MOQ"
        }, 
        {
            "location": "/dotnet/notes/#sportsstore", 
            "text": "Create a new empty  ASP.NET Core Web Application (.NET Core)  project/solution.  Add these packages/tools to the  project.json  file:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13    dependencies :   { \n       ... \n       Microsoft.AspNetCore.Razor.Tools :   { \n           version :   1.0.0-preview2-final , \n           type :   build \n       }, \n       Microsoft.AspNetCore.StaticFiles :   1.0.0 , \n       Microsoft.AspNetCore.Mvc :   1.0.1 \n   } , \n   tools :   { \n       Microsoft.AspNetCore.Razor.Tools :   1.0.0-preview2-final , \n       ... \n   } ,    In addition to the packages in the  dependencies  section, there is an addition to the  tools  section of the  project.json  file that configures the  Microsoft.AspNetCore.Razor.Tools  package for use in Visual Studio and enables IntelliSense for the built-in tag helpers, which are used to create HTML content that is tailored to the configuration of the MVC application.  Here is the  Startup.cs :   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25    using   Microsoft.AspNetCore.Builder ; \n   using   Microsoft.AspNetCore.Hosting ; \n   using   Microsoft.AspNetCore.Http ; \n   using   Microsoft.Extensions.DependencyInjection ; \n   using   Microsoft.Extensions.Logging ; \n\n   namespace   SportsStore \n   { \n       public   class   Startup \n       { \n           public   void   ConfigureServices ( IServiceCollection   services ) \n           { \n               services . AddMvc (); \n           } \n\n           public   void   Configure ( IApplicationBuilder   app , \n           IHostingEnvironment   env ,   ILoggerFactory   loggerFactory ) \n           { \n               app . UseDeveloperExceptionPage (); \n               app . UseStatusCodePages (); \n               app . UseStaticFiles (); \n               app . UseMvcWithDefaultRoute (); \n           } \n       } \n   }    The  ConfigureServices  method is used to set up shared objects that can be used throughout the application through the  dependency injection  feature. The  AddMvc  method that is called in the  ConfigureServices  method is an extension method that sets up the shared objects used in MVC applications.  The  Configure  method is used to set up the features that receive and process  HTTP requests .  add these folders:  Models ,  Controllers ,  Views  in the  Views  folder add  _ViewImports.cshtml  file:  1\n2    @using   SportsStore . Models \n   @addTagHelper   *,   Microsoft . AspNetCore . Mvc . TagHelpers    create the unit test project  SportsStore.Tests  in the  test  folder.  Configure its  project .json  as follows:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20    { \n       version :   1.0.0-* , \n       testRunner :   xunit , \n       dependencies :   { \n           Microsoft.NETCore.App :   { \n               type :   platform , \n               version :   1.0.1 \n           }, \n           xunit :   2.1.0 , \n           dotnet-test-xunit :   2.2.0-preview2-build1029 , \n           moq.netcore :   4.4.0-beta8 , \n           System.Diagnostics.TraceSource :   4.0.0 , \n           SportsStore :   1.0.0 \n       }, \n       frameworks :   { \n           netcoreapp1.0 :   { \n               imports :   [   dotnet5.6 ,   portable-net45+win8   ] \n           } \n       } \n   }    Make sure that both  project.json  files refer to the same  ASP.NET Core MVC  version.  Add your model class  Product.cs , repository interface  IProductRepository  and a simple fake repository  FakeProductRepository  Register the fake repository as a service in  Startup.cs :  1\n2\n3\n4\n5    public   void   ConfigureServices ( IServiceCollection   services ) \n   { \n       services . AddTransient IProductRepository ,   FakeProductRepository (); \n       ... \n   }    Add the following standard views:  Views/Shared/_Layout.cshtml  Views/_ViewStart.cshtml  refering to  _Layout.cshtml  by default  Example of setting up the default route in  Startup.cs . Substitute  1    app . UseMvcWithDefaultRoute ();    with  1\n2\n3\n4\n5\n6    app . UseMvc ( routes   = \n   { \n       routes . MapRoute ( \n           name :   default , \n           template :   {controller=Product}/{action=List}/{id?} ); \n   });", 
            "title": "SportsStore"
        }, 
        {
            "location": "/dotnet/notes/#scaffolding", 
            "text": "Some people prefer to have certain features automatically created when they create new controller or views. That is called  scaffolding . If you want that, add the following packages to the  project.json  file:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26 ...  dependencies :   { \n     ... \n     Microsoft.AspNetCore.StaticFiles :   1.0.0 , \n     Microsoft.AspNetCore.Mvc :   1.0.0 , \n     Microsoft.VisualStudio.Web.CodeGeneration.Tools :   { \n         version :   1.0.0-preview2-final , \n         type :   build \n     }, \n     Microsoft.VisualStudio.Web.CodeGenerators.Mvc :   { \n         version :   1.0.0-preview2-final , \n         type :   build \n     }  }  ...  tools :   { \n     ... \n     Microsoft.VisualStudio.Web.CodeGeneration.Tools :   { \n         version :   1.0.0-preview2-final , \n         imports :   [ \n             portable-net45+win8+dnxcore50 , \n             portable-net45+win8 \n         ] \n     }  }  ...", 
            "title": "Scaffolding"
        }, 
        {
            "location": "/dotnet/notes/#setup-the-database", 
            "text": "add  EntityFramework  packages to  package.json :  1\n2\n3\n4\n5    dependencies :   { \n       ... \n       Microsoft.EntityFrameworkCore.SqlServer :   1.0.1 , \n       Microsoft.EntityFrameworkCore.Tools :   1.0.0-preview2-final \n   }    and the tools:  1\n2\n3\n4\n5\n6\n7    tools :   { \n       ... \n       Microsoft.EntityFrameworkCore.Tools :   { \n           version :   1.0.0-preview2-final , \n           imports :   [   portable-net45+win8+dnxcore50 ,   portable-net45+win8   ] \n       } \n   }    The  database context class  is the bridge between the  application  and the  EF Core  and provides access to the application\u2019s data using model objects. To create the database context class for the  SportsStore  application, we add a class file called  ApplicationDbContext.cs  to the  Models  folder:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11    using   Microsoft.EntityFrameworkCore ; \n\n   namespace   SportsStore.Models \n   { \n       public   class   ApplicationDbContext   :   DbContext \n       { \n           public   ApplicationDbContext ( DbContextOptions ApplicationDbContext   options ) \n               :   base ( options )   {   } \n           public   DbSet Product   Products   {   get ;   set ;   } \n       } \n   }    To populate the database initially with some data, we use  SeedData.cs  class:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29    using   System.Linq ; \n   using   Microsoft.AspNetCore.Builder ; \n   using   Microsoft.Extensions.DependencyInjection ; \n   namespace   SportsStore.Models \n   { \n       public   static   class   SeedData \n       { \n           public   static   void   EnsurePopulated ( IApplicationBuilder   app ) \n           { \n               ApplicationDbContext   context   = \n                   app . ApplicationServices . GetRequiredService ApplicationDbContext (); \n\n               if   (! context . Products . Any ()) \n               { \n                   context . Products . AddRange ( \n                   new   Product \n                   { \n                       Name   =   Kayak , \n                       Description   =   A boat for one person , \n                       Category   =   Watersports , \n                       Price   =   275 \n                   }, \n                   ... \n\n                   context . SaveChanges (); \n               } \n           } \n       } \n   }    The static  EnsurePopulated  method receives an  IApplicationBuilder  argument, which is the class used in the  Configure  method of the  Startup  class to register middleware classes to handle HTTP requests, which is where we ensure that the database has content.  The  EnsurePopulated  method obtains an  ApplicationDbContext  object through the  IApplicationBuilder  interface and uses it to check whether there are any  Product  objects in the database. If there are no objects, then the database is populated using a collection of  Product  objects using the  AddRange  method and then written to the database using the  SaveChanges  method.  The next step is to create a class that implements the  IProductRepository  interface and gets its data using  Entity Framework Core  from the  ApplicationDbContext .   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14    using   System.Collections.Generic ; \n\n   namespace   SportsStore.Models \n   { \n       public   class   EFProductRepository   :   IProductRepository \n       { \n           private   ApplicationDbContext   context ; \n           public   EFProductRepository ( ApplicationDbContext   ctx ) \n           { \n               context   =   ctx ; \n           } \n           public   IEnumerable Product   Products   =   context . Products ; \n       } \n   }    create  appsettings.json  file in the project root folder based on the  ASP.NET Configuration File  template and configure the connection string:  1\n2\n3\n4\n5\n6\n7    { \n       Data :   { \n           SportStoreProducts :   { \n               ConnectionString :   Server=(localdb)\\\\MSSQLLocalDB;Database=SportsStore;Trusted_Connection=True;MultipleActiveResultSets=true \n           } \n       } \n   }    add a new dependency to read the  json  configuration file:  1\n2\n3\n4    dependencies :   { \n       ... \n       Microsoft.Extensions.Configuration.Json :   1.0.0 \n   } ,    configure the  Startup.cs :   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35    ... \n   using   Microsoft.EntityFrameworkCore ; \n   using   Microsoft.Extensions.Configuration ; \n\n   namespace   SportsStore \n   { \n       public   class   Startup \n       { \n           IConfigurationRoot   Configuration ; \n\n           public   Startup ( IHostingEnvironment   env ) \n           { \n               Configuration   =   new   ConfigurationBuilder () \n                   . SetBasePath ( env . ContentRootPath ) \n                   . AddJsonFile ( appsettings.json ). Build (); \n           } \n\n           public   void   ConfigureServices ( IServiceCollection   services ) \n           { \n               services . AddDbContext ApplicationDbContext ( options   = \n                   options . UseSqlServer ( Configuration [ Data:SportStoreProducts:ConnectionString ])); \n               services . AddTransient IProductRepository ,   EFProductRepository (); \n               ... \n           } \n\n           public   void   Configure ( \n               IApplicationBuilder   app , \n               IHostingEnvironment   env , \n               ILoggerFactory   loggerFactory ) \n           { \n               ... \n               SeedData . EnsurePopulated ( app ); \n           } \n       } \n   }    open  Tools | Nuget Package Manager | Package Manager Console  to create and apply database migrations:  1\n2   Add-Migration Initial\n  Update-Database   rebuild the solution and run - we will see the list of products loaded from the database.", 
            "title": "Setup the database"
        }, 
        {
            "location": "/dotnet/notes/#viewmodels-and-taghelpers", 
            "text": "If we want to customize the information to be used in the view, we can do that with  ViewModels . For that we create a  ViewModels  subfolder inside the  Models  folder. They can  be registered  in  _ViewImports.cshtml .  TagHelpers  are one of the most useful ways that you can introduce C# logic into your views. The code for a tag helper can look tortured because C# and HTML don\u2019t mix easily. But using tag helpers is preferable to including blocks of C# code in a view because a tag helper can be easily  unit tested . Most MVC components, such as controllers and views, are discovered automatically, but tag helpers  have to be registered  in  _ViewImports.cshtml .  To test the  tag helper  class, I call the  Process  method with test data and provide a  TagHelperOutput  object that is inspected to see the HTML that was generated.  When we pass the data to the view via a view model, we need to replace the type. E.g. it can become  @model ProductsListViewModel  and  Model.Products  instead of  @model IEnumerable Product  and  Model .", 
            "title": "ViewModels and TagHelpers"
        }, 
        {
            "location": "/dotnet/notes/#installing-bootstrap-package", 
            "text": "Add  bower.json  file to the project root:  1\n2\n3\n4\n5\n6\n7 { \n     name :   asp.net , \n     private :   true , \n     dependencies :   { \n         bootstrap :   3.3.7 \n     }  }    This will add  wwwroot/lib  folder and inside it  bootstrap  and  jquery  sources.", 
            "title": "Installing Bootstrap package"
        }, 
        {
            "location": "/dotnet/notes/#improving-the-urls", 
            "text": "Normally, the page links look like this:  http://localhost/?page=2  But we can make them more user friendly by creating a scheme that follows the pattern of  composable URLs , which look like this:  http://localhost/Page2  To do that we register a new route in our MVC middleware ( Configure  method in  Startup.cs ):  1\n2\n3\n4 routes . MapRoute ( \n     name :   pagination , \n     template :   Products/Page{page} , \n     defaults :   new   {   Controller   =   Product ,   action   =   List   });    It is important that this route is added  before  the default route.", 
            "title": "Improving the URLs"
        }, 
        {
            "location": "/dotnet/notes/#enabling-sessions", 
            "text": "Add these new packages to the  package.json :  1\n2\n3 Microsoft.AspNetCore.Session :   1.0.0 ,  Microsoft.Extensions.Caching.Memory :   1.0.0 ,  Microsoft.AspNetCore.Http.Extensions :   1.0.0    Register new services and middleware to the  Startup.cs :   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 public   void   ConfigureServices ( IServiceCollection   services )   { \n     ... \n     services . AddMemoryCache (); \n     services . AddSession (); \n     services . AddMvc ();  }  public   void   Configure ( IApplicationBuilder   app , \n     ... \n     app . UseSession (); \n     app . UseMvc (...);  }     AddMemoryCache  The  AddMemoryCache  method call sets up the in-memory data store. The  AddSession  method registers the services used to access session data, and the  UseSession  method allows the session system to automatically associate requests with sessions when they arrive from the client.", 
            "title": "Enabling Sessions"
        }, 
        {
            "location": "/dotnet/notes/#annotations", 
            "text": "BindNever  attribute prevents the user supplying values for these properties in an HTTP request.", 
            "title": "Annotations"
        }, 
        {
            "location": "/dotnet/notes/#adding-migrations", 
            "text": "Suppose we add a new  DbSet  to our  ApplicationDbContext.cs :  1\n2\n3\n4\n5\n6\n7 public   class   ApplicationDbContext   :   DbContext  { \n     public   ApplicationDbContext ( DbContextOptions ApplicationDbContext   options ) \n         :   base ( options )   {   } \n     ... \n     public   DbSet Order   Orders   {   get ;   set ;   }  }    To create the  migration , open the NuGet  Package Manger Console  from the  Tools \u27a4 NuGet Package Manage  menu and run the following command :  Add-Migration Orders  This command tells EF Core to take a new snapshot of the application, work out how it differs from the previous database version, and generate a new migration called  Orders . The name  Orders  here is arbitrary but it is handy to let it reflect the change.  To update the database schema, run the following command:  Update-Database", 
            "title": "Adding migrations"
        }, 
        {
            "location": "/dotnet/notes/#resetting-the-database", 
            "text": "When you are making frequent changes to the model, there will come a point when your migrations and your database schema get out of sync. The easiest thing to do is delete the database and start over. However, this applies  only during development , of course, because you will lose any data you have stored.   Select the  SQL Server Object Explorer  item from the Visual Studio  View  menu and click the  Add Sql Server  button.  Enter  (localdb)\\mssqllocaldb  into the  Server Name  field and click the  Connect  button. A new item will appear in the  SQL Server Object Explorer  window, which you can expand to see the  LocalDB  databases that have been created.  Right-click the database you want to remove and select  Delete  from the pop-up menu.  Check the option to close the existing connections  and then click the  OK  button to delete the database.  Once the database has been removed, run the following command from the  Package Manager Console  to create the database and apply the migrations you have created by running the following command:   Update-Database   This will reset the database so that it accurately reflects your model and allow you to return to developing your application.", 
            "title": "Resetting the Database"
        }, 
        {
            "location": "/dotnet/notes/#using-tempdata", 
            "text": "We are using TempData in the POST method in a controller:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15 [HttpPost]  public   IActionResult   Edit ( Product   product )  { \n     if   ( ModelState . IsValid ) \n     { \n         _repository . SaveProduct ( product ); \n         TempData [ message ]   =   $ {product.Name} has been saved ; \n         return   RedirectToAction ( Index ); \n     } \n     else \n     { \n         // there is something wrong with the data values \n         return   View ( product ); \n     }  }    We check that the model binding process has been able to validate the data submitted to the user by reading the value of the  ModelState.IsValid  property. If everything is OK, we save the changes to the repository and redirect the user to the  Index  action so they see the modified list of products. If there is a problem with the data, we render the default view again so that the user can make corrections.  After we have saved the changes in the repository, we store a message using the  TempData  feature, which is part of the  ASP.NET Core session state  feature. This is a  key/value  dictionary similar to the  session data  and  view bag  features we used previously.  The key difference from  session data  is that  temp data  persists until it is read. We cannot use  ViewBag  in this situation because  ViewBag  passes data between the  controller  and  view , and it cannot hold data for longer than  the current HTTP request . When an edit succeeds, the browser is redirected to a new URL, so the  ViewBag  data is lost.  We could use the  session data  feature, but then the message would be persistent until we explicitly removed it, which we would rather not have to do.  So, the  temp data  feature is the perfect fit. The data is restricted to a  single user\u2019s session  (so that users do not see each other\u2019s  TempData ) and will persist long enough for us to read it. We will read the data in the  view  rendered by the  action method  to which we redirect the user  The message will be displayed once and disappear if you reload the screen with the template using this  temp data , because  TempData  is deleted when it is read. That is convenient since we do not want old messages hanging around.", 
            "title": "Using TempData"
        }, 
        {
            "location": "/dotnet/notes/#localization-hell", 
            "text": "By the time we get to editing with validation, something bad happens. It looks that by default the  jQuery-validation  (client side validation) expects  en-US  as its culture and the server side validation expects  nl-NL . Therefore, when I see  \u20ac  as currency and  ,  as decimal separator, I cannot change the price. Neither  ,  nor  .  are accepted. One is rejected by the client side and the other by the server side validation.  Temporary workaround was to configure  en-US  as the default culture, so that  $  and  .  are displayed on the screen. Then the validation works.", 
            "title": "Localization hell"
        }, 
        {
            "location": "/dotnet/notes/#adding-identity", 
            "text": "Add a new dependency to  project.json :  1\n2\n3\n4 dependencies :   { \n     ... \n     Microsoft.AspNetCore.Identity.EntityFrameworkCore :   1.0.0  }    Add a new  AppIdentityDbContext  class to  Models  folder:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11 using   Microsoft.AspNetCore.Identity.EntityFrameworkCore ;  using   Microsoft.EntityFrameworkCore ;  namespace   SportsStore.Models  { \n     public   class   AppIdentityDbContext   :   IdentityDbContext IdentityUser \n     { \n         public   AppIdentityDbContext ( DbContextOptions AppIdentityDbContext   options ) \n             :   base ( options )   {   } \n     }  }    and a new connection string in  appsettings.json  file:  1\n2\n3\n4\n5\n6\n7\n8 { \n     Data :   { \n         ... \n         SportStoreIdentity :   { \n             ConnectionString :   Server=(localdb)\\\\MSSQLLocalDB;Database=Identity;Trusted_Connection=True;MultipleActiveResultSets=true \n         } \n     }  }    Add new services to  ConfigureServices  in  Startup.cs :   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 public   void   ConfigureServices ( IServiceCollection   services )  { \n     ... \n     services . AddDbContext AppIdentityDbContext ( options   = \n         options . UseSqlServer ( Configuration [ Data:SportStoreIdentity:ConnectionString ])); \n\n     services . AddIdentity IdentityUser ,   IdentityRole () \n         . AddEntityFrameworkStores AppIdentityDbContext (); \n     ...  }    and new entries in  Configure :  1\n2\n3\n4\n5\n6 public   void   Configure () \n     app . UseIdentity (); \n     app . UseMvc (); \n     SeedData . EnsurePopulated ( app ); \n     IdentitySeedData . EnsurePopulated ( app );  }    IdentitySeedData  should be created in the  Models  folder to create an administrative account.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27 using   Microsoft.AspNetCore.Builder ;  using   Microsoft.AspNetCore.Identity ;  using   Microsoft.AspNetCore.Identity.EntityFrameworkCore ;  using   Microsoft.Extensions.DependencyInjection ;  namespace   SportsStore.Models  { \n     public   static   class   IdentitySeedData \n     { \n         private   const   string   adminUser   =   Admin ; \n         private   const   string   adminPassword   =   Secret123$ ; \n\n         public   static   async   void   EnsurePopulated ( IApplicationBuilder   app ) \n         { \n             UserManager IdentityUser   userManager   =   app . ApplicationServices \n                 . GetRequiredService UserManager IdentityUser (); \n\n             IdentityUser   user   =   await   userManager . FindByIdAsync ( adminUser ); \n\n             if   ( user   ==   null ) \n             { \n                 user   =   new   IdentityUser ( Admin ); \n                 await   userManager . CreateAsync ( user ,   adminPassword ); \n             } \n         } \n     }  }", 
            "title": "Adding Identity"
        }, 
        {
            "location": "/dotnet/notes/#adding-identity-migrations", 
            "text": "Add-Migration Initial -Context AppIdentityDbContext  Update-Database -Context AppIdentityDbContext   This will create the new database and add the  AspNetUsers  and  AspNetRoles  in it.", 
            "title": "Adding Identity migrations"
        }, 
        {
            "location": "/dotnet/notes/#adding-authorization", 
            "text": "When  ASP.NET Core Identity  is in place, we can apply  Authorization . We don\u2019t want to stop unauthenticated users from accessing the other action methods in the  Order  controller, so we have applied the  Authorize  attribute only to the  List  and  MarkShipped  methods.  1\n2\n3\n4\n5\n6\n7 [Authorize]  public   ViewResult   List ()   = \n     View ( _repository . Orders . Where ( o   =   ! o . Shipped ));  [HttpPost]  [Authorize]  public   IActionResult   MarkShipped ( int   orderID )   {...}    We want to protect  all of the action methods  defined by the  Admin  controller, and we can do this by applying the  Authorize attribute to the controller class, which then applies the authorization policy to all the action methods it contains.  1\n2\n3 [Authorize]  public   class   AdminController   :   Controller  {...}     Caution  In general, using client-side data validation is a good idea. It offloads some of the work from your server and gives users immediate feedback about the data they are providing. However, you should not be tempted to perform authentication at the client, as this would typically involve sending valid credentials to the client so they can be used to check the username and password that the user has entered, or at least trusting the client\u2019s report of whether they have successfully authenticated. Authentication should always be done at the server.", 
            "title": "Adding Authorization"
        }, 
        {
            "location": "/dotnet/notes/#sources-used", 
            "text": "Adam Freeman - Pro ASP.NET Core MVC (2016)  Christian Nagel - Professional C# 6 and .NET Core 1.0 (2016)", 
            "title": "Sources used"
        }, 
        {
            "location": "/dotnet/tips/", 
            "text": ".NET Core Tips\n\n\ndotnet command prompt\n\n\nRun the web application on a specified port, e.g. 10000, via\n\n\n1\ndotnet run --server.urls http://127.0.0.1:10000\n\n\n\n\n\n\n\n\nDotnet NuGet Packages\n\n\nUsing command \ndotnet pack\n we can actually create a \nNuGet\n package from our project. This command will create two files in \nbin/debug/[runtime]\n directory:\n\n\n\n\nDNXConsoleDemo.1.0.0.nupkg\n\n\nDNXConsoleDemo.1.0.0.symbols.nupkg\n\n\n\n\nActually, the \n.nupkg\n files are just \n.zip\n files. If you rename the extension, you can see what is inside the package.\n\n\n\n\nApplication as a NuGet package\n\n\nIt should now be possible to install your project as a NuGet package.\n\n\n\n\n\n\nSome Definitions\n\n\nASP.NET Services\n = objects that provide functionality to other parts of the application. Services registered in the \nStartup.ConfigureServices\n method can be accessed by creating a constructor that accepts an argument of the required service type.\n\n\nConfigureServices\n method hooks into the service registry all of the services we want our application to make use of. It is configuring the types of services that can be used in the infrastructur altogether.\n\n\nConfigure\n methods configures the behavior of the registered services.\n\n\nMiddleware\n = components that are combined to form the \nrequest pipeline\n.\n\n\nAddTransient\n = every time we call for the service to be used, we would get a new instance of the service from the \nDI Framework\n.\n\n\nAddScoped\n = same instance of the service is used in all stages of the middleware pipeline for the same request.\n\n\nAddSingleton\n = one instance of the service is created for the entire lifetime of the application across all user requests.\n\n\nAddInstance\n = similar to AddSingleton but we need to new up the instance of this service explicitly.\n\n\n\n\nSome Facts\n\n\n\n\nJSON schema of the \nproject.json\n file: \njson.schemastore.org/project\n\n\nIt is possible to use more that one \nStartup\n class, e.g. \nStartup\n, \nStartupFoo\n, \nStartupBar\n, and to specify the one we need to be activated in the \nProgram.cs\n:\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n  \npublic\n \nstatic\n \nvoid\n \nMain\n(\nstring\n[]\n \nargs\n)\n\n  \n{\n\n      \nvar\n \nhost\n \n=\n \nnew\n \nWebHostBuilder\n()\n\n          \n...\n\n          \n.\nUseStartup\nStartup\n()\n\n          \n...\n\n  \n}", 
            "title": "Tips"
        }, 
        {
            "location": "/dotnet/tips/#net-core-tips", 
            "text": "", 
            "title": ".NET Core Tips"
        }, 
        {
            "location": "/dotnet/tips/#dotnet-command-prompt", 
            "text": "Run the web application on a specified port, e.g. 10000, via  1 dotnet run --server.urls http://127.0.0.1:10000", 
            "title": "dotnet command prompt"
        }, 
        {
            "location": "/dotnet/tips/#dotnet-nuget-packages", 
            "text": "Using command  dotnet pack  we can actually create a  NuGet  package from our project. This command will create two files in  bin/debug/[runtime]  directory:   DNXConsoleDemo.1.0.0.nupkg  DNXConsoleDemo.1.0.0.symbols.nupkg   Actually, the  .nupkg  files are just  .zip  files. If you rename the extension, you can see what is inside the package.   Application as a NuGet package  It should now be possible to install your project as a NuGet package.", 
            "title": "Dotnet NuGet Packages"
        }, 
        {
            "location": "/dotnet/tips/#some-definitions", 
            "text": "ASP.NET Services  = objects that provide functionality to other parts of the application. Services registered in the  Startup.ConfigureServices  method can be accessed by creating a constructor that accepts an argument of the required service type.  ConfigureServices  method hooks into the service registry all of the services we want our application to make use of. It is configuring the types of services that can be used in the infrastructur altogether.  Configure  methods configures the behavior of the registered services.  Middleware  = components that are combined to form the  request pipeline .  AddTransient  = every time we call for the service to be used, we would get a new instance of the service from the  DI Framework .  AddScoped  = same instance of the service is used in all stages of the middleware pipeline for the same request.  AddSingleton  = one instance of the service is created for the entire lifetime of the application across all user requests.  AddInstance  = similar to AddSingleton but we need to new up the instance of this service explicitly.", 
            "title": "Some Definitions"
        }, 
        {
            "location": "/dotnet/tips/#some-facts", 
            "text": "JSON schema of the  project.json  file:  json.schemastore.org/project  It is possible to use more that one  Startup  class, e.g.  Startup ,  StartupFoo ,  StartupBar , and to specify the one we need to be activated in the  Program.cs :   1\n2\n3\n4\n5\n6\n7    public   static   void   Main ( string []   args ) \n   { \n       var   host   =   new   WebHostBuilder () \n           ... \n           . UseStartup Startup () \n           ... \n   }", 
            "title": "Some Facts"
        }, 
        {
            "location": "/powershell/vscode/", 
            "text": "This article describes the new version of PowerShell, \nPowerShell Core v6.0\n, which is a new generation of Powershell. It is cross-platform and at the moment implements only the most important functionality. Unfortunately, it has no modules to manage IIS.\n\n\n\n\nRecommended Prerequisites\n\n\nTo effectively debug \nPowerShell\n in \nVisual Studio Code\n you might consider to carry out the following steps:\n\n\n\n\ninstall \nPowerShell\n VS Code extension\n\n\ninstall the latest version of \nPowerShell Core\n (at the moment of writing this article, it was version \n6.0.2\n) from its \nGitHub repo\n\n\nadd the installation path to the Windows environment \nPATH\n variable:\n\n\nC:\\Program Files\\PowerShell\\\nversion\n\\\n \n\n\nadd the corresponding line to your VS Code settings:\n\n\n1\n2\n3\n4\n5\n6\n//\n \nOn\n \nWindows:\n\n\npowershell.powerShellExePath\n:\n \nC:/Program Files/PowerShell/\nversion\n/pwsh.exe\n\n\n//\n \nOn\n \nLinux:\n\n\npowershell.powerShellExePath\n:\n \n/opt/microsoft/powershell/\nversion\n/pwsh\n\n\n//\n \nOn\n \nmacOS:\n\n\npowershell.powerShellExePath\n:\n \n/usr/local/microsoft/powershell/\nversion\n/pwsh\n\n\n\n\n\n\n\n\nNow, when you start the VS Code you will notice that it is using the installed \nPowerShell Core\n as its integrated terminal.\n\n\n\n\nDebugging\n\n\nWhen you open your PowerShell file in the VS Code window, you can run it in the debugger mode. If you have not done it yet, initialize the \nlaunch.json\n configuration file by choosing the \nbug\n icon in the left side menu. Now, click on the gear icon at the top of the screen. The \nlaunch.json\n file will be created if necessary and open in the editor window. Probably the second configuration with look something like this:\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n{\n\n  \ntype\n:\n \nPowerShell\n,\n\n  \nrequest\n:\n \nlaunch\n,\n\n  \nname\n:\n \nPowerShell Launch Current File\n,\n\n  \nscript\n:\n \n${file}\n,\n\n  \nargs\n:\n \n[],\n\n  \ncwd\n:\n \n${file}\n\n\n}\n,\n\n\n\n\n\n\n\nNow, switch back to your PowerShell file in the editor window and set breakpoints where you need them. Choose \nPowerShell Launch Current File\n option in the \nDebug\n menu above, and click on the green triangle to run the script in the debugger mode. The debugger will stop at the first breakpoint it encounters.\n\n\n\n\nA nice feature of the PowerShell debugger is that it can \nalso\n debug inside the invoked commands, e.g by \nInvoke-Command\n. Just stop the debugger at the line with \nInvoke-Command\n first. From that breakpoint, you can go inside the invoked block by stepping inside it, e.g with \nF11\n.", 
            "title": "Debugging PowerShell in VS Code"
        }, 
        {
            "location": "/powershell/vscode/#recommended-prerequisites", 
            "text": "To effectively debug  PowerShell  in  Visual Studio Code  you might consider to carry out the following steps:   install  PowerShell  VS Code extension  install the latest version of  PowerShell Core  (at the moment of writing this article, it was version  6.0.2 ) from its  GitHub repo  add the installation path to the Windows environment  PATH  variable:  C:\\Program Files\\PowerShell\\ version \\    add the corresponding line to your VS Code settings:  1\n2\n3\n4\n5\n6 //   On   Windows:  powershell.powerShellExePath :   C:/Program Files/PowerShell/ version /pwsh.exe  //   On   Linux:  powershell.powerShellExePath :   /opt/microsoft/powershell/ version /pwsh  //   On   macOS:  powershell.powerShellExePath :   /usr/local/microsoft/powershell/ version /pwsh     Now, when you start the VS Code you will notice that it is using the installed  PowerShell Core  as its integrated terminal.", 
            "title": "Recommended Prerequisites"
        }, 
        {
            "location": "/powershell/vscode/#debugging", 
            "text": "When you open your PowerShell file in the VS Code window, you can run it in the debugger mode. If you have not done it yet, initialize the  launch.json  configuration file by choosing the  bug  icon in the left side menu. Now, click on the gear icon at the top of the screen. The  launch.json  file will be created if necessary and open in the editor window. Probably the second configuration with look something like this:  1\n2\n3\n4\n5\n6\n7\n8 { \n   type :   PowerShell , \n   request :   launch , \n   name :   PowerShell Launch Current File , \n   script :   ${file} , \n   args :   [], \n   cwd :   ${file}  } ,    Now, switch back to your PowerShell file in the editor window and set breakpoints where you need them. Choose  PowerShell Launch Current File  option in the  Debug  menu above, and click on the green triangle to run the script in the debugger mode. The debugger will stop at the first breakpoint it encounters.   A nice feature of the PowerShell debugger is that it can  also  debug inside the invoked commands, e.g by  Invoke-Command . Just stop the debugger at the line with  Invoke-Command  first. From that breakpoint, you can go inside the invoked block by stepping inside it, e.g with  F11 .", 
            "title": "Debugging"
        }, 
        {
            "location": "/umbraco/technicalities/", 
            "text": "Using SSL in Production\n\n\n(This is a tip of \nSebastiaan Janssen\n at \nOur Umbraco\n.)\n\n\nOur aim is to use \nSSL\n in Production and to issue an \nautomatic 301-redirect\n for any non-secure url within the domain. For example,\n\n\n\n\nmydomain.com =\n https://mydomain.com\n\n\nwww.mydomain.com =\n https://www.mydomain.com\n\n\n\n\nIn order to achieve this, several things have to be done. This is based on GoDaddy\ns hosting, so for SSL one needs to buy their\n\n\n\n\nGoDaddy does not specialize on Windows hosting\n\n\nUnfortunately, the Windows hosting support of GoDaddy ends up when the place there minimal \nindex.html\n file in the root directory and can successfully view that page in the browser.\n\n\n\n\nStep 1 \n Configure the Production web server\n\n\nGo to \nWebsites \n Domains\n and choose \nWeb Server Settings\n. Check \nRequire SSL\n checkbox to prevent non-secure access to the website. Don\nt forget to save the changes.\n\n\nStep 2 \n Create the SSL Certificate\n\n\nGoDaddy offers a \nSHA-2\n type SSL-certificate.\n\n\nYou can also place the \nSSL Certificate security seal\n on your website that looks like this:\n\n\n\n\nGoDaddy provides the snippet for this. When you click on the seal, you see the confirmation:\n\n\n\n\nStep 3 \n Add transformations to the Web.Release.config file\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nconfiguration\n \nxmlns:xdt=\nhttp://schemas.microsoft.com/XML-Document-Transform\n\n  \nappSettings\n\n    \nadd\n \nkey=\ndebugWebErrors\n \nvalue=\nfalse\n\n      \nxdt:Transform=\nSetAttributes\n \nxdt:Locator=\nMatch(key)\n/\n\n  \n/appSettings\n\n  \nrewrite\n \nxdt:Transform=\nInsertAfter(/configuration/system.webServer/validation)\n\n    \nrules\n\n      \nrule\n \nname=\nRedirect to https\n \nstopProcessing=\ntrue\n\n        \nmatch\n \nurl=\n(.*)\n \n/\n\n        \nconditions\n\n          \nadd\n \ninput=\n{HTTPS}\n \npattern=\noff\n \nignoreCase=\ntrue\n \n/\n\n        \n/conditions\n\n        \naction\n \ntype=\nRedirect\n \nurl=\nhttps://{HTTP_HOST}{REQUEST_URI}\n\n                \nredirectType=\nPermanent\n \nappendQueryString=\nfalse\n \n/\n\n      \n/rule\n\n    \n/rules\n\n  \n/rewrite\n\n\n/configuration\n\n\n\n\n\n\n\n\n\nURL Rewriting plugin\n\n\nNote that the above rewrite only works if the URL Rewriting plugin for IIS has been installed on the server.\n\n\n\n\nYou\nll also need to update all your templates if they refer to (for example) fonts on a CDN, the easiest way to do that is to not give it the scheme (http or https). So instead of:\n\n\n1\n2\nlink\n \nhref\n=\nhttp://fonts.googleapis.com/css?family=Open+Sans:400,700\n\n\ntype\n=\ntext/css\n \nrel\n=\nstylesheet\n/\n\n\n\n\n\n\n\nyou can make:\n\n\n1\n2\nlink\n \nhref\n=\n//fonts.googleapis.com/css?family=Open+Sans:400,700\n\n\ntype\n=\ntext/css\n \nrel\n=\nstylesheet\n/\n\n\n\n\n\n\n\nNotice that \nhttp:\n has been removed. This way it will load over both https and also over http (if you ever decide to revert to http).\n\n\n\n\nrobots.txt\n\n\n\n\ninstall \nCultiv DynamicRobots\n and \nRobots.txt Editor\n packages in the Umbraco backend.\n\n\n(I am not yet sure if this is a good option) intall the \nCultiv SearchEngineSitemap\n package, which supports multisite solutions out of the box.\n\n\nopen Developer section in the backend and you will see \nRobots.txt\n option. Click on it. Now, you can enter the code you need. Here is an example of such file for Umbraco projects:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n    # robots.txt for Umbraco\n    User-agent: *\n    Disallow: /bin/\n    Disallow: /config/\n    Disallow: /css/\n    Disallow: /data/\n    Disallow: /scripts/\n    Disallow: /umbraco/\n    Disallow: /umbraco_client/\n    Disallow: /usercontrols/\n    Sitemap: http://{HTTP_HOST}/sitemap\n\n\n\n\n\n\n\nThe interesting part here is that the \n{HTTP_HOST}\n template parameter here is dynamically substituted for the right URL when the project is deployed.\n\n\n\n\nDeployment error\n\n\nCurrently the \nCultiv.DynamicRobots.dll\n file in the \nbin\n directory is not being copied by the deployment process and has to be separately copied later.\n\n\n\n\nAlternatively, you could also create \nrobots.txt\n manually in the project root directory and make sure the link \n/robots.txt\n is redirected to \n/robotstxt\n in \n~\\Config\\UrlRewriting.config\n. For details see this article: \nHow to create a robots.txt in Umbraco and edit it from the backoffice", 
            "title": "Technical details"
        }, 
        {
            "location": "/umbraco/technicalities/#using-ssl-in-production", 
            "text": "(This is a tip of  Sebastiaan Janssen  at  Our Umbraco .)  Our aim is to use  SSL  in Production and to issue an  automatic 301-redirect  for any non-secure url within the domain. For example,   mydomain.com =  https://mydomain.com  www.mydomain.com =  https://www.mydomain.com   In order to achieve this, several things have to be done. This is based on GoDaddy s hosting, so for SSL one needs to buy their   GoDaddy does not specialize on Windows hosting  Unfortunately, the Windows hosting support of GoDaddy ends up when the place there minimal  index.html  file in the root directory and can successfully view that page in the browser.", 
            "title": "Using SSL in Production"
        }, 
        {
            "location": "/umbraco/technicalities/#step-1-configure-the-production-web-server", 
            "text": "Go to  Websites   Domains  and choose  Web Server Settings . Check  Require SSL  checkbox to prevent non-secure access to the website. Don t forget to save the changes.", 
            "title": "Step 1 -- Configure the Production web server"
        }, 
        {
            "location": "/umbraco/technicalities/#step-2-create-the-ssl-certificate", 
            "text": "GoDaddy offers a  SHA-2  type SSL-certificate.  You can also place the  SSL Certificate security seal  on your website that looks like this:   GoDaddy provides the snippet for this. When you click on the seal, you see the confirmation:", 
            "title": "Step 2 -- Create the SSL Certificate"
        }, 
        {
            "location": "/umbraco/technicalities/#step-3-add-transformations-to-the-webreleaseconfig-file", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 configuration   xmlns:xdt= http://schemas.microsoft.com/XML-Document-Transform \n   appSettings \n     add   key= debugWebErrors   value= false \n       xdt:Transform= SetAttributes   xdt:Locator= Match(key) / \n   /appSettings \n   rewrite   xdt:Transform= InsertAfter(/configuration/system.webServer/validation) \n     rules \n       rule   name= Redirect to https   stopProcessing= true \n         match   url= (.*)   / \n         conditions \n           add   input= {HTTPS}   pattern= off   ignoreCase= true   / \n         /conditions \n         action   type= Redirect   url= https://{HTTP_HOST}{REQUEST_URI} \n                 redirectType= Permanent   appendQueryString= false   / \n       /rule \n     /rules \n   /rewrite  /configuration     URL Rewriting plugin  Note that the above rewrite only works if the URL Rewriting plugin for IIS has been installed on the server.   You ll also need to update all your templates if they refer to (for example) fonts on a CDN, the easiest way to do that is to not give it the scheme (http or https). So instead of:  1\n2 link   href = http://fonts.googleapis.com/css?family=Open+Sans:400,700  type = text/css   rel = stylesheet /    you can make:  1\n2 link   href = //fonts.googleapis.com/css?family=Open+Sans:400,700  type = text/css   rel = stylesheet /    Notice that  http:  has been removed. This way it will load over both https and also over http (if you ever decide to revert to http).", 
            "title": "Step 3 -- Add transformations to the Web.Release.config file"
        }, 
        {
            "location": "/umbraco/technicalities/#robotstxt", 
            "text": "install  Cultiv DynamicRobots  and  Robots.txt Editor  packages in the Umbraco backend.  (I am not yet sure if this is a good option) intall the  Cultiv SearchEngineSitemap  package, which supports multisite solutions out of the box.  open Developer section in the backend and you will see  Robots.txt  option. Click on it. Now, you can enter the code you need. Here is an example of such file for Umbraco projects:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11     # robots.txt for Umbraco\n    User-agent: *\n    Disallow: /bin/\n    Disallow: /config/\n    Disallow: /css/\n    Disallow: /data/\n    Disallow: /scripts/\n    Disallow: /umbraco/\n    Disallow: /umbraco_client/\n    Disallow: /usercontrols/\n    Sitemap: http://{HTTP_HOST}/sitemap    The interesting part here is that the  {HTTP_HOST}  template parameter here is dynamically substituted for the right URL when the project is deployed.   Deployment error  Currently the  Cultiv.DynamicRobots.dll  file in the  bin  directory is not being copied by the deployment process and has to be separately copied later.   Alternatively, you could also create  robots.txt  manually in the project root directory and make sure the link  /robots.txt  is redirected to  /robotstxt  in  ~\\Config\\UrlRewriting.config . For details see this article:  How to create a robots.txt in Umbraco and edit it from the backoffice", 
            "title": "robots.txt"
        }, 
        {
            "location": "/umbraco/faq/", 
            "text": "Bundling and minifying\n\n\nMost of the information comes from two articles: \nHow to bundle CSS and JS\n and \nBundling and minification in Umbraco\n.\n\n\n\n\nAdded \nApp_Start\n folder\n\n\nCreated \nBundleConfig.cs\n class with bundles for JavaScript and CSS files\n\n\nAdded \nBundleTable.EnableOptimizations = true;\n in \nBundleConfig.cs\n to be able to test bundling and minification.\n\n\nAt the same time, added \ncompilation debug=\ntrue\n /\n in \nsystem.web\n section of \nWeb.config\n, \ncompilation debug=\nfalse\n /\n in \nweb.Release.config\n.\n\n\n\n\n\n\nImportant\n\n\nEnableOptimizations\n takes precedence of \ncompilation debug\n value.\n\n\n\n\n\n\nIt is also important to make sure that \nbundles\n are included in the \numbracoReservedPaths\n:\n\n\n\n\n1\n2\n3\n4\n5\n  \nappSettings\n\n    ...\n    \nadd\n \nkey=\numbracoReservedPaths\n \nvalue=\n~/umbraco,~/install/,~/bundles/\n \n/\n\n    ...\n  \n/appSettings\n\n\n\n\n\n\n\n\n\nWeb Deployment - Could not find part of the path\n\n\nQuestion\n\n\nError during web deploy\n\n\n\n\nCould not open Source file: Could not find a part of the path \nJ:\\U\\Ed4u\\Ed4u\\App_Plugins\\LeBlender\\Web.config;\\App_Plugins\\LeBlender\\Web.config\n.\n\n\n\n\nAnswer\n\n\nFind the deployment profile \nenergydiet4u.nl - Web Deploy.pubxml\n\n\n\n\nand add the following key to the \nPropertyGroup\n section:\n\n\n1\nAutoParameterizationWebConfigConnectionStrings\nFalse\n/AutoParameterizationWebConfigConnectionStrings\n\n\n\n\n\n\n\n\n\nWeb Deployment - Group policy prevents Roslyn\ns csc.exe from running\n\n\nQuestion\n\n\nWebsite runtime error after deployment to GoDaddy:\n\n\n\n\nAnswer\n\n\nSince the .NET 4.5 version, Roslyn compilation is the default way of compiling. This means if you create any web application either Web Forms or MVC using .NET 4.5 you get this Roslyn csc.exe compilation pre-installed in your project.\n\n\n\n\nUninstall \nMicrosoft.CodeDOM.Providers.DotNetCompilerPlatform\n NuGet package, rebuild and redeploy the website\n\n\nDelete the corresponding .dll\ns from the \nbin\n directory\n\n\n\n\nNOTE\n This will be probably necessary to do every time \nUmbraco\n is upgraded.", 
            "title": "Issues and solutions"
        }, 
        {
            "location": "/umbraco/faq/#bundling-and-minifying", 
            "text": "Most of the information comes from two articles:  How to bundle CSS and JS  and  Bundling and minification in Umbraco .   Added  App_Start  folder  Created  BundleConfig.cs  class with bundles for JavaScript and CSS files  Added  BundleTable.EnableOptimizations = true;  in  BundleConfig.cs  to be able to test bundling and minification.  At the same time, added  compilation debug= true  /  in  system.web  section of  Web.config ,  compilation debug= false  /  in  web.Release.config .    Important  EnableOptimizations  takes precedence of  compilation debug  value.    It is also important to make sure that  bundles  are included in the  umbracoReservedPaths :   1\n2\n3\n4\n5    appSettings \n    ...\n     add   key= umbracoReservedPaths   value= ~/umbraco,~/install/,~/bundles/   / \n    ...\n   /appSettings", 
            "title": "Bundling and minifying"
        }, 
        {
            "location": "/umbraco/faq/#web-deployment-could-not-find-part-of-the-path", 
            "text": "", 
            "title": "Web Deployment - Could not find part of the path"
        }, 
        {
            "location": "/umbraco/faq/#question", 
            "text": "Error during web deploy   Could not open Source file: Could not find a part of the path  J:\\U\\Ed4u\\Ed4u\\App_Plugins\\LeBlender\\Web.config;\\App_Plugins\\LeBlender\\Web.config .", 
            "title": "Question"
        }, 
        {
            "location": "/umbraco/faq/#answer", 
            "text": "Find the deployment profile  energydiet4u.nl - Web Deploy.pubxml   and add the following key to the  PropertyGroup  section:  1 AutoParameterizationWebConfigConnectionStrings False /AutoParameterizationWebConfigConnectionStrings", 
            "title": "Answer"
        }, 
        {
            "location": "/umbraco/faq/#web-deployment-group-policy-prevents-roslyns-cscexe-from-running", 
            "text": "", 
            "title": "Web Deployment - Group policy prevents Roslyn's csc.exe from running"
        }, 
        {
            "location": "/umbraco/faq/#question_1", 
            "text": "Website runtime error after deployment to GoDaddy:", 
            "title": "Question"
        }, 
        {
            "location": "/umbraco/faq/#answer_1", 
            "text": "Since the .NET 4.5 version, Roslyn compilation is the default way of compiling. This means if you create any web application either Web Forms or MVC using .NET 4.5 you get this Roslyn csc.exe compilation pre-installed in your project.   Uninstall  Microsoft.CodeDOM.Providers.DotNetCompilerPlatform  NuGet package, rebuild and redeploy the website  Delete the corresponding .dll s from the  bin  directory   NOTE  This will be probably necessary to do every time  Umbraco  is upgraded.", 
            "title": "Answer"
        }, 
        {
            "location": "/vuejs/basics/", 
            "text": "Installation\n\n\nStart by installing \nyarn\n from \nyarn website\n.\n\n\nQuick and dirty\n\n\n1\n2\n3\n4\n5\n6\nyarn global add vue-cli\nvue init webpack-simple my-app\n\ncd\n my-app\nyarn install\nyarn upgrade\nyarn run dev\n\n\n\n\n\n\nNormal Development\n\n\n1\n2\n3\n4\n5\n6\nyarn global add vue-cli\nvue init webpack my-app\n\ncd\n my-app\nyarn install\nyarn upgrade\nyarn run dev\n\n\n\n\n\n\nWhen answering questions, choose standard installation (not airbnb) unless you like to fight with eslint and prefer to use semicolons everywhere.\n\n\n\n\nAvoid Vue.js DOM templates\n\n\nThis advice comes from the Anthony Gore\ns article: \nWhy You Should Avoid Vue.js DOM Templates\n. The issue he writes about is that Vue.js DOM templates are not reliable in that they don\nt always render the DOM code you expect.\n\n\nIn Short\n\n\n\n\nDOM templates are problematic as the DOM parser can mess with your markup. There\u2019s also a potential for clashes with templating engines and incompatibility with server-side rendering.\n\n\nTo minimize your DOM template, abstract your markup into components.\n\n\nTo completely eliminate your DOM template you\u2019ll need to mount your root-level component with a render function.\n\n\n\n\nSo, how can you architect a Vue.js app without a DOM template, or at least a small one?\n\n\nAbstract markup to components\n\n\nYour root instance can hold some state, but generally, you want any presentational logic and markup to be abstracted to components so it\u2019s out of your DOM template.\n\n\nSingle-file components are the superior choice. If you\u2019re unable to include a build step in your project and don\u2019t like writing your templates as JavaScript strings (who does), you can try \nx-templates\n.\n\n\nx-templates\n\n\nWith \nx-templates\n, your template is still defined in the page, but within a script tag, and will, therefore, avoid processing by the DOM parser. The script tag is marked with \ntext/x-template\n and referenced by an id in your component definition.\n\n\n1\n2\n3\n4\n5\n6\n7\nVue\n.\ncomponent\n(\nmy-component\n,\n \n{\n\n  \ntemplate\n:\n \n#my-component\n\n\n}\n\n\nscript\n \ntype\n=\ntext/x-template\n \nid\n=\nmy-component\n\n  \ndiv\nMy\n \ncomponent\n \ntemplate\n/div\n\n  \nNonStandardMarkupIsFineHere\n/\n\n\n/script\n\n\n\n\n\n\n\nMount to an empty node with a render function\n\n\nAbstracting markup into components hits a wall when you realize you still need to declare your root-level component in the DOM template.\n\n\n1\n2\n3\n4\ndiv\n \nid\n=\napp\n\n  \n!--\n \nWe\n \nstill\n \nhave\n \na\n \nDOM\n \ntemplate\n \n:\n(\n \n--\n\n  \napp\n/app\n\n\n/div\n\n\n\n\n\n\n\nIf you want to totally eliminate your DOM template, you can mount your root-level component(s) with a render function.\n\n\nLet\u2019s say you have one all-encompassing component that declares the other components called \nApp\n. App can be declared with a render function and mounted to an empty node since render functions will replace their mount element.\n\n\nAutogenerated by \nvue-cli\n:\n\n\n1\n2\n3\n4\n5\n6\n7\ndiv\n \nid\n=\napp\n/div\n\n\n\nnew\n \nVue\n({\n\n  \nel\n:\n \n#app\n,\n\n  \ntemplate\n:\n \nApp/\n,\n\n  \ncomponents\n:\n \n{\n \nApp\n \n}\n\n\n})\n\n\n\n\n\n\n\nReplace with:\n\n\n1\n2\n3\n4\n5\n6\n7\ndiv\n \nid\n=\napp\n/div\n\n\n\nnew\n \nVue\n({\n\n  \nel\n:\n \n#app\n,\n\n  \ncomponents\n:\n \n{\n \nApp\n \n},\n\n  \nrender\n:\n \n(\ncreateElement\n)\n \n=\n \ncreateElement\n(\nApp\n)\n\n\n})\n\n\n\n\n\n\n\nAnd with that, your app is free of any DOM templates!\n\n\nIf you can eliminate all string and DOM templates from your app you can use the smaller runtime-only build of Vue. This is an ideal project architecture and is the one you\u2019ll see used in vue-cli templates.", 
            "title": "Vue.js Basics"
        }, 
        {
            "location": "/vuejs/basics/#installation", 
            "text": "Start by installing  yarn  from  yarn website .", 
            "title": "Installation"
        }, 
        {
            "location": "/vuejs/basics/#quick-and-dirty", 
            "text": "1\n2\n3\n4\n5\n6 yarn global add vue-cli\nvue init webpack-simple my-app cd  my-app\nyarn install\nyarn upgrade\nyarn run dev", 
            "title": "Quick and dirty"
        }, 
        {
            "location": "/vuejs/basics/#normal-development", 
            "text": "1\n2\n3\n4\n5\n6 yarn global add vue-cli\nvue init webpack my-app cd  my-app\nyarn install\nyarn upgrade\nyarn run dev   When answering questions, choose standard installation (not airbnb) unless you like to fight with eslint and prefer to use semicolons everywhere.", 
            "title": "Normal Development"
        }, 
        {
            "location": "/vuejs/basics/#avoid-vuejs-dom-templates", 
            "text": "This advice comes from the Anthony Gore s article:  Why You Should Avoid Vue.js DOM Templates . The issue he writes about is that Vue.js DOM templates are not reliable in that they don t always render the DOM code you expect.", 
            "title": "Avoid Vue.js DOM templates"
        }, 
        {
            "location": "/vuejs/basics/#in-short", 
            "text": "DOM templates are problematic as the DOM parser can mess with your markup. There\u2019s also a potential for clashes with templating engines and incompatibility with server-side rendering.  To minimize your DOM template, abstract your markup into components.  To completely eliminate your DOM template you\u2019ll need to mount your root-level component with a render function.   So, how can you architect a Vue.js app without a DOM template, or at least a small one?", 
            "title": "In Short"
        }, 
        {
            "location": "/vuejs/basics/#abstract-markup-to-components", 
            "text": "Your root instance can hold some state, but generally, you want any presentational logic and markup to be abstracted to components so it\u2019s out of your DOM template.  Single-file components are the superior choice. If you\u2019re unable to include a build step in your project and don\u2019t like writing your templates as JavaScript strings (who does), you can try  x-templates .", 
            "title": "Abstract markup to components"
        }, 
        {
            "location": "/vuejs/basics/#x-templates", 
            "text": "With  x-templates , your template is still defined in the page, but within a script tag, and will, therefore, avoid processing by the DOM parser. The script tag is marked with  text/x-template  and referenced by an id in your component definition.  1\n2\n3\n4\n5\n6\n7 Vue . component ( my-component ,   { \n   template :   #my-component  }  script   type = text/x-template   id = my-component \n   div My   component   template /div \n   NonStandardMarkupIsFineHere /  /script", 
            "title": "x-templates"
        }, 
        {
            "location": "/vuejs/basics/#mount-to-an-empty-node-with-a-render-function", 
            "text": "Abstracting markup into components hits a wall when you realize you still need to declare your root-level component in the DOM template.  1\n2\n3\n4 div   id = app \n   !--   We   still   have   a   DOM   template   : (   -- \n   app /app  /div    If you want to totally eliminate your DOM template, you can mount your root-level component(s) with a render function.  Let\u2019s say you have one all-encompassing component that declares the other components called  App . App can be declared with a render function and mounted to an empty node since render functions will replace their mount element.  Autogenerated by  vue-cli :  1\n2\n3\n4\n5\n6\n7 div   id = app /div  new   Vue ({ \n   el :   #app , \n   template :   App/ , \n   components :   {   App   }  })    Replace with:  1\n2\n3\n4\n5\n6\n7 div   id = app /div  new   Vue ({ \n   el :   #app , \n   components :   {   App   }, \n   render :   ( createElement )   =   createElement ( App )  })    And with that, your app is free of any DOM templates!  If you can eliminate all string and DOM templates from your app you can use the smaller runtime-only build of Vue. This is an ideal project architecture and is the one you\u2019ll see used in vue-cli templates.", 
            "title": "Mount to an empty node with a render function"
        }, 
        {
            "location": "/webpack/basics/", 
            "text": "Webpack Architecture 101\n\n\n\n\nWebpack\n is based on the \nTapable Module\n.\n\n\n\n\nHere is a concise Webpack workflow description:\n\n\n\n\nthe \nCompiler\n reads option and create the \nCompilation\n\n\nthe \nCompilation\n reads the \nentry property\n, and sends it through the \nNormal Module Factory (NMF)\n to the \nResolver\nto find out if the file exists\n\n\nif it exists, the \nResolver\n creates a \nModule Object\n from it with the source inside\n\n\nif some module is not in \nJavaScript\n, e.g. CSS, HTML, etc., the \nLoaders\n will transpile it into JavaScript\n\n\nthen it goes through the \nParser\n that converts it into an \nAbstract Syntax Tree (AST)\n to find all \nrequire\ns and \nimport\ns, in other words all \ndependencies\n\n\nthis process is \nrecursively repeated\n for every dependency\n\n\n\n\nTaken from the \nEverything is a plugin! Mastering webpack from the inside out\n presentation by \nSean Larkin\n at \nng-conf 2017\n in Salt Lake City (UT)\n\n\nMore information can be found in the \nConcepts\n section of the \nWebpack\n documentation.\n\n\nIn the \nSingle Page Applications with Vue.js\n PluralSight course, Bill Stavroulakis shows step by step how to add \nwebpack\n and build it out together with the Vue.js solution.", 
            "title": "Webpack Basics"
        }, 
        {
            "location": "/webpack/basics/#webpack-architecture-101", 
            "text": "Webpack  is based on the  Tapable Module .   Here is a concise Webpack workflow description:   the  Compiler  reads option and create the  Compilation  the  Compilation  reads the  entry property , and sends it through the  Normal Module Factory (NMF)  to the  Resolver to find out if the file exists  if it exists, the  Resolver  creates a  Module Object  from it with the source inside  if some module is not in  JavaScript , e.g. CSS, HTML, etc., the  Loaders  will transpile it into JavaScript  then it goes through the  Parser  that converts it into an  Abstract Syntax Tree (AST)  to find all  require s and  import s, in other words all  dependencies  this process is  recursively repeated  for every dependency   Taken from the  Everything is a plugin! Mastering webpack from the inside out  presentation by  Sean Larkin  at  ng-conf 2017  in Salt Lake City (UT)  More information can be found in the  Concepts  section of the  Webpack  documentation.  In the  Single Page Applications with Vue.js  PluralSight course, Bill Stavroulakis shows step by step how to add  webpack  and build it out together with the Vue.js solution.", 
            "title": "Webpack Architecture 101"
        }, 
        {
            "location": "/playground/todo/", 
            "text": "TODOs\n\n\nFunctionality\n\n\n\n\nFood / Non-Food (Umbraco)\n\n\nDisqus comments (MkDocs)\n\n\nHave I set up \nindentifier\n and \nurl\n correctly?\n\n\nHow do I append \n#disqus_thread\n to the \nhref\n attribute in my links?\n\n\nAdd Disqus chapter to the Docs\n\n\n\n\n\n\n\n\n\n\nBuild and Deployment\n\n\n\n\ndeployment \nCultiv.DynamicRobots.dll\n \n should be copied to the target \n/bin\n\n\nTravis CI: \nmy profile\n (MkDocs) \n how to?\n\n\n\n\n\n\nSEO\n\n\n\n\nSitemap\n\n\nGoogle Search\n\n\nMicrocode snippets\n\n\nSitemap in Google and Yandex\n\n\n\n\n\n\nLearning\n\n\nNew EGGHEAD.IO courses\n\n\nThis is the main link of \nEGGHEAD.IO\n.\n\n\nTOOLS\n\n\n\n\nDebug the DOM in Chrome with the Devtools Elements Panel\n\n\nDebug JavaScript in Chrome with DevTool Sources\n\n\nDebug HTTP with Chrome DevTools Network Panel\n\n\nDeploy Web Apps with Zeit Now\n\n\n\n\nREACT\n\n\n\n\nBuild Your First React.js App\n\n\nStart Using React to Build Web Applications\n\n\nReact Native Fundamentals\n\n\nGetting Started with React Router\n\n\nReact Testing Cookbook\n\n\nReact: Flux Architecture (ES6)\n\n\nAnimate React Native UI Elements\n\n\n\n\nGet the excercise files\n\n\nREACT\n\n\n\n\nGetting started with Redux\n\n\nBuilding React Applications with Idiomatic Redux", 
            "title": "TODOs"
        }, 
        {
            "location": "/playground/todo/#todos", 
            "text": "", 
            "title": "TODOs"
        }, 
        {
            "location": "/playground/todo/#functionality", 
            "text": "Food / Non-Food (Umbraco)  Disqus comments (MkDocs)  Have I set up  indentifier  and  url  correctly?  How do I append  #disqus_thread  to the  href  attribute in my links?  Add Disqus chapter to the Docs", 
            "title": "Functionality"
        }, 
        {
            "location": "/playground/todo/#build-and-deployment", 
            "text": "deployment  Cultiv.DynamicRobots.dll    should be copied to the target  /bin  Travis CI:  my profile  (MkDocs)   how to?", 
            "title": "Build and Deployment"
        }, 
        {
            "location": "/playground/todo/#seo", 
            "text": "Sitemap  Google Search  Microcode snippets  Sitemap in Google and Yandex", 
            "title": "SEO"
        }, 
        {
            "location": "/playground/todo/#learning", 
            "text": "", 
            "title": "Learning"
        }, 
        {
            "location": "/playground/todo/#new-eggheadio-courses", 
            "text": "This is the main link of  EGGHEAD.IO .", 
            "title": "New EGGHEAD.IO courses"
        }, 
        {
            "location": "/playground/todo/#tools", 
            "text": "Debug the DOM in Chrome with the Devtools Elements Panel  Debug JavaScript in Chrome with DevTool Sources  Debug HTTP with Chrome DevTools Network Panel  Deploy Web Apps with Zeit Now", 
            "title": "TOOLS"
        }, 
        {
            "location": "/playground/todo/#react", 
            "text": "Build Your First React.js App  Start Using React to Build Web Applications  React Native Fundamentals  Getting Started with React Router  React Testing Cookbook  React: Flux Architecture (ES6)  Animate React Native UI Elements", 
            "title": "REACT"
        }, 
        {
            "location": "/playground/todo/#get-the-excercise-files", 
            "text": "", 
            "title": "Get the excercise files"
        }, 
        {
            "location": "/playground/todo/#react_1", 
            "text": "Getting started with Redux  Building React Applications with Idiomatic Redux", 
            "title": "REACT"
        }, 
        {
            "location": "/playground/test/", 
            "text": "Test Document\n\n\nTable\n\n\nThis is an example of a table:\n\n\n\n\n\n\n\n\nheader1\n\n\nheader2\n\n\n\n\n\n\n\n\n\n\ncell 1.1\n\n\ncell 1.2\n\n\n\n\n\n\ncell 2.1\n\n\ncell 2.2\n\n\n\n\n\n\ncell 3.1\n\n\ncell 3.2", 
            "title": "Test Document"
        }, 
        {
            "location": "/playground/test/#test-document", 
            "text": "", 
            "title": "Test Document"
        }, 
        {
            "location": "/playground/test/#table", 
            "text": "This is an example of a table:     header1  header2      cell 1.1  cell 1.2    cell 2.1  cell 2.2    cell 3.1  cell 3.2", 
            "title": "Table"
        }
    ]
}