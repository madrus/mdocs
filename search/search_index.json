{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 About this documentation \u00b6 WTF \u00b6 You may ask yourself a question: \u201cWhat\u2019s the point of having a Markdown documentation website if there are tools like Atlassian Confluence or Microsoft Sharepoint ?\u201d Indeed, WHAT? BEFORE: Confluence and Sharepoint \u00b6 Confluence and Sharepoint are good portals for project documentation, and are very useful for managers, information analysts, architects, etc. For all sorts of reference information. They also allow the whole team and even organisation to work on the same documents in an easy way. However, in my mind these tools have certain downsizes specifically for us software developers. We need to have our own hub of documentation where program code looks like code with all the syntax color marking to make it more readable and understandable. We need efficient access to how-to type of documentation containing searchable how-to guides, walk-through procedures, hints and tips on specific techniques, languages and projects. It is well-known that searching on Confluence or Sharepoint is a huge headache. One gets presented with pages upon pages of links that for 95% are irrelevant to what you are looking for. These company portals are \u201covercrowded\u201d. Markdown \u00b6 Markdown is a much more suitable language for developers\u2019 documentation. You write plain text and you get beautiful website automatically generated. So, one does not even need to have Microsoft Office installed. Any plain text editor will do. You can even use emoji. Isn\u2019t the website you are currently looking at amazingly beautiful?! And it consists for 100% out Markdown documents. It is more like a blog for yourself and your teammates. Also, for developers it is very handy to create Markdown README.md files in every project and/or solution. This is what the whole open-source world has been already doing for many years. Every GitHub repository contains a standard README.md file as its home page. Even Microsoft keeps a lot of its own documentation as Markdown documents in GitHub! See e.g. Windows PowerShell documentation . In Azure DevOps/Visual Studio Online/VSTS , every repository also has a standard Markdown home page. Collecting tips and tricks can be huge fun. Just do it along the way every time you get stuck and later find the solution. Then every bit of information will be useful to you and other developers. Enjoy! Give it a try \u00b6 Have a look at the Getting Started document.","title":"Home"},{"location":"#welcome","text":"","title":"Welcome"},{"location":"#about-this-documentation","text":"","title":"About this documentation"},{"location":"#wtf","text":"You may ask yourself a question: \u201cWhat\u2019s the point of having a Markdown documentation website if there are tools like Atlassian Confluence or Microsoft Sharepoint ?\u201d Indeed, WHAT?","title":"WTF"},{"location":"#before-confluence-and-sharepoint","text":"Confluence and Sharepoint are good portals for project documentation, and are very useful for managers, information analysts, architects, etc. For all sorts of reference information. They also allow the whole team and even organisation to work on the same documents in an easy way. However, in my mind these tools have certain downsizes specifically for us software developers. We need to have our own hub of documentation where program code looks like code with all the syntax color marking to make it more readable and understandable. We need efficient access to how-to type of documentation containing searchable how-to guides, walk-through procedures, hints and tips on specific techniques, languages and projects. It is well-known that searching on Confluence or Sharepoint is a huge headache. One gets presented with pages upon pages of links that for 95% are irrelevant to what you are looking for. These company portals are \u201covercrowded\u201d.","title":"BEFORE: Confluence and Sharepoint"},{"location":"#markdown","text":"Markdown is a much more suitable language for developers\u2019 documentation. You write plain text and you get beautiful website automatically generated. So, one does not even need to have Microsoft Office installed. Any plain text editor will do. You can even use emoji. Isn\u2019t the website you are currently looking at amazingly beautiful?! And it consists for 100% out Markdown documents. It is more like a blog for yourself and your teammates. Also, for developers it is very handy to create Markdown README.md files in every project and/or solution. This is what the whole open-source world has been already doing for many years. Every GitHub repository contains a standard README.md file as its home page. Even Microsoft keeps a lot of its own documentation as Markdown documents in GitHub! See e.g. Windows PowerShell documentation . In Azure DevOps/Visual Studio Online/VSTS , every repository also has a standard Markdown home page. Collecting tips and tricks can be huge fun. Just do it along the way every time you get stuck and later find the solution. Then every bit of information will be useful to you and other developers. Enjoy!","title":"Markdown"},{"location":"#give-it-a-try","text":"Have a look at the Getting Started document.","title":"Give it a try"},{"location":"aurelia/technicalities/","text":"Font Awesome in Aurelia project \u00b6 Add new prepare-font-awesome.ts task file to aurelia_project/tasks : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import * as gulp from 'gulp' ; import * as merge from 'merge-stream' ; import * as changedInPlace from 'gulp-changed-in-place' ; import * as project from '../aurelia.json' ; export default function prepareFontAwesome () { const source = 'node_modules/font-awesome' ; const cssSource = ` ${ source } /css/font-awesome.min.css` ; const cssDest = ` ${ project . platform . output } /css` ; const fontsSource = ` ${ source } /fonts/*` ; const fontsDest = ` ${ project . platform . output } /fonts` ; const taskCss = gulp . src ( cssSource ) . pipe ( changedInPlace ({ firstPass : true })) . pipe ( gulp . dest ( cssDest )); const taskFonts = gulp . src ( fontsSource ) . pipe ( changedInPlace ({ firstPass : true })) . pipe ( gulp . dest ( fontsDest )); return merge ( taskCss , taskFonts ); }; Add this new task to aurelia_project/tasks/build.ts . You will get something like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import * as gulp from 'gulp' ; import transpile from './transpile' ; import processMarkup from './process-markup' ; import processCSS from './process-css' ; import { build } from 'aurelia-cli' ; import * as project from '../aurelia.json' ; import prepareFontAwesome from './prepare-font-awesome' ; // our custom task export default gulp . series ( readProjectConfiguration , gulp . parallel ( transpile , processMarkup , processCSS , prepareFontAwesome // our custom task ), writeBundles ); function readProjectConfiguration () { return build . src ( project ); } function writeBundles () { return build . dest (); } Finally, add 1 < link rel = \"stylesheet\" href = \"scripts/css/font-awesome.min.css\" > to wwwroot/index.html . Now, if you run au build , you will see two new directories created under wwwwroot/scripts : css fonts and inside these folders the Font Awesome stylesheet and fonts.","title":"Some Technical Notes"},{"location":"aurelia/technicalities/#font-awesome-in-aurelia-project","text":"Add new prepare-font-awesome.ts task file to aurelia_project/tasks : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import * as gulp from 'gulp' ; import * as merge from 'merge-stream' ; import * as changedInPlace from 'gulp-changed-in-place' ; import * as project from '../aurelia.json' ; export default function prepareFontAwesome () { const source = 'node_modules/font-awesome' ; const cssSource = ` ${ source } /css/font-awesome.min.css` ; const cssDest = ` ${ project . platform . output } /css` ; const fontsSource = ` ${ source } /fonts/*` ; const fontsDest = ` ${ project . platform . output } /fonts` ; const taskCss = gulp . src ( cssSource ) . pipe ( changedInPlace ({ firstPass : true })) . pipe ( gulp . dest ( cssDest )); const taskFonts = gulp . src ( fontsSource ) . pipe ( changedInPlace ({ firstPass : true })) . pipe ( gulp . dest ( fontsDest )); return merge ( taskCss , taskFonts ); }; Add this new task to aurelia_project/tasks/build.ts . You will get something like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import * as gulp from 'gulp' ; import transpile from './transpile' ; import processMarkup from './process-markup' ; import processCSS from './process-css' ; import { build } from 'aurelia-cli' ; import * as project from '../aurelia.json' ; import prepareFontAwesome from './prepare-font-awesome' ; // our custom task export default gulp . series ( readProjectConfiguration , gulp . parallel ( transpile , processMarkup , processCSS , prepareFontAwesome // our custom task ), writeBundles ); function readProjectConfiguration () { return build . src ( project ); } function writeBundles () { return build . dest (); } Finally, add 1 < link rel = \"stylesheet\" href = \"scripts/css/font-awesome.min.css\" > to wwwroot/index.html . Now, if you run au build , you will see two new directories created under wwwwroot/scripts : css fonts and inside these folders the Font Awesome stylesheet and fonts.","title":"Font Awesome in Aurelia project"},{"location":"dev/choco/","text":"Chocolatey \u00b6 Installations \u00b6 Install Chocolatey \u00b6 Run PowerShell as Administrator: 1 Set-ExecutionPolicy Bypass -Scope Process -Force ; iex (( New-Object System . Net . WebClient ). DownloadString ( 'https://chocolatey.org/install.ps1' )) Alternatively, run cmd.exe : 1 @ \"%SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\" -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command \"iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))\" && SET \"PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin\" Install Stuff \u00b6 Run command prompt as Admin: 1 2 3 4 cinst cmder -y cinst boxstarter cinst conemu -y cinst vim -y","title":"Chocolatey"},{"location":"dev/choco/#chocolatey","text":"","title":"Chocolatey"},{"location":"dev/choco/#installations","text":"","title":"Installations"},{"location":"dev/choco/#install-chocolatey","text":"Run PowerShell as Administrator: 1 Set-ExecutionPolicy Bypass -Scope Process -Force ; iex (( New-Object System . Net . WebClient ). DownloadString ( 'https://chocolatey.org/install.ps1' )) Alternatively, run cmd.exe : 1 @ \"%SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\" -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command \"iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))\" && SET \"PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin\"","title":"Install Chocolatey"},{"location":"dev/choco/#install-stuff","text":"Run command prompt as Admin: 1 2 3 4 cinst cmder -y cinst boxstarter cinst conemu -y cinst vim -y","title":"Install Stuff"},{"location":"dev/devServers/","text":"Development Servers \u00b6 Live Server VSCode Extension \u00b6 Extension page . You must have a .html or .htm file in the current folder. Just click on Go Live button on your VSCode taskbar. SERVE \u00b6 Install: 1 2 yarn global add serve npm i -g serve If your static website is located in the ./build folder, you can open it as follows: 1 serve -s build Browse to http://localhost:5000 HTTP-SERVER \u00b6 Install: 1 2 yarn global add http-server npm i -g http-server REACT-SCRIPTS \u00b6 These scripts allow you to run a React dev environment seeded via Create-React-App . After installation, run: 1 2 3 4 yarn start yarn build yarn test yarn eject","title":"Dev Servers"},{"location":"dev/devServers/#development-servers","text":"","title":"Development Servers"},{"location":"dev/devServers/#live-server-vscode-extension","text":"Extension page . You must have a .html or .htm file in the current folder. Just click on Go Live button on your VSCode taskbar.","title":"Live Server VSCode Extension"},{"location":"dev/devServers/#serve","text":"Install: 1 2 yarn global add serve npm i -g serve If your static website is located in the ./build folder, you can open it as follows: 1 serve -s build Browse to http://localhost:5000","title":"SERVE"},{"location":"dev/devServers/#http-server","text":"Install: 1 2 yarn global add http-server npm i -g http-server","title":"HTTP-SERVER"},{"location":"dev/devServers/#react-scripts","text":"These scripts allow you to run a React dev environment seeded via Create-React-App . After installation, run: 1 2 3 4 yarn start yarn build yarn test yarn eject","title":"REACT-SCRIPTS"},{"location":"dev/npx/","text":"NPX \u00b6 What is NPX \u00b6 npx is a tool for running npm packages that: live inside of a local node_modules folder, or are not installed globally. Example: 1 2 3 4 # Before $ node ./node_modules/.bin/mocha # Now with npx: $ npx mocha npx looks into the local node_modules folder for the package and if it can\u2019t find it, it will download and run it without having that package globally installed. npx is a replacement for installing global packages. It encourages you to install packages locally, but still be able run them as if they were global, just with npx. Usage \u00b6 Run Local Packages \u00b6 Suppose we want run gulp from the command prompt. We have two options. Either install gulp globally or not install gulp globally and just use npx : 1 2 3 4 5 $ cd /path/to/project/folder # option 1: install globally $ npm i -D gulp gulp-cli # option 2: don't install globally but use npx $ npx gulp Run One-off Packages via URL \u00b6 npx will download and execute any package you give it. This is useful for one-off commands, e.g., to check the accessibility score of a website: 1 2 $ npx pa11y https://scottlogic.com > Running Pa11y on URL https://scottlogic.com/ Create a Boilerplate App \u00b6 Creating a boilerplate React app. 1 $ npx create-react-app harrys-site Run a Static Web Server \u00b6 Running a static web server. 1 2 3 4 5 6 7 $ cd my-website $ npx http-server > Starting up http-server, serving ./ > Available on: > http://192.168.36.65:8080 > http://127.0.0.1:8080 > Hit CTRL-C to stop the server Deploy to a Live Server \u00b6 Deploying to a live server . 1 2 3 $ cd my-website $ npx now --public > Ready! https://test-hffvgcpvvq.now.sh [ 2s ] Execute a Package from a URL \u00b6 npx can also execute a package from a URL , e.g. this GitHub gist : 1 2 $ npx https://gist.github.com/zkat/4bc19503fe9e9309e2bfaa2c58074d32 > yay gist Credits \u00b6 This information is taken this article: Harry Mumford-Turner , \u201c How to use npx: the npm package runner \u201d. Goodbye \u00b6 1 2 3 4 5 6 7 8 9 10 $ npx cowsay goodbye! npx: installed 10 in 5 .303s __________ < goodbye! > ---------- \\ ^__^ \\ ( oo ) \\_ ______ ( __ ) \\ ) \\/\\ || ----w | || || Egghead.io Course \u00b6 There is a free Egghead.io course on NPX: Learn about the npx Package Runner . Here is the list of lessons: Use npx to run locally installed node modules Use npx to Temporarily Install and Invoke a Package from npm Test Different Node Module Versions with npx Use npx to run commands with different Node.js versions Execute npx commands with $npm_ Environment Variables Execute Code from a Remote GitHub Branch with npx Use npx to execute code from a GitHub gist ```","title":"NPX tool"},{"location":"dev/npx/#npx","text":"","title":"NPX"},{"location":"dev/npx/#what-is-npx","text":"npx is a tool for running npm packages that: live inside of a local node_modules folder, or are not installed globally. Example: 1 2 3 4 # Before $ node ./node_modules/.bin/mocha # Now with npx: $ npx mocha npx looks into the local node_modules folder for the package and if it can\u2019t find it, it will download and run it without having that package globally installed. npx is a replacement for installing global packages. It encourages you to install packages locally, but still be able run them as if they were global, just with npx.","title":"What is NPX"},{"location":"dev/npx/#usage","text":"","title":"Usage"},{"location":"dev/npx/#run-local-packages","text":"Suppose we want run gulp from the command prompt. We have two options. Either install gulp globally or not install gulp globally and just use npx : 1 2 3 4 5 $ cd /path/to/project/folder # option 1: install globally $ npm i -D gulp gulp-cli # option 2: don't install globally but use npx $ npx gulp","title":"Run Local Packages"},{"location":"dev/npx/#run-one-off-packages-via-url","text":"npx will download and execute any package you give it. This is useful for one-off commands, e.g., to check the accessibility score of a website: 1 2 $ npx pa11y https://scottlogic.com > Running Pa11y on URL https://scottlogic.com/","title":"Run One-off Packages via URL"},{"location":"dev/npx/#create-a-boilerplate-app","text":"Creating a boilerplate React app. 1 $ npx create-react-app harrys-site","title":"Create a Boilerplate App"},{"location":"dev/npx/#run-a-static-web-server","text":"Running a static web server. 1 2 3 4 5 6 7 $ cd my-website $ npx http-server > Starting up http-server, serving ./ > Available on: > http://192.168.36.65:8080 > http://127.0.0.1:8080 > Hit CTRL-C to stop the server","title":"Run a Static Web Server"},{"location":"dev/npx/#deploy-to-a-live-server","text":"Deploying to a live server . 1 2 3 $ cd my-website $ npx now --public > Ready! https://test-hffvgcpvvq.now.sh [ 2s ]","title":"Deploy to a Live Server"},{"location":"dev/npx/#execute-a-package-from-a-url","text":"npx can also execute a package from a URL , e.g. this GitHub gist : 1 2 $ npx https://gist.github.com/zkat/4bc19503fe9e9309e2bfaa2c58074d32 > yay gist","title":"Execute a Package from a URL"},{"location":"dev/npx/#credits","text":"This information is taken this article: Harry Mumford-Turner , \u201c How to use npx: the npm package runner \u201d.","title":"Credits"},{"location":"dev/npx/#goodbye","text":"1 2 3 4 5 6 7 8 9 10 $ npx cowsay goodbye! npx: installed 10 in 5 .303s __________ < goodbye! > ---------- \\ ^__^ \\ ( oo ) \\_ ______ ( __ ) \\ ) \\/\\ || ----w | || ||","title":"Goodbye"},{"location":"dev/npx/#eggheadio-course","text":"There is a free Egghead.io course on NPX: Learn about the npx Package Runner . Here is the list of lessons: Use npx to run locally installed node modules Use npx to Temporarily Install and Invoke a Package from npm Test Different Node Module Versions with npx Use npx to run commands with different Node.js versions Execute npx commands with $npm_ Environment Variables Execute Code from a Remote GitHub Branch with npx Use npx to execute code from a GitHub gist ```","title":"Egghead.io Course"},{"location":"dev/todo/","text":"TODOs \u00b6 Functionality \u00b6 Food / Non-Food (Umbraco) Disqus comments (MkDocs) Have I set up indentifier and url correctly? How do I append #disqus_thread to the href attribute in my links? Add Disqus chapter to the Docs Build and Deployment \u00b6 deployment Cultiv.DynamicRobots.dll \u2014 should be copied to the target /bin Travis CI: my profile (MkDocs) \u2014 how to? SEO \u00b6 Sitemap Google Search Microcode snippets Sitemap in Google and Yandex Learning \u00b6 New EGGHEAD.IO courses \u00b6 This is the main link of EGGHEAD.IO . TOOLS \u00b6 Debug the DOM in Chrome with the Devtools Elements Panel Debug JavaScript in Chrome with DevTool Sources Debug HTTP with Chrome DevTools Network Panel Deploy Web Apps with Zeit Now REACT \u00b6 Build Your First React.js App Start Using React to Build Web Applications React Native Fundamentals Getting Started with React Router React Testing Cookbook React: Flux Architecture (ES6) Animate React Native UI Elements Get the excercise files \u00b6 REACT \u00b6 Getting started with Redux Building React Applications with Idiomatic Redux","title":"TODOs"},{"location":"dev/todo/#todos","text":"","title":"TODOs"},{"location":"dev/todo/#functionality","text":"Food / Non-Food (Umbraco) Disqus comments (MkDocs) Have I set up indentifier and url correctly? How do I append #disqus_thread to the href attribute in my links? Add Disqus chapter to the Docs","title":"Functionality"},{"location":"dev/todo/#build-and-deployment","text":"deployment Cultiv.DynamicRobots.dll \u2014 should be copied to the target /bin Travis CI: my profile (MkDocs) \u2014 how to?","title":"Build and Deployment"},{"location":"dev/todo/#seo","text":"Sitemap Google Search Microcode snippets Sitemap in Google and Yandex","title":"SEO"},{"location":"dev/todo/#learning","text":"","title":"Learning"},{"location":"dev/todo/#new-eggheadio-courses","text":"This is the main link of EGGHEAD.IO .","title":"New EGGHEAD.IO courses"},{"location":"dev/todo/#tools","text":"Debug the DOM in Chrome with the Devtools Elements Panel Debug JavaScript in Chrome with DevTool Sources Debug HTTP with Chrome DevTools Network Panel Deploy Web Apps with Zeit Now","title":"TOOLS"},{"location":"dev/todo/#react","text":"Build Your First React.js App Start Using React to Build Web Applications React Native Fundamentals Getting Started with React Router React Testing Cookbook React: Flux Architecture (ES6) Animate React Native UI Elements","title":"REACT"},{"location":"dev/todo/#get-the-excercise-files","text":"","title":"Get the excercise files"},{"location":"dev/todo/#react_1","text":"Getting started with Redux Building React Applications with Idiomatic Redux","title":"REACT"},{"location":"dotnet/new_project/","text":"Workflow with an new ASP.NET Core MVC Project \u00b6 .NET Core Prerequisites \u00b6 Ideally, you have to have a number of components installed on your system (Windows | Linux | MacOS): .NET Core .NET Core SDK Node.js Create a new minimal ASP.NET Core project \u00b6 IMPORTANT! When working with Visual Studio as IDE, make sure that - AT ALL TIMES! - you can run your application both from inside the Visual Studio by pressing Ctrl + F5 , and from the command prompt by executing dotnet run command. Dotnet Command Line Version \u00b6 Create a new project directory and CD to it: mkdir myproj && cd myproj Create the default initial project: dotnet new Restore the default dependencies: dotnet restore Run the project and see the Hello World! message: dotnet run Visual Studio 2015 Version \u00b6 Start Visual Studio. Click on File | New | Project . In the Templates choose Visual C# | .NET Core and then ASP.NET Core Web Application (.NET Core) . Browse to the root location for your new solution. Choose a nice name for it, e.g. MyGreatApp . Click the OK button. Choose now the empty ASP.NET Core template. The solution is created. Wait for the dependencies to be installed. Build and run the solution with Ctrl + F5 . When the browser starts, you will see the Hello World! message. You can also start the command prompt in the MyGreatApp/Src/MyGreatApp folder. Run this command: dotnet restore && dotnet run Browse to the localhost:5000 and you will see the Hello World! message. Dependencies \u00b6 Versions are constantly changing ASP.NET Core is constantly being developed and new versions of different components are being released. Therefore, the versions stated below can get outdated at any moment. If you wish to upgrade a version, you have to install the referenced component first. Project.json \u00b6 You can start with this configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 { \"version\" : \"1.0.0-*\" , \"description\" : \"Your best description of the application\" , \"authors\" : [ \"Your Name\" ], \"packOptions\" : { \"tags\" : [ \"\" ], \"projectUrl\" : \"\" , \"licenseUrl\" : \"\" }, \"dependencies\" : { \"Microsoft.NETCore.App\" : { \"version\" : \"1.1.*\" , \"type\" : \"platform\" }, \"Microsoft.AspNetCore.Diagnostics\" : \"1.1.0\" , \"Microsoft.AspNetCore.Mvc\" : \"1.1.0\" , \"Microsoft.AspNetCore.Razor.Tools\" : { \"version\" : \"1.1.0-preview4-final\" , \"type\" : \"build\" }, \"Microsoft.AspNetCore.Server.IISIntegration\" : \"1.1.0\" , \"Microsoft.AspNetCore.Server.Kestrel\" : \"1.1.0\" , \"Microsoft.AspNetCore.StaticFiles\" : \"1.1.0\" , \"Microsoft.Extensions.Logging.Console\" : \"1.1.0\" , \"Microsoft.VisualStudio.Web.BrowserLink.Loader\" : \"14.1.0\" , \"System.Net.Http\" : \"4.3.0\" }, \"tools\" : { \"Microsoft.AspNetCore.Server.IISIntegration.Tools\" : \"1.0.0-preview2-final\" }, \"frameworks\" : { \"netcoreapp1.0\" : { \"imports\" : [ \"dotnet5.6\" , \"portable-net45+win8\" , \"dnxcore50\" ] } }, \"buildOptions\" : { \"emitEntryPoint\" : true , \"preserveCompilationContext\" : true }, \"runtimes\" : { \"win81-x64\" : {}, \"win7-x64\" : {}, \"osx.10.12-x64\" : {} }, \"runtimeOptions\" : { \"configProperties\" : { \"System.GC.Server\" : true } }, \"publishOptions\" : { \"include\" : [ \"wwwroot\" , \"web.config\" ] }, \"scripts\" : { \"postpublish\" : [ \"dotnet publish-iis --publish-folder %publish:OutputPath% --framework %publish:FullTargetFramework%\" ] } } Global.json \u00b6 When you install the .NET Core SDK on Windows, it shows up in C:\\Program Files\\dotnet\\sdk folder. Using the \u201csdk\u201d option, we can override the default version. 1 2 3 4 5 6 { \"projects\" : [ \"src\" , \"test\" ], \"sdk\" : { \"version\" : \"1.0.0-preview2-1-003177\" } } Bower.json \u00b6 If you need Bootstrap 3 for the styling of your website, add this bower.json file in the project root. 1 2 3 4 5 6 7 { \"name\" : \"asp.net\" , \"private\" : true , \"dependencies\" : { \"bootstrap\" : \"3.3.*\" } } Program.cs \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 using Microsoft.AspNetCore.Hosting ; using System.IO ; namespace NNMeta { public class Program { public static void Main ( string [] args ) { var host = new WebHostBuilder () . UseKestrel () . UseContentRoot ( Directory . GetCurrentDirectory ()) . UseIISIntegration () . UseStartup < Startup >() . Build (); host . Run (); } } } Startup.cs \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 using Microsoft.AspNetCore.Builder ; using Microsoft.AspNetCore.Hosting ; using Microsoft.Extensions.DependencyInjection ; using Microsoft.Extensions.Logging ; namespace NNMeta { public class Startup { public void ConfigureServices ( IServiceCollection services ) { services . AddMvc (); } public void Configure ( IApplicationBuilder app , IHostingEnvironment env , ILoggerFactory loggerFactory ) { if ( env . IsDevelopment ()) { app . UseDeveloperExceptionPage (); } app . UseStaticFiles (); app . UseMvcWithDefaultRoute (); } } } Controllers/HomeController.cs \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 using System.Collections.Generic ; using Microsoft.AspNetCore.Mvc ; namespace NNMeta.Controllers { public class HomeController : Controller { public ViewResult Index () => View ( new Dictionary < string , string > { [\"Message1\"] = \"This is the first message from the Index action\" , [\"Message2\"] = \"This is the second message from the Index action\" }); } } Views/_ViewImports.cshtml \u00b6 1 @addTagHelper *, Microsoft.AspNetCore.Mvc.TagHelpers Views/Home/Index.cshtml \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @model Dictionary < string , string > @{ Layout = null; } <!DOCTYPE html> < html > < head > < meta name = \"viewport\" content = \"width=device-width\" /> < link asp-href-include = \"~/lib/bootstrap/dist/css/*.min.css\" rel = \"stylesheet\" /> < title > Result </ title > </ head > < body class = \"panel-body\" > < table class = \"table table-condensed table-bordered table-striped\" > < tr > @foreach (var kvp in Model) { < th > @kvp.Key </ th > } </ tr > < tr > @foreach (var kvp in Model) { < td > @kvp.Value </ td > } </ tr > </ table > </ body > </ html >","title":"New Project"},{"location":"dotnet/new_project/#workflow-with-an-new-aspnet-core-mvc-project","text":"","title":"Workflow with an new ASP.NET Core MVC Project"},{"location":"dotnet/new_project/#net-core-prerequisites","text":"Ideally, you have to have a number of components installed on your system (Windows | Linux | MacOS): .NET Core .NET Core SDK Node.js","title":".NET Core Prerequisites"},{"location":"dotnet/new_project/#create-a-new-minimal-aspnet-core-project","text":"IMPORTANT! When working with Visual Studio as IDE, make sure that - AT ALL TIMES! - you can run your application both from inside the Visual Studio by pressing Ctrl + F5 , and from the command prompt by executing dotnet run command.","title":"Create a new minimal ASP.NET Core project"},{"location":"dotnet/new_project/#dotnet-command-line-version","text":"Create a new project directory and CD to it: mkdir myproj && cd myproj Create the default initial project: dotnet new Restore the default dependencies: dotnet restore Run the project and see the Hello World! message: dotnet run","title":"Dotnet Command Line Version"},{"location":"dotnet/new_project/#visual-studio-2015-version","text":"Start Visual Studio. Click on File | New | Project . In the Templates choose Visual C# | .NET Core and then ASP.NET Core Web Application (.NET Core) . Browse to the root location for your new solution. Choose a nice name for it, e.g. MyGreatApp . Click the OK button. Choose now the empty ASP.NET Core template. The solution is created. Wait for the dependencies to be installed. Build and run the solution with Ctrl + F5 . When the browser starts, you will see the Hello World! message. You can also start the command prompt in the MyGreatApp/Src/MyGreatApp folder. Run this command: dotnet restore && dotnet run Browse to the localhost:5000 and you will see the Hello World! message.","title":"Visual Studio 2015 Version"},{"location":"dotnet/new_project/#dependencies","text":"Versions are constantly changing ASP.NET Core is constantly being developed and new versions of different components are being released. Therefore, the versions stated below can get outdated at any moment. If you wish to upgrade a version, you have to install the referenced component first.","title":"Dependencies"},{"location":"dotnet/new_project/#projectjson","text":"You can start with this configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 { \"version\" : \"1.0.0-*\" , \"description\" : \"Your best description of the application\" , \"authors\" : [ \"Your Name\" ], \"packOptions\" : { \"tags\" : [ \"\" ], \"projectUrl\" : \"\" , \"licenseUrl\" : \"\" }, \"dependencies\" : { \"Microsoft.NETCore.App\" : { \"version\" : \"1.1.*\" , \"type\" : \"platform\" }, \"Microsoft.AspNetCore.Diagnostics\" : \"1.1.0\" , \"Microsoft.AspNetCore.Mvc\" : \"1.1.0\" , \"Microsoft.AspNetCore.Razor.Tools\" : { \"version\" : \"1.1.0-preview4-final\" , \"type\" : \"build\" }, \"Microsoft.AspNetCore.Server.IISIntegration\" : \"1.1.0\" , \"Microsoft.AspNetCore.Server.Kestrel\" : \"1.1.0\" , \"Microsoft.AspNetCore.StaticFiles\" : \"1.1.0\" , \"Microsoft.Extensions.Logging.Console\" : \"1.1.0\" , \"Microsoft.VisualStudio.Web.BrowserLink.Loader\" : \"14.1.0\" , \"System.Net.Http\" : \"4.3.0\" }, \"tools\" : { \"Microsoft.AspNetCore.Server.IISIntegration.Tools\" : \"1.0.0-preview2-final\" }, \"frameworks\" : { \"netcoreapp1.0\" : { \"imports\" : [ \"dotnet5.6\" , \"portable-net45+win8\" , \"dnxcore50\" ] } }, \"buildOptions\" : { \"emitEntryPoint\" : true , \"preserveCompilationContext\" : true }, \"runtimes\" : { \"win81-x64\" : {}, \"win7-x64\" : {}, \"osx.10.12-x64\" : {} }, \"runtimeOptions\" : { \"configProperties\" : { \"System.GC.Server\" : true } }, \"publishOptions\" : { \"include\" : [ \"wwwroot\" , \"web.config\" ] }, \"scripts\" : { \"postpublish\" : [ \"dotnet publish-iis --publish-folder %publish:OutputPath% --framework %publish:FullTargetFramework%\" ] } }","title":"Project.json"},{"location":"dotnet/new_project/#globaljson","text":"When you install the .NET Core SDK on Windows, it shows up in C:\\Program Files\\dotnet\\sdk folder. Using the \u201csdk\u201d option, we can override the default version. 1 2 3 4 5 6 { \"projects\" : [ \"src\" , \"test\" ], \"sdk\" : { \"version\" : \"1.0.0-preview2-1-003177\" } }","title":"Global.json"},{"location":"dotnet/new_project/#bowerjson","text":"If you need Bootstrap 3 for the styling of your website, add this bower.json file in the project root. 1 2 3 4 5 6 7 { \"name\" : \"asp.net\" , \"private\" : true , \"dependencies\" : { \"bootstrap\" : \"3.3.*\" } }","title":"Bower.json"},{"location":"dotnet/new_project/#programcs","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 using Microsoft.AspNetCore.Hosting ; using System.IO ; namespace NNMeta { public class Program { public static void Main ( string [] args ) { var host = new WebHostBuilder () . UseKestrel () . UseContentRoot ( Directory . GetCurrentDirectory ()) . UseIISIntegration () . UseStartup < Startup >() . Build (); host . Run (); } } }","title":"Program.cs"},{"location":"dotnet/new_project/#startupcs","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 using Microsoft.AspNetCore.Builder ; using Microsoft.AspNetCore.Hosting ; using Microsoft.Extensions.DependencyInjection ; using Microsoft.Extensions.Logging ; namespace NNMeta { public class Startup { public void ConfigureServices ( IServiceCollection services ) { services . AddMvc (); } public void Configure ( IApplicationBuilder app , IHostingEnvironment env , ILoggerFactory loggerFactory ) { if ( env . IsDevelopment ()) { app . UseDeveloperExceptionPage (); } app . UseStaticFiles (); app . UseMvcWithDefaultRoute (); } } }","title":"Startup.cs"},{"location":"dotnet/new_project/#controllershomecontrollercs","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 using System.Collections.Generic ; using Microsoft.AspNetCore.Mvc ; namespace NNMeta.Controllers { public class HomeController : Controller { public ViewResult Index () => View ( new Dictionary < string , string > { [\"Message1\"] = \"This is the first message from the Index action\" , [\"Message2\"] = \"This is the second message from the Index action\" }); } }","title":"Controllers/HomeController.cs"},{"location":"dotnet/new_project/#views_viewimportscshtml","text":"1 @addTagHelper *, Microsoft.AspNetCore.Mvc.TagHelpers","title":"Views/_ViewImports.cshtml"},{"location":"dotnet/new_project/#viewshomeindexcshtml","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @model Dictionary < string , string > @{ Layout = null; } <!DOCTYPE html> < html > < head > < meta name = \"viewport\" content = \"width=device-width\" /> < link asp-href-include = \"~/lib/bootstrap/dist/css/*.min.css\" rel = \"stylesheet\" /> < title > Result </ title > </ head > < body class = \"panel-body\" > < table class = \"table table-condensed table-bordered table-striped\" > < tr > @foreach (var kvp in Model) { < th > @kvp.Key </ th > } </ tr > < tr > @foreach (var kvp in Model) { < td > @kvp.Value </ td > } </ tr > </ table > </ body > </ html >","title":"Views/Home/Index.cshtml"},{"location":"dotnet/notes/","text":"Notes on ASP.NET Core \u00b6 I have written these notes while working on a couple of great books on the subject. See Sources used . Models - the M in MVC - contain the data that users work with. There are two broad types of model: view models , which represent just data passed from the controller to the view, and domain models , which contain the data in a business domain, along with the operations, transformations, and rules for creating, storing, and manipulating that data, collectively referred to as the model logic. In ASP.NET Core MVC, controllers are C# classes, usually derived from the Microsoft.AspNetCore.Mvc.Controller class. Each public method in a class derived from Controller is an action method , which is associated with a URL . Conventions \u00b6 put the third-party JavaScript and CSS packages you rely on in the wwwroot/lib folder. convention over configuration the controller for /product uri should have the name ProductController.cs and reside in the /Controllers folder; from other parts in the project, such as when using an HTML helper method, you specify the first part of the name ( Product ), and MVC automatically appends Controller to the name and starts looking for the controller class. views for /product uri associated with ProductController should all reside in the /Views/Product folder. MVC expects that the default view for an action method should be named after that method. For example, the default view associated with an action method called List should be called List.cshtml . Thus, for the List action method in the ProductController class, the default view is expected to be /Views/Product/List.cshtml . The default view is used when you return the result of calling the View method in an action method, like this: 1 return View (); You can specify a different view by name, like this: 1 return View ( \"MyOtherView\" ); When looking for a view , MVC looks in the folder named after the controller and then in the /Views/Shared folder. This means that I can put views that will be used by more than one controller in the /Views/Shared folder and MVC will find them. The naming convention for layouts is to prefix the file with an underscore ( _ ) character, and layout files are placed in the /Views/Shared folder. This layout is applied to all views by default through the /Views/_ViewStart.cshtml file. If you do not want the default layout applied to views, you can change the settings in ViewStart.cshtml (or delete the file entirely) to specify another layout in the view, like this: 1 2 3 @ { Layout = \"~/_MyLayout.cshtml\" ; } Or you can disable any layout for a given view, like this: 1 2 3 @ { Layout = null ; } Extension methods \u00b6 Class extensions \u00b6 Suppose we have a simple class: 1 2 3 4 5 6 7 8 9 using System.Collections.Generic ; namespace LanguageFeatures.Models { public class ShoppingCart { public IEnumerable < Product > Products { get ; set ; } } } We want to extend its functionality with a new method to calculate the total amount: 1 2 3 4 5 6 7 8 9 10 public static decimal TotalPrices ( this ShoppingCart cartParam ) { decimal total = 0 ; foreach ( Product prod in cartParam . Products ) { total += prod ?. Price ?? 0 ; } return total ; } We can then use this extension method like this: 1 2 ShoppingCart cart = new ShoppingCart { Products = Product . GetProducts () }; decimal cartTotal = cart . TotalPrices (); Interface extensions \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 using System.Collections ; using System.Collections.Generic ; namespace LanguageFeatures.Models { public class ShoppingCart : IEnumerable < Product > { public IEnumerable < Product > Products { get ; set ; } public IEnumerator < Product > GetEnumerator () { return Products . GetEnumerator (); } IEnumerator IEnumerable . GetEnumerator () { return GetEnumerator (); } } } We can rewrite our extension method like this: 1 2 3 4 5 6 7 8 9 10 public static decimal TotalPrices ( this IEnumerable < Product > products ) { decimal total = 0 ; foreach ( Product prod in products ) { total += prod ?. Price ?? 0 ; } return total ; } and use it with any object of type IEnumerable<Product> like ShoppingCart and Product array: 1 2 3 4 5 6 7 8 9 10 ShoppingCart cart = new ShoppingCart { Products = Product . GetProducts () }; Product [] productArray = { new Product { Name = \"Kayak\" , Price = 275 M }, new Product { Name = \"Lifejacket\" , Price = 48.95 M } }; decimal cartTotal = cart . TotalPrices (); decimal arrayTotal = productArray . TotalPrices (); Filtering \u00b6 Extension methods can be used to filter collections of objects. An extension method that operates on an IEnumerable<T> and that also returns an IEnumerable<T> can use the yield keyword to apply selection criteria to items in the source data to produce a reduced set of results. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 using System.Collections.Generic ; namespace LanguageFeatures.Models { public static class MyExtensionMethods { public static IEnumerable < Product > FilterByPrice ( this IEnumerable < Product > productEnum , decimal minimumPrice ) { foreach ( Product prod in productEnum ) { if (( prod ?. Price ?? 0 ) >= minimumPrice ) { yield return prod ; } } } } } Lambda anonymous functions \u00b6 We can repeat this process indefinitely and create a different filter method for every property and every combination of properties that we are interested in. A more elegant approach is to separate out the code that processes the enumeration from the selection criteria. C# makes this easy by allowing functions to be passed around as objects. We can then create a single extension method that filters an enumeration of Product objects but that delegates the decision about which ones are included in the results to a separate function. 1 2 3 4 5 6 7 8 9 10 11 12 public static IEnumerable < Product > Filter ( this IEnumerable < Product > productEnum , Func < Product , bool > selector ) { foreach ( Product prod in productEnum ) { if ( selector ( prod )) { yield return prod ; } } } Now, we can use this Filter function as follows: 1 2 3 4 5 6 decimal priceFilterTotal = productArray . Filter ( p => ( p ?. Price ?? 0 ) >= 20 ) . TotalPrices (); decimal nameFilterTotal = productArray . Filter ( p => p ?. Name ?[ 0 ] == 'S' ) . TotalPrices (); Lambdas can also be used in class properties, e.g.: 1 public bool NameBeginsWithS => Name ?[ 0 ] == 'S' ; Asynchronous methods \u00b6 Add \"System.Net.Http\": \"4.1.0\" dependency in project.json . Here is how we could make an asynchronous call \u201cthe hard way\u201d: 1 2 3 4 5 6 7 8 9 10 public static Task < long? > GetPageLengthWithoutAsyncAwait () { HttpClient client = new HttpClient (); var httpTask = client . GetAsync ( \"http://apress.com\" ); // we could do other things here while the HTTP request is performed return httpTask . ContinueWith (( Task < HttpResponseMessage > antecedent ) => { return antecedent . Result . Content . Headers . ContentLength ; }); } And here is the clever way: 1 2 3 4 5 6 7 public static async Task < long? > GetPageLength () { HttpClient client = new HttpClient (); var httpMessage = await client . GetAsync ( \"http://apress.com\" ); // we could do other things here while the HTTP request is performed return httpMessage . Content . Headers . ContentLength ; } And we could use this in our controller: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 using LanguageFeatures.Models ; using Microsoft.AspNetCore.Mvc ; using System.Threading.Tasks ; namespace LanguageFeatures.Controllers { public class HomeController : Controller { public async Task < ViewResult > Index () { long? length = await MyAsyncMethods . GetPageLength (); return View ( new string [] { $ \"Length: {length}\" }); } } } Getting property names with nameof \u00b6 If we use lambdas the classic way: 1 products . Select ( p => $ \"Name: {p.Name}, Price: {p.Price}\" ) we of course get no intellisense on Name: and Price: . So, if we change the property name in the class and forget to change these strings here, we get a mismatch. Fortunately, we can now rewrite the same code like this: 1 products . Select ( p => $ \"{nameof(p.Name)}: {p.Name}, {nameof(p.Price)}: {p.Price}\" ) but then we will get intellisense and type safety. Workflow with an empty project \u00b6 create a new empty ASP.NET Core project add \"Microsoft.AspNetCore.Mvc\": \"1.0.1\" dependency in project.json add \"System.Net.Http\": \"4.1.0\" dependency in project.json add Mvc to Startup.cs : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 using Microsoft.AspNetCore.Builder ; using Microsoft.AspNetCore.Hosting ; using Microsoft.Extensions.DependencyInjection ; using Microsoft.Extensions.Logging ; namespace LanguageFeatures { public class Startup { public void ConfigureServices ( IServiceCollection services ) { services . AddMvc (); } public void Configure ( IApplicationBuilder app , IHostingEnvironment env , ILoggerFactory loggerFactory ) { app . UseMvcWithDefaultRoute (); } } } The JSON Configuration Files \u00b6 Name Description global.json This file, which is found in the Solution Items folder, is responsible for telling Visual Studio where to find the projects in the solution and which version of the .NET execution environment should be used to run the application. launchSettings.json This file, which is revealed by expanding the Properties item in the MVC application project, is used to specify how the application is started. appsettings.json This file is used to define application-specific settings. bower.json This file is used by Bower to list the client-side packages that are installed into the project. bundleconfig.json This file is used to bundle and minify JavaScript and CSS files. project.json This file is used to specify the NuGet packages that are installed into the application. This file is also used for other project settings. project.lock.json This file, which is revealed by expanding the project.json item in the Solution Explorer, contains detailed dependencies between packages installed in the project. It is generated automatically and should not be edited manually. Razor \u00b6 View Imports File \u00b6 Use _ViewImports.cshtml file in the Views folder to specify the standard include namespaces. Then you can omit them in the individual views. View Start File \u00b6 Normally, we have to specify the layout file we want in every view. Therefore, if we need to rename the layout file, we are going to have to find every view that refers to it and make a change, which will be an error-prone process and counter to the general theme of easy maintenance that runs through MVC development. We can resolve this by using a view start file . When it renders a view, MVC will look for a file called _ViewStart.cshtml and we can put it in the Views folder. The contents of this file will be treated as though they were contained in the view file itself, and we can use this feature to automatically set a value for the Layout property. 1 2 3 @ { Layout = \"_BasicLayout\" ; } Now, in the views that should use this _BasicLayout , we can omit the layout line. We do not have to specify that we want to use the view start file. MVC will locate the file and use its contents automatically. The values defined in the view file take precedence, which makes it easy to override the view start file. We can also use multiple view start files to set defaults for different parts of the application. Razor looks for the closest view start file to the view that it being processed, which means that you can override the default setting by adding a view start file to the Views/Home or Views/Shared folders, for example. Caution It is important to understand the difference between omitting the Layout property from the view file and setting it to null . If your view is self-contained and you do not want to use a layout, then set the Layout property to null. If you omit the Layout property, then MVC will assume that you do want a layout and that it should use the value it finds in the view start file. ViewBag property \u00b6 The ViewBag property returns a dynamic object that can be used to define arbitrary properties. Since the ViewBag is dynamic, we don\u2019t have to declare the property names in advance, but it does mean that Visual Studio is unable to provide autocomplete suggestions for view bag properties. Attribute values \u00b6 We can also use Razor expressions to set the value of element attributes , not only on the content. 1 2 3 4 5 <div data-productid=\"@Model.ProductID\" data-stocklevel=\"@ViewBag.StockLevel\"> <p>Product Name: @Model.Name</p> <p>Product Price: @($\"{Model.Price:C2}\")</p> <p>Stock Level: @ViewBag.StockLevel</p> </div> Switch statement \u00b6 We have to cast the dynamic ViewBag properties to the right type once, inside the condition: 1 @switch ((int)ViewBag.StockLevel) {...} After that, inside the body, we dont need to do it any more: 1 2 3 default: @: @ViewBag.StockLevel in Stock break; We do not have to put the elements or expressions in quotes or denote them in any special way\u2014the Razor engine will interpret these as output to be processed. However, if we want to insert literal text into the view when it is not contained in an HTML element, then we need to give Razor a helping hand and prefix the line with an @ character (see above). Visual Studio tips and tricks \u00b6 Enable Developer Exception Page \u00b6 In Startup.cs add this line to the Configure method: 1 app . UseDeveloperExceptionPage (); Browser Link Loader \u00b6 Add 1 \"Microsoft.VisualStudio.Web.BrowserLink.Loader\" : \"14.0.0\" to project.json dependencies list. Also add 1 app . UseBrowserLink (); to the Configure method of Startup.cs . Run the project without debugging (Ctrl + F5) and you see this kind of code added to the HTML: 1 2 3 4 5 6 7 8 9 <!-- Visual Studio Browser Link --> < script type = \"application/json\" id = \"__browserLink_initializationData\" > { \"requestId\" : \"497a61f26544432a857e06ab5d501b7f\" , \"requestMappingFromServer\" : false } </ script > < script type = \"text/javascript\" src = \"http://localhost:2701/029471b4ee954e43adc0d452954d080f/browserLink\" async = \"async\" > </ script > <!-- End Browser Link --> Alas I still see no added value to it. :( Unless it is just the synchronized browsing using multiple browsers. I also see this error in the browser console: [14:07:17 GMT+0200 (West-Europa (zomertijd))] Browser Link: Failed to invoke return value callback: TypeError: Cannot read property 'files' of null Static files \u00b6 ASP.NET Core includes support for delivering static files from the wwwroot folder to clients but it isn\u2019t enabled by default when the Empty template is used to create the project. To enable static file support, add 1 \"Microsoft.AspNetCore.StaticFiles\" : \"1.0.0\" to project.json dependencies list. Also add 1 app . UseStaticFiles (); to the Configure method of Startup.cs . Bundling and minifying \u00b6 Install Bundler and Minifier extension for the Visual Studio. After that it is possible to add css or js files to the bundle by selecting them one by one and choosing Bundler & Minifier | Bundle and Minify Files (Shift + Alt + F) from the right mouse button menu. This will create a bundle.css or bundle.js file and also bundleconfig.json in the project root folder. Make sure the order of the files is what you need as loading order . Unit Testing with xUnit Framework \u00b6 Preparation \u00b6 create test folder inside the solution folder next to src folder add new .NET Core | Class Library (.NET Core) project inside the test folder add this code to its project.json file (check the latest versions): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"version\" : \"1.0.0-*\" , \"testRunner\" : \"xunit\" , \"dependencies\" : { \"Microsoft.NETCore.App\" : { \"type\" : \"platform\" , \"version\" : \"1.0.1\" }, \"xunit\" : \"2.1.0\" , \"dotnet-test-xunit\" : \"2.2.0-preview2-build1029\" }, \"frameworks\" : { \"netcoreapp1.0\" : { \"imports\" : [ \"dotnet5.6\" , \"portable-net45+win8\" ] } } } this configuration tells Visual Studio that three packages are required: the Microsoft.NETCore.App package provides the .NET Core API . the xunit package provides the testing framework. the dotnet-test-xunit package provides the integration between xUnit and Visual Studio . add the main project reference to the dependencies, e.g. 1 2 3 4 5 6 7 { \"dependencies\" : { ... \"WorkingWithVisualStudio\" : \"1.0.0\" ... } } Fact and Theory \u00b6 In the xUnit framework, a Fact is one single unit test. Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [Fact] public void IndexActionModelIsComplete () { // Arrange var controller = new HomeController (); controller . Repository = new ModelCompleteFakeRepository (); // Act var model = ( controller . Index () as ViewResult )?. ViewData . Model as IEnumerable < Product >; // Assert Assert . Equal ( controller . Repository . Products , model , Comparer . Get < Product >(( p1 , p2 ) => p1 . Name == p2 . Name && p1 . Price == p2 . Price )); } A Theory is a way to parametrize the unit test in such a way that it becomes possible to run the same test multiple times, each time with a different set of parameter values. Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 [Theory] [InlineData(275, 48.95, 19.50, 24.95)] [InlineData(5, 48.95, 19.50, 24.95)] public void IndexActionModelIsComplete ( decimal price1 , decimal price2 , decimal price3 , decimal price4 ) { // Arrange var controller = new HomeController (); controller . Repository = new ModelCompleteFakeRepository { Products = new Product [] { new Product { Name = \"P1\" , Price = price1 }, new Product { Name = \"P2\" , Price = price2 }, new Product { Name = \"P3\" , Price = price3 }, new Product { Name = \"P4\" , Price = price4 }, } }; // Act var model = ( controller . Index () as ViewResult )?. ViewData . Model as IEnumerable < Product >; // Assert Assert . Equal ( controller . Repository . Products , model , Comparer . Get < Product >(( p1 , p2 ) => p1 . Name == p2 . Name && p1 . Price == p2 . Price )); } Getting Test Data from a Method or Property \u00b6 We can create methods or properties giving us the enumerations for the test parameter values in a separate class, e.g. ProductTestData.cs . Then we can use MemberData attribute to specify it for the unit test to use. Example: 1 2 3 [Theory] [ClassData(typeof(ProductTestData))] public void IndexActionModelIsComplete ( Product [] products ) {...} If we want to include the test data in the same class as the unit tests, then you can use the MemberData attribute instead of ClassData . The MemberData attribute is configured using a string that specifies the name of a static method that will provide an IEnumerable<object[]> , where each object array in the sequence is a set of arguments for the test method. Example: 1 2 3 [Theory] [MemberData(\"GetData\")] public void IndexActionModelIsComplete ( Product [] products ) {...} and the GetData should look something like this 1 2 3 4 5 6 7 8 9 public static IEnumerable < object []> GetData { get { // ... yield return new object [] { 8 , 21 }; yield return new object [] { 16 , 987 }; } } Every yield statement should return an array of objects to substitute for the Product properties. And the method itself should be of type IEnumerable<object[]> . Mocking with MOQ \u00b6 Microsoft created a special fork of the Moq project and ported it to work with .NET Core . In order to be able to install the Moq NuGet package , we need first to configure the NuGet Options . Open Tools | Options | NuGet Package Manager , click on Package Sources and then on the green plus sign. Configure the new package source as follows: Name: ASP.NET Contrib Source: https://www.myget.org/F/aspnet-contrib/api/v3/index.json Add these two packages to the package.json in the test project: 1 2 \"moq.netcore\" : \"4.4.0-beta8\" \"System.Diagnostics.TraceSource\" : \"4.0.0\" Usage example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [Fact] public void RepositoryPropertyCalledOnce () { // Arrange var mock = new Mock < IRepository >(); mock . SetupGet ( m => m . Products ) . Returns ( new [] { new Product { Name = \"P1\" , Price = 100 } }); var controller = new HomeController { Repository = mock . Object }; // Act var result = controller . Index (); // Assert mock . VerifyGet ( m => m . Products , Times . Once ); } Explanation: var mock = new Mock<IRepository>(); - define the interface to be mocked SetupGet(m => m.Products) - specify the property to be tested .Returns(...) - specify the test value to be returned Repository = mock.Object - Object is the special property that gives back the object we mock for this test mock.VerifyGet(m => m.Products, Times.Once); - one of the verify methods to inspect the getter property SportsStore \u00b6 Create a new empty ASP.NET Core Web Application (.NET Core) project/solution. Add these packages/tools to the project.json file: 1 2 3 4 5 6 7 8 9 10 11 12 13 \"dependencies\" : { ... \"Microsoft.AspNetCore.Razor.Tools\" : { \"version\" : \"1.0.0-preview2-final\" , \"type\" : \"build\" }, \"Microsoft.AspNetCore.StaticFiles\" : \"1.0.0\" , \"Microsoft.AspNetCore.Mvc\" : \"1.0.1\" } , \"tools\" : { \"Microsoft.AspNetCore.Razor.Tools\" : \"1.0.0-preview2-final\" , ... } , In addition to the packages in the dependencies section, there is an addition to the tools section of the project.json file that configures the Microsoft.AspNetCore.Razor.Tools package for use in Visual Studio and enables IntelliSense for the built-in tag helpers, which are used to create HTML content that is tailored to the configuration of the MVC application. Here is the Startup.cs : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 using Microsoft.AspNetCore.Builder ; using Microsoft.AspNetCore.Hosting ; using Microsoft.AspNetCore.Http ; using Microsoft.Extensions.DependencyInjection ; using Microsoft.Extensions.Logging ; namespace SportsStore { public class Startup { public void ConfigureServices ( IServiceCollection services ) { services . AddMvc (); } public void Configure ( IApplicationBuilder app , IHostingEnvironment env , ILoggerFactory loggerFactory ) { app . UseDeveloperExceptionPage (); app . UseStatusCodePages (); app . UseStaticFiles (); app . UseMvcWithDefaultRoute (); } } } The ConfigureServices method is used to set up shared objects that can be used throughout the application through the dependency injection feature. The AddMvc method that is called in the ConfigureServices method is an extension method that sets up the shared objects used in MVC applications. The Configure method is used to set up the features that receive and process HTTP requests . add these folders: Models , Controllers , Views in the Views folder add _ViewImports.cshtml file: 1 2 @using SportsStore . Models @addTagHelper *, Microsoft . AspNetCore . Mvc . TagHelpers create the unit test project SportsStore.Tests in the test folder. Configure its project .json as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"version\" : \"1.0.0-*\" , \"testRunner\" : \"xunit\" , \"dependencies\" : { \"Microsoft.NETCore.App\" : { \"type\" : \"platform\" , \"version\" : \"1.0.1\" }, \"xunit\" : \"2.1.0\" , \"dotnet-test-xunit\" : \"2.2.0-preview2-build1029\" , \"moq.netcore\" : \"4.4.0-beta8\" , \"System.Diagnostics.TraceSource\" : \"4.0.0\" , \"SportsStore\" : \"1.0.0\" }, \"frameworks\" : { \"netcoreapp1.0\" : { \"imports\" : [ \"dotnet5.6\" , \"portable-net45+win8\" ] } } } Make sure that both project.json files refer to the same ASP.NET Core MVC version. Add your model class Product.cs , repository interface IProductRepository and a simple fake repository FakeProductRepository Register the fake repository as a service in Startup.cs : 1 2 3 4 5 public void ConfigureServices ( IServiceCollection services ) { services . AddTransient < IProductRepository , FakeProductRepository >(); ... } Add the following standard views: Views/Shared/_Layout.cshtml Views/_ViewStart.cshtml refering to _Layout.cshtml by default Example of setting up the default route in Startup.cs . Substitute 1 app . UseMvcWithDefaultRoute (); with 1 2 3 4 5 6 app . UseMvc ( routes => { routes . MapRoute ( name : \"default\" , template : \"{controller=Product}/{action=List}/{id?}\" ); }); Scaffolding \u00b6 Some people prefer to have certain features automatically created when they create new controller or views. That is called scaffolding . If you want that, add the following packages to the project.json file: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 ... \"dependencies\" : { ... \"Microsoft.AspNetCore.StaticFiles\" : \"1.0.0\" , \"Microsoft.AspNetCore.Mvc\" : \"1.0.0\" , \"Microsoft.VisualStudio.Web.CodeGeneration.Tools\" : { \"version\" : \"1.0.0-preview2-final\" , \"type\" : \"build\" }, \"Microsoft.VisualStudio.Web.CodeGenerators.Mvc\" : { \"version\" : \"1.0.0-preview2-final\" , \"type\" : \"build\" } } ... \"tools\" : { ... \"Microsoft.VisualStudio.Web.CodeGeneration.Tools\" : { \"version\" : \"1.0.0-preview2-final\" , \"imports\" : [ \"portable-net45+win8+dnxcore50\" , \"portable-net45+win8\" ] } } ... Setup the database \u00b6 add EntityFramework packages to package.json : 1 2 3 4 5 \"dependencies\" : { ... \"Microsoft.EntityFrameworkCore.SqlServer\" : \"1.0.1\" , \"Microsoft.EntityFrameworkCore.Tools\" : \"1.0.0-preview2-final\" } and the tools: 1 2 3 4 5 6 7 \"tools\" : { ... \"Microsoft.EntityFrameworkCore.Tools\" : { \"version\" : \"1.0.0-preview2-final\" , \"imports\" : [ \"portable-net45+win8+dnxcore50\" , \"portable-net45+win8\" ] } } The database context class is the bridge between the application and the EF Core and provides access to the application\u2019s data using model objects. To create the database context class for the SportsStore application, we add a class file called ApplicationDbContext.cs to the Models folder: 1 2 3 4 5 6 7 8 9 10 11 using Microsoft.EntityFrameworkCore ; namespace SportsStore.Models { public class ApplicationDbContext : DbContext { public ApplicationDbContext ( DbContextOptions < ApplicationDbContext > options ) : base ( options ) { } public DbSet < Product > Products { get ; set ; } } } To populate the database initially with some data, we use SeedData.cs class: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 using System.Linq ; using Microsoft.AspNetCore.Builder ; using Microsoft.Extensions.DependencyInjection ; namespace SportsStore.Models { public static class SeedData { public static void EnsurePopulated ( IApplicationBuilder app ) { ApplicationDbContext context = app . ApplicationServices . GetRequiredService < ApplicationDbContext >(); if (! context . Products . Any ()) { context . Products . AddRange ( new Product { Name = \"Kayak\" , Description = \"A boat for one person\" , Category = \"Watersports\" , Price = 275 }, ... context . SaveChanges (); } } } } The static EnsurePopulated method receives an IApplicationBuilder argument, which is the class used in the Configure method of the Startup class to register middleware classes to handle HTTP requests, which is where we ensure that the database has content. The EnsurePopulated method obtains an ApplicationDbContext object through the IApplicationBuilder interface and uses it to check whether there are any Product objects in the database. If there are no objects, then the database is populated using a collection of Product objects using the AddRange method and then written to the database using the SaveChanges method. The next step is to create a class that implements the IProductRepository interface and gets its data using Entity Framework Core from the ApplicationDbContext . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 using System.Collections.Generic ; namespace SportsStore.Models { public class EFProductRepository : IProductRepository { private ApplicationDbContext context ; public EFProductRepository ( ApplicationDbContext ctx ) { context = ctx ; } public IEnumerable < Product > Products => context . Products ; } } create appsettings.json file in the project root folder based on the ASP.NET Configuration File template and configure the connection string: 1 2 3 4 5 6 7 { \"Data\" : { \"SportStoreProducts\" : { \"ConnectionString\" : \"Server=(localdb)\\\\MSSQLLocalDB;Database=SportsStore;Trusted_Connection=True;MultipleActiveResultSets=true\" } } } add a new dependency to read the json configuration file: 1 2 3 4 \"dependencies\" : { ... \"Microsoft.Extensions.Configuration.Json\" : \"1.0.0\" } , configure the Startup.cs : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 ... using Microsoft.EntityFrameworkCore ; using Microsoft.Extensions.Configuration ; namespace SportsStore { public class Startup { IConfigurationRoot Configuration ; public Startup ( IHostingEnvironment env ) { Configuration = new ConfigurationBuilder () . SetBasePath ( env . ContentRootPath ) . AddJsonFile ( \"appsettings.json\" ). Build (); } public void ConfigureServices ( IServiceCollection services ) { services . AddDbContext < ApplicationDbContext >( options => options . UseSqlServer ( Configuration [ \"Data:SportStoreProducts:ConnectionString\" ])); services . AddTransient < IProductRepository , EFProductRepository >(); ... } public void Configure ( IApplicationBuilder app , IHostingEnvironment env , ILoggerFactory loggerFactory ) { ... SeedData . EnsurePopulated ( app ); } } } open Tools | Nuget Package Manager | Package Manager Console to create and apply database migrations: 1 2 Add-Migration Initial Update-Database rebuild the solution and run - we will see the list of products loaded from the database. ViewModels and TagHelpers \u00b6 If we want to customize the information to be used in the view, we can do that with ViewModels . For that we create a ViewModels subfolder inside the Models folder. They can be registered in _ViewImports.cshtml . TagHelpers are one of the most useful ways that you can introduce C# logic into your views. The code for a tag helper can look tortured because C# and HTML don\u2019t mix easily. But using tag helpers is preferable to including blocks of C# code in a view because a tag helper can be easily unit tested . Most MVC components, such as controllers and views, are discovered automatically, but tag helpers have to be registered in _ViewImports.cshtml . To test the tag helper class, I call the Process method with test data and provide a TagHelperOutput object that is inspected to see the HTML that was generated. When we pass the data to the view via a view model, we need to replace the type. E.g. it can become @model ProductsListViewModel and Model.Products instead of @model IEnumerable<Product> and Model . Installing Bootstrap package \u00b6 Add bower.json file to the project root: 1 2 3 4 5 6 7 { \"name\" : \"asp.net\" , \"private\" : true , \"dependencies\" : { \"bootstrap\" : \"3.3.7\" } } This will add wwwroot/lib folder and inside it bootstrap and jquery sources. Improving the URLs \u00b6 Normally, the page links look like this: http://localhost/?page=2 But we can make them more user friendly by creating a scheme that follows the pattern of composable URLs , which look like this: http://localhost/Page2 To do that we register a new route in our MVC middleware ( Configure method in Startup.cs ): 1 2 3 4 routes . MapRoute ( name : \"pagination\" , template : \"Products/Page{page}\" , defaults : new { Controller = \"Product\" , action = \"List\" }); It is important that this route is added before the default route. Enabling Sessions \u00b6 Add these new packages to the package.json : 1 2 3 \"Microsoft.AspNetCore.Session\" : \"1.0.0\" , \"Microsoft.Extensions.Caching.Memory\" : \"1.0.0\" , \"Microsoft.AspNetCore.Http.Extensions\" : \"1.0.0\" Register new services and middleware to the Startup.cs : 1 2 3 4 5 6 7 8 9 10 11 12 public void ConfigureServices ( IServiceCollection services ) { ... services . AddMemoryCache (); services . AddSession (); services . AddMvc (); } public void Configure ( IApplicationBuilder app , ... app . UseSession (); app . UseMvc (...); } AddMemoryCache The AddMemoryCache method call sets up the in-memory data store. The AddSession method registers the services used to access session data, and the UseSession method allows the session system to automatically associate requests with sessions when they arrive from the client. Annotations \u00b6 BindNever attribute prevents the user supplying values for these properties in an HTTP request. Adding migrations \u00b6 Suppose we add a new DbSet to our ApplicationDbContext.cs : 1 2 3 4 5 6 7 public class ApplicationDbContext : DbContext { public ApplicationDbContext ( DbContextOptions < ApplicationDbContext > options ) : base ( options ) { } ... public DbSet < Order > Orders { get ; set ; } } To create the migration , open the NuGet Package Manger Console from the Tools \u27a4 NuGet Package Manage menu and run the following command : Add-Migration Orders This command tells EF Core to take a new snapshot of the application, work out how it differs from the previous database version, and generate a new migration called Orders . The name Orders here is arbitrary but it is handy to let it reflect the change. To update the database schema, run the following command: Update-Database Resetting the Database \u00b6 When you are making frequent changes to the model, there will come a point when your migrations and your database schema get out of sync. The easiest thing to do is delete the database and start over. However, this applies only during development , of course, because you will lose any data you have stored. Select the SQL Server Object Explorer item from the Visual Studio View menu and click the Add Sql Server button. Enter (localdb)\\mssqllocaldb into the Server Name field and click the Connect button. A new item will appear in the SQL Server Object Explorer window, which you can expand to see the LocalDB databases that have been created. Right-click the database you want to remove and select Delete from the pop-up menu. Check the option to close the existing connections and then click the OK button to delete the database. Once the database has been removed, run the following command from the Package Manager Console to create the database and apply the migrations you have created by running the following command: Update-Database This will reset the database so that it accurately reflects your model and allow you to return to developing your application. Using TempData \u00b6 We are using TempData in the POST method in a controller: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [HttpPost] public IActionResult Edit ( Product product ) { if ( ModelState . IsValid ) { _repository . SaveProduct ( product ); TempData [ \"message\" ] = $ \"{product.Name} has been saved\" ; return RedirectToAction ( \"Index\" ); } else { // there is something wrong with the data values return View ( product ); } } We check that the model binding process has been able to validate the data submitted to the user by reading the value of the ModelState.IsValid property. If everything is OK, we save the changes to the repository and redirect the user to the Index action so they see the modified list of products. If there is a problem with the data, we render the default view again so that the user can make corrections. After we have saved the changes in the repository, we store a message using the TempData feature, which is part of the ASP.NET Core session state feature. This is a key/value dictionary similar to the session data and view bag features we used previously. The key difference from session data is that temp data persists until it is read. We cannot use ViewBag in this situation because ViewBag passes data between the controller and view , and it cannot hold data for longer than the current HTTP request . When an edit succeeds, the browser is redirected to a new URL, so the ViewBag data is lost. We could use the session data feature, but then the message would be persistent until we explicitly removed it, which we would rather not have to do. So, the temp data feature is the perfect fit. The data is restricted to a single user\u2019s session (so that users do not see each other\u2019s TempData ) and will persist long enough for us to read it. We will read the data in the view rendered by the action method to which we redirect the user The message will be displayed once and disappear if you reload the screen with the template using this temp data , because TempData is deleted when it is read. That is convenient since we do not want old messages hanging around. Localization hell \u00b6 By the time we get to editing with validation, something bad happens. It looks that by default the jQuery-validation (client side validation) expects \"en-US\" as its culture and the server side validation expects \"nl-NL\" . Therefore, when I see \u20ac as currency and \",\" as decimal separator, I cannot change the price. Neither \",\" nor \".\" are accepted. One is rejected by the client side and the other by the server side validation. Temporary workaround was to configure \"en-US\" as the default culture, so that \"$\" and \".\" are displayed on the screen. Then the validation works. Adding Identity \u00b6 Add a new dependency to project.json : 1 2 3 4 \"dependencies\" : { ... \"Microsoft.AspNetCore.Identity.EntityFrameworkCore\" : \"1.0.0\" } Add a new AppIdentityDbContext class to Models folder: 1 2 3 4 5 6 7 8 9 10 11 using Microsoft.AspNetCore.Identity.EntityFrameworkCore ; using Microsoft.EntityFrameworkCore ; namespace SportsStore.Models { public class AppIdentityDbContext : IdentityDbContext < IdentityUser > { public AppIdentityDbContext ( DbContextOptions < AppIdentityDbContext > options ) : base ( options ) { } } } and a new connection string in appsettings.json file: 1 2 3 4 5 6 7 8 { \"Data\" : { ... \"SportStoreIdentity\" : { \"ConnectionString\" : \"Server=(localdb)\\\\MSSQLLocalDB;Database=Identity;Trusted_Connection=True;MultipleActiveResultSets=true\" } } } Add new services to ConfigureServices in Startup.cs : 1 2 3 4 5 6 7 8 9 10 public void ConfigureServices ( IServiceCollection services ) { ... services . AddDbContext < AppIdentityDbContext >( options => options . UseSqlServer ( Configuration [ \"Data:SportStoreIdentity:ConnectionString\" ])); services . AddIdentity < IdentityUser , IdentityRole >() . AddEntityFrameworkStores < AppIdentityDbContext >(); ... } and new entries in Configure : 1 2 3 4 5 6 public void Configure () app . UseIdentity (); app . UseMvc (); SeedData . EnsurePopulated ( app ); IdentitySeedData . EnsurePopulated ( app ); } IdentitySeedData should be created in the Models folder to create an administrative account. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 using Microsoft.AspNetCore.Builder ; using Microsoft.AspNetCore.Identity ; using Microsoft.AspNetCore.Identity.EntityFrameworkCore ; using Microsoft.Extensions.DependencyInjection ; namespace SportsStore.Models { public static class IdentitySeedData { private const string adminUser = \"Admin\" ; private const string adminPassword = \"Secret123$\" ; public static async void EnsurePopulated ( IApplicationBuilder app ) { UserManager < IdentityUser > userManager = app . ApplicationServices . GetRequiredService < UserManager < IdentityUser >>(); IdentityUser user = await userManager . FindByIdAsync ( adminUser ); if ( user == null ) { user = new IdentityUser ( \"Admin\" ); await userManager . CreateAsync ( user , adminPassword ); } } } } Adding Identity migrations \u00b6 Add-Migration Initial -Context AppIdentityDbContext Update-Database -Context AppIdentityDbContext This will create the new database and add the AspNetUsers and AspNetRoles in it. Adding Authorization \u00b6 When ASP.NET Core Identity is in place, we can apply Authorization . We don\u2019t want to stop unauthenticated users from accessing the other action methods in the Order controller, so we have applied the Authorize attribute only to the List and MarkShipped methods. 1 2 3 4 5 6 7 [Authorize] public ViewResult List () => View ( _repository . Orders . Where ( o => ! o . Shipped )); [HttpPost] [Authorize] public IActionResult MarkShipped ( int orderID ) {...} We want to protect all of the action methods defined by the Admin controller, and we can do this by applying the Authorize attribute to the controller class, which then applies the authorization policy to all the action methods it contains. 1 2 3 [Authorize] public class AdminController : Controller {...} Caution In general, using client-side data validation is a good idea. It offloads some of the work from your server and gives users immediate feedback about the data they are providing. However, you should not be tempted to perform authentication at the client, as this would typically involve sending valid credentials to the client so they can be used to check the username and password that the user has entered, or at least trusting the client\u2019s report of whether they have successfully authenticated. Authentication should always be done at the server. Sources used \u00b6 Adam Freeman - Pro ASP.NET Core MVC (2016) Christian Nagel - Professional C# 6 and .NET Core 1.0 (2016)","title":"Notes"},{"location":"dotnet/notes/#notes-on-aspnet-core","text":"I have written these notes while working on a couple of great books on the subject. See Sources used . Models - the M in MVC - contain the data that users work with. There are two broad types of model: view models , which represent just data passed from the controller to the view, and domain models , which contain the data in a business domain, along with the operations, transformations, and rules for creating, storing, and manipulating that data, collectively referred to as the model logic. In ASP.NET Core MVC, controllers are C# classes, usually derived from the Microsoft.AspNetCore.Mvc.Controller class. Each public method in a class derived from Controller is an action method , which is associated with a URL .","title":"Notes on ASP.NET Core"},{"location":"dotnet/notes/#conventions","text":"put the third-party JavaScript and CSS packages you rely on in the wwwroot/lib folder. convention over configuration the controller for /product uri should have the name ProductController.cs and reside in the /Controllers folder; from other parts in the project, such as when using an HTML helper method, you specify the first part of the name ( Product ), and MVC automatically appends Controller to the name and starts looking for the controller class. views for /product uri associated with ProductController should all reside in the /Views/Product folder. MVC expects that the default view for an action method should be named after that method. For example, the default view associated with an action method called List should be called List.cshtml . Thus, for the List action method in the ProductController class, the default view is expected to be /Views/Product/List.cshtml . The default view is used when you return the result of calling the View method in an action method, like this: 1 return View (); You can specify a different view by name, like this: 1 return View ( \"MyOtherView\" ); When looking for a view , MVC looks in the folder named after the controller and then in the /Views/Shared folder. This means that I can put views that will be used by more than one controller in the /Views/Shared folder and MVC will find them. The naming convention for layouts is to prefix the file with an underscore ( _ ) character, and layout files are placed in the /Views/Shared folder. This layout is applied to all views by default through the /Views/_ViewStart.cshtml file. If you do not want the default layout applied to views, you can change the settings in ViewStart.cshtml (or delete the file entirely) to specify another layout in the view, like this: 1 2 3 @ { Layout = \"~/_MyLayout.cshtml\" ; } Or you can disable any layout for a given view, like this: 1 2 3 @ { Layout = null ; }","title":"Conventions"},{"location":"dotnet/notes/#extension-methods","text":"","title":"Extension methods"},{"location":"dotnet/notes/#class-extensions","text":"Suppose we have a simple class: 1 2 3 4 5 6 7 8 9 using System.Collections.Generic ; namespace LanguageFeatures.Models { public class ShoppingCart { public IEnumerable < Product > Products { get ; set ; } } } We want to extend its functionality with a new method to calculate the total amount: 1 2 3 4 5 6 7 8 9 10 public static decimal TotalPrices ( this ShoppingCart cartParam ) { decimal total = 0 ; foreach ( Product prod in cartParam . Products ) { total += prod ?. Price ?? 0 ; } return total ; } We can then use this extension method like this: 1 2 ShoppingCart cart = new ShoppingCart { Products = Product . GetProducts () }; decimal cartTotal = cart . TotalPrices ();","title":"Class extensions"},{"location":"dotnet/notes/#interface-extensions","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 using System.Collections ; using System.Collections.Generic ; namespace LanguageFeatures.Models { public class ShoppingCart : IEnumerable < Product > { public IEnumerable < Product > Products { get ; set ; } public IEnumerator < Product > GetEnumerator () { return Products . GetEnumerator (); } IEnumerator IEnumerable . GetEnumerator () { return GetEnumerator (); } } } We can rewrite our extension method like this: 1 2 3 4 5 6 7 8 9 10 public static decimal TotalPrices ( this IEnumerable < Product > products ) { decimal total = 0 ; foreach ( Product prod in products ) { total += prod ?. Price ?? 0 ; } return total ; } and use it with any object of type IEnumerable<Product> like ShoppingCart and Product array: 1 2 3 4 5 6 7 8 9 10 ShoppingCart cart = new ShoppingCart { Products = Product . GetProducts () }; Product [] productArray = { new Product { Name = \"Kayak\" , Price = 275 M }, new Product { Name = \"Lifejacket\" , Price = 48.95 M } }; decimal cartTotal = cart . TotalPrices (); decimal arrayTotal = productArray . TotalPrices ();","title":"Interface extensions"},{"location":"dotnet/notes/#filtering","text":"Extension methods can be used to filter collections of objects. An extension method that operates on an IEnumerable<T> and that also returns an IEnumerable<T> can use the yield keyword to apply selection criteria to items in the source data to produce a reduced set of results. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 using System.Collections.Generic ; namespace LanguageFeatures.Models { public static class MyExtensionMethods { public static IEnumerable < Product > FilterByPrice ( this IEnumerable < Product > productEnum , decimal minimumPrice ) { foreach ( Product prod in productEnum ) { if (( prod ?. Price ?? 0 ) >= minimumPrice ) { yield return prod ; } } } } }","title":"Filtering"},{"location":"dotnet/notes/#lambda-anonymous-functions","text":"We can repeat this process indefinitely and create a different filter method for every property and every combination of properties that we are interested in. A more elegant approach is to separate out the code that processes the enumeration from the selection criteria. C# makes this easy by allowing functions to be passed around as objects. We can then create a single extension method that filters an enumeration of Product objects but that delegates the decision about which ones are included in the results to a separate function. 1 2 3 4 5 6 7 8 9 10 11 12 public static IEnumerable < Product > Filter ( this IEnumerable < Product > productEnum , Func < Product , bool > selector ) { foreach ( Product prod in productEnum ) { if ( selector ( prod )) { yield return prod ; } } } Now, we can use this Filter function as follows: 1 2 3 4 5 6 decimal priceFilterTotal = productArray . Filter ( p => ( p ?. Price ?? 0 ) >= 20 ) . TotalPrices (); decimal nameFilterTotal = productArray . Filter ( p => p ?. Name ?[ 0 ] == 'S' ) . TotalPrices (); Lambdas can also be used in class properties, e.g.: 1 public bool NameBeginsWithS => Name ?[ 0 ] == 'S' ;","title":"Lambda anonymous functions"},{"location":"dotnet/notes/#asynchronous-methods","text":"Add \"System.Net.Http\": \"4.1.0\" dependency in project.json . Here is how we could make an asynchronous call \u201cthe hard way\u201d: 1 2 3 4 5 6 7 8 9 10 public static Task < long? > GetPageLengthWithoutAsyncAwait () { HttpClient client = new HttpClient (); var httpTask = client . GetAsync ( \"http://apress.com\" ); // we could do other things here while the HTTP request is performed return httpTask . ContinueWith (( Task < HttpResponseMessage > antecedent ) => { return antecedent . Result . Content . Headers . ContentLength ; }); } And here is the clever way: 1 2 3 4 5 6 7 public static async Task < long? > GetPageLength () { HttpClient client = new HttpClient (); var httpMessage = await client . GetAsync ( \"http://apress.com\" ); // we could do other things here while the HTTP request is performed return httpMessage . Content . Headers . ContentLength ; } And we could use this in our controller: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 using LanguageFeatures.Models ; using Microsoft.AspNetCore.Mvc ; using System.Threading.Tasks ; namespace LanguageFeatures.Controllers { public class HomeController : Controller { public async Task < ViewResult > Index () { long? length = await MyAsyncMethods . GetPageLength (); return View ( new string [] { $ \"Length: {length}\" }); } } }","title":"Asynchronous methods"},{"location":"dotnet/notes/#getting-property-names-with-nameof","text":"If we use lambdas the classic way: 1 products . Select ( p => $ \"Name: {p.Name}, Price: {p.Price}\" ) we of course get no intellisense on Name: and Price: . So, if we change the property name in the class and forget to change these strings here, we get a mismatch. Fortunately, we can now rewrite the same code like this: 1 products . Select ( p => $ \"{nameof(p.Name)}: {p.Name}, {nameof(p.Price)}: {p.Price}\" ) but then we will get intellisense and type safety.","title":"Getting property names with nameof"},{"location":"dotnet/notes/#workflow-with-an-empty-project","text":"create a new empty ASP.NET Core project add \"Microsoft.AspNetCore.Mvc\": \"1.0.1\" dependency in project.json add \"System.Net.Http\": \"4.1.0\" dependency in project.json add Mvc to Startup.cs : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 using Microsoft.AspNetCore.Builder ; using Microsoft.AspNetCore.Hosting ; using Microsoft.Extensions.DependencyInjection ; using Microsoft.Extensions.Logging ; namespace LanguageFeatures { public class Startup { public void ConfigureServices ( IServiceCollection services ) { services . AddMvc (); } public void Configure ( IApplicationBuilder app , IHostingEnvironment env , ILoggerFactory loggerFactory ) { app . UseMvcWithDefaultRoute (); } } }","title":"Workflow with an empty project"},{"location":"dotnet/notes/#the-json-configuration-files","text":"Name Description global.json This file, which is found in the Solution Items folder, is responsible for telling Visual Studio where to find the projects in the solution and which version of the .NET execution environment should be used to run the application. launchSettings.json This file, which is revealed by expanding the Properties item in the MVC application project, is used to specify how the application is started. appsettings.json This file is used to define application-specific settings. bower.json This file is used by Bower to list the client-side packages that are installed into the project. bundleconfig.json This file is used to bundle and minify JavaScript and CSS files. project.json This file is used to specify the NuGet packages that are installed into the application. This file is also used for other project settings. project.lock.json This file, which is revealed by expanding the project.json item in the Solution Explorer, contains detailed dependencies between packages installed in the project. It is generated automatically and should not be edited manually.","title":"The JSON Configuration Files"},{"location":"dotnet/notes/#razor","text":"","title":"Razor"},{"location":"dotnet/notes/#view-imports-file","text":"Use _ViewImports.cshtml file in the Views folder to specify the standard include namespaces. Then you can omit them in the individual views.","title":"View Imports File"},{"location":"dotnet/notes/#view-start-file","text":"Normally, we have to specify the layout file we want in every view. Therefore, if we need to rename the layout file, we are going to have to find every view that refers to it and make a change, which will be an error-prone process and counter to the general theme of easy maintenance that runs through MVC development. We can resolve this by using a view start file . When it renders a view, MVC will look for a file called _ViewStart.cshtml and we can put it in the Views folder. The contents of this file will be treated as though they were contained in the view file itself, and we can use this feature to automatically set a value for the Layout property. 1 2 3 @ { Layout = \"_BasicLayout\" ; } Now, in the views that should use this _BasicLayout , we can omit the layout line. We do not have to specify that we want to use the view start file. MVC will locate the file and use its contents automatically. The values defined in the view file take precedence, which makes it easy to override the view start file. We can also use multiple view start files to set defaults for different parts of the application. Razor looks for the closest view start file to the view that it being processed, which means that you can override the default setting by adding a view start file to the Views/Home or Views/Shared folders, for example. Caution It is important to understand the difference between omitting the Layout property from the view file and setting it to null . If your view is self-contained and you do not want to use a layout, then set the Layout property to null. If you omit the Layout property, then MVC will assume that you do want a layout and that it should use the value it finds in the view start file.","title":"View Start File"},{"location":"dotnet/notes/#viewbag-property","text":"The ViewBag property returns a dynamic object that can be used to define arbitrary properties. Since the ViewBag is dynamic, we don\u2019t have to declare the property names in advance, but it does mean that Visual Studio is unable to provide autocomplete suggestions for view bag properties.","title":"ViewBag property"},{"location":"dotnet/notes/#attribute-values","text":"We can also use Razor expressions to set the value of element attributes , not only on the content. 1 2 3 4 5 <div data-productid=\"@Model.ProductID\" data-stocklevel=\"@ViewBag.StockLevel\"> <p>Product Name: @Model.Name</p> <p>Product Price: @($\"{Model.Price:C2}\")</p> <p>Stock Level: @ViewBag.StockLevel</p> </div>","title":"Attribute values"},{"location":"dotnet/notes/#switch-statement","text":"We have to cast the dynamic ViewBag properties to the right type once, inside the condition: 1 @switch ((int)ViewBag.StockLevel) {...} After that, inside the body, we dont need to do it any more: 1 2 3 default: @: @ViewBag.StockLevel in Stock break; We do not have to put the elements or expressions in quotes or denote them in any special way\u2014the Razor engine will interpret these as output to be processed. However, if we want to insert literal text into the view when it is not contained in an HTML element, then we need to give Razor a helping hand and prefix the line with an @ character (see above).","title":"Switch statement"},{"location":"dotnet/notes/#visual-studio-tips-and-tricks","text":"","title":"Visual Studio tips and tricks"},{"location":"dotnet/notes/#enable-developer-exception-page","text":"In Startup.cs add this line to the Configure method: 1 app . UseDeveloperExceptionPage ();","title":"Enable Developer Exception Page"},{"location":"dotnet/notes/#browser-link-loader","text":"Add 1 \"Microsoft.VisualStudio.Web.BrowserLink.Loader\" : \"14.0.0\" to project.json dependencies list. Also add 1 app . UseBrowserLink (); to the Configure method of Startup.cs . Run the project without debugging (Ctrl + F5) and you see this kind of code added to the HTML: 1 2 3 4 5 6 7 8 9 <!-- Visual Studio Browser Link --> < script type = \"application/json\" id = \"__browserLink_initializationData\" > { \"requestId\" : \"497a61f26544432a857e06ab5d501b7f\" , \"requestMappingFromServer\" : false } </ script > < script type = \"text/javascript\" src = \"http://localhost:2701/029471b4ee954e43adc0d452954d080f/browserLink\" async = \"async\" > </ script > <!-- End Browser Link --> Alas I still see no added value to it. :( Unless it is just the synchronized browsing using multiple browsers. I also see this error in the browser console: [14:07:17 GMT+0200 (West-Europa (zomertijd))] Browser Link: Failed to invoke return value callback: TypeError: Cannot read property 'files' of null","title":"Browser Link Loader"},{"location":"dotnet/notes/#static-files","text":"ASP.NET Core includes support for delivering static files from the wwwroot folder to clients but it isn\u2019t enabled by default when the Empty template is used to create the project. To enable static file support, add 1 \"Microsoft.AspNetCore.StaticFiles\" : \"1.0.0\" to project.json dependencies list. Also add 1 app . UseStaticFiles (); to the Configure method of Startup.cs .","title":"Static files"},{"location":"dotnet/notes/#bundling-and-minifying","text":"Install Bundler and Minifier extension for the Visual Studio. After that it is possible to add css or js files to the bundle by selecting them one by one and choosing Bundler & Minifier | Bundle and Minify Files (Shift + Alt + F) from the right mouse button menu. This will create a bundle.css or bundle.js file and also bundleconfig.json in the project root folder. Make sure the order of the files is what you need as loading order .","title":"Bundling and minifying"},{"location":"dotnet/notes/#unit-testing-with-xunit-framework","text":"","title":"Unit Testing with xUnit Framework"},{"location":"dotnet/notes/#preparation","text":"create test folder inside the solution folder next to src folder add new .NET Core | Class Library (.NET Core) project inside the test folder add this code to its project.json file (check the latest versions): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"version\" : \"1.0.0-*\" , \"testRunner\" : \"xunit\" , \"dependencies\" : { \"Microsoft.NETCore.App\" : { \"type\" : \"platform\" , \"version\" : \"1.0.1\" }, \"xunit\" : \"2.1.0\" , \"dotnet-test-xunit\" : \"2.2.0-preview2-build1029\" }, \"frameworks\" : { \"netcoreapp1.0\" : { \"imports\" : [ \"dotnet5.6\" , \"portable-net45+win8\" ] } } } this configuration tells Visual Studio that three packages are required: the Microsoft.NETCore.App package provides the .NET Core API . the xunit package provides the testing framework. the dotnet-test-xunit package provides the integration between xUnit and Visual Studio . add the main project reference to the dependencies, e.g. 1 2 3 4 5 6 7 { \"dependencies\" : { ... \"WorkingWithVisualStudio\" : \"1.0.0\" ... } }","title":"Preparation"},{"location":"dotnet/notes/#fact-and-theory","text":"In the xUnit framework, a Fact is one single unit test. Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [Fact] public void IndexActionModelIsComplete () { // Arrange var controller = new HomeController (); controller . Repository = new ModelCompleteFakeRepository (); // Act var model = ( controller . Index () as ViewResult )?. ViewData . Model as IEnumerable < Product >; // Assert Assert . Equal ( controller . Repository . Products , model , Comparer . Get < Product >(( p1 , p2 ) => p1 . Name == p2 . Name && p1 . Price == p2 . Price )); } A Theory is a way to parametrize the unit test in such a way that it becomes possible to run the same test multiple times, each time with a different set of parameter values. Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 [Theory] [InlineData(275, 48.95, 19.50, 24.95)] [InlineData(5, 48.95, 19.50, 24.95)] public void IndexActionModelIsComplete ( decimal price1 , decimal price2 , decimal price3 , decimal price4 ) { // Arrange var controller = new HomeController (); controller . Repository = new ModelCompleteFakeRepository { Products = new Product [] { new Product { Name = \"P1\" , Price = price1 }, new Product { Name = \"P2\" , Price = price2 }, new Product { Name = \"P3\" , Price = price3 }, new Product { Name = \"P4\" , Price = price4 }, } }; // Act var model = ( controller . Index () as ViewResult )?. ViewData . Model as IEnumerable < Product >; // Assert Assert . Equal ( controller . Repository . Products , model , Comparer . Get < Product >(( p1 , p2 ) => p1 . Name == p2 . Name && p1 . Price == p2 . Price )); }","title":"Fact and Theory"},{"location":"dotnet/notes/#getting-test-data-from-a-method-or-property","text":"We can create methods or properties giving us the enumerations for the test parameter values in a separate class, e.g. ProductTestData.cs . Then we can use MemberData attribute to specify it for the unit test to use. Example: 1 2 3 [Theory] [ClassData(typeof(ProductTestData))] public void IndexActionModelIsComplete ( Product [] products ) {...} If we want to include the test data in the same class as the unit tests, then you can use the MemberData attribute instead of ClassData . The MemberData attribute is configured using a string that specifies the name of a static method that will provide an IEnumerable<object[]> , where each object array in the sequence is a set of arguments for the test method. Example: 1 2 3 [Theory] [MemberData(\"GetData\")] public void IndexActionModelIsComplete ( Product [] products ) {...} and the GetData should look something like this 1 2 3 4 5 6 7 8 9 public static IEnumerable < object []> GetData { get { // ... yield return new object [] { 8 , 21 }; yield return new object [] { 16 , 987 }; } } Every yield statement should return an array of objects to substitute for the Product properties. And the method itself should be of type IEnumerable<object[]> .","title":"Getting Test Data from a Method or Property"},{"location":"dotnet/notes/#mocking-with-moq","text":"Microsoft created a special fork of the Moq project and ported it to work with .NET Core . In order to be able to install the Moq NuGet package , we need first to configure the NuGet Options . Open Tools | Options | NuGet Package Manager , click on Package Sources and then on the green plus sign. Configure the new package source as follows: Name: ASP.NET Contrib Source: https://www.myget.org/F/aspnet-contrib/api/v3/index.json Add these two packages to the package.json in the test project: 1 2 \"moq.netcore\" : \"4.4.0-beta8\" \"System.Diagnostics.TraceSource\" : \"4.0.0\" Usage example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [Fact] public void RepositoryPropertyCalledOnce () { // Arrange var mock = new Mock < IRepository >(); mock . SetupGet ( m => m . Products ) . Returns ( new [] { new Product { Name = \"P1\" , Price = 100 } }); var controller = new HomeController { Repository = mock . Object }; // Act var result = controller . Index (); // Assert mock . VerifyGet ( m => m . Products , Times . Once ); } Explanation: var mock = new Mock<IRepository>(); - define the interface to be mocked SetupGet(m => m.Products) - specify the property to be tested .Returns(...) - specify the test value to be returned Repository = mock.Object - Object is the special property that gives back the object we mock for this test mock.VerifyGet(m => m.Products, Times.Once); - one of the verify methods to inspect the getter property","title":"Mocking with MOQ"},{"location":"dotnet/notes/#sportsstore","text":"Create a new empty ASP.NET Core Web Application (.NET Core) project/solution. Add these packages/tools to the project.json file: 1 2 3 4 5 6 7 8 9 10 11 12 13 \"dependencies\" : { ... \"Microsoft.AspNetCore.Razor.Tools\" : { \"version\" : \"1.0.0-preview2-final\" , \"type\" : \"build\" }, \"Microsoft.AspNetCore.StaticFiles\" : \"1.0.0\" , \"Microsoft.AspNetCore.Mvc\" : \"1.0.1\" } , \"tools\" : { \"Microsoft.AspNetCore.Razor.Tools\" : \"1.0.0-preview2-final\" , ... } , In addition to the packages in the dependencies section, there is an addition to the tools section of the project.json file that configures the Microsoft.AspNetCore.Razor.Tools package for use in Visual Studio and enables IntelliSense for the built-in tag helpers, which are used to create HTML content that is tailored to the configuration of the MVC application. Here is the Startup.cs : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 using Microsoft.AspNetCore.Builder ; using Microsoft.AspNetCore.Hosting ; using Microsoft.AspNetCore.Http ; using Microsoft.Extensions.DependencyInjection ; using Microsoft.Extensions.Logging ; namespace SportsStore { public class Startup { public void ConfigureServices ( IServiceCollection services ) { services . AddMvc (); } public void Configure ( IApplicationBuilder app , IHostingEnvironment env , ILoggerFactory loggerFactory ) { app . UseDeveloperExceptionPage (); app . UseStatusCodePages (); app . UseStaticFiles (); app . UseMvcWithDefaultRoute (); } } } The ConfigureServices method is used to set up shared objects that can be used throughout the application through the dependency injection feature. The AddMvc method that is called in the ConfigureServices method is an extension method that sets up the shared objects used in MVC applications. The Configure method is used to set up the features that receive and process HTTP requests . add these folders: Models , Controllers , Views in the Views folder add _ViewImports.cshtml file: 1 2 @using SportsStore . Models @addTagHelper *, Microsoft . AspNetCore . Mvc . TagHelpers create the unit test project SportsStore.Tests in the test folder. Configure its project .json as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"version\" : \"1.0.0-*\" , \"testRunner\" : \"xunit\" , \"dependencies\" : { \"Microsoft.NETCore.App\" : { \"type\" : \"platform\" , \"version\" : \"1.0.1\" }, \"xunit\" : \"2.1.0\" , \"dotnet-test-xunit\" : \"2.2.0-preview2-build1029\" , \"moq.netcore\" : \"4.4.0-beta8\" , \"System.Diagnostics.TraceSource\" : \"4.0.0\" , \"SportsStore\" : \"1.0.0\" }, \"frameworks\" : { \"netcoreapp1.0\" : { \"imports\" : [ \"dotnet5.6\" , \"portable-net45+win8\" ] } } } Make sure that both project.json files refer to the same ASP.NET Core MVC version. Add your model class Product.cs , repository interface IProductRepository and a simple fake repository FakeProductRepository Register the fake repository as a service in Startup.cs : 1 2 3 4 5 public void ConfigureServices ( IServiceCollection services ) { services . AddTransient < IProductRepository , FakeProductRepository >(); ... } Add the following standard views: Views/Shared/_Layout.cshtml Views/_ViewStart.cshtml refering to _Layout.cshtml by default Example of setting up the default route in Startup.cs . Substitute 1 app . UseMvcWithDefaultRoute (); with 1 2 3 4 5 6 app . UseMvc ( routes => { routes . MapRoute ( name : \"default\" , template : \"{controller=Product}/{action=List}/{id?}\" ); });","title":"SportsStore"},{"location":"dotnet/notes/#scaffolding","text":"Some people prefer to have certain features automatically created when they create new controller or views. That is called scaffolding . If you want that, add the following packages to the project.json file: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 ... \"dependencies\" : { ... \"Microsoft.AspNetCore.StaticFiles\" : \"1.0.0\" , \"Microsoft.AspNetCore.Mvc\" : \"1.0.0\" , \"Microsoft.VisualStudio.Web.CodeGeneration.Tools\" : { \"version\" : \"1.0.0-preview2-final\" , \"type\" : \"build\" }, \"Microsoft.VisualStudio.Web.CodeGenerators.Mvc\" : { \"version\" : \"1.0.0-preview2-final\" , \"type\" : \"build\" } } ... \"tools\" : { ... \"Microsoft.VisualStudio.Web.CodeGeneration.Tools\" : { \"version\" : \"1.0.0-preview2-final\" , \"imports\" : [ \"portable-net45+win8+dnxcore50\" , \"portable-net45+win8\" ] } } ...","title":"Scaffolding"},{"location":"dotnet/notes/#setup-the-database","text":"add EntityFramework packages to package.json : 1 2 3 4 5 \"dependencies\" : { ... \"Microsoft.EntityFrameworkCore.SqlServer\" : \"1.0.1\" , \"Microsoft.EntityFrameworkCore.Tools\" : \"1.0.0-preview2-final\" } and the tools: 1 2 3 4 5 6 7 \"tools\" : { ... \"Microsoft.EntityFrameworkCore.Tools\" : { \"version\" : \"1.0.0-preview2-final\" , \"imports\" : [ \"portable-net45+win8+dnxcore50\" , \"portable-net45+win8\" ] } } The database context class is the bridge between the application and the EF Core and provides access to the application\u2019s data using model objects. To create the database context class for the SportsStore application, we add a class file called ApplicationDbContext.cs to the Models folder: 1 2 3 4 5 6 7 8 9 10 11 using Microsoft.EntityFrameworkCore ; namespace SportsStore.Models { public class ApplicationDbContext : DbContext { public ApplicationDbContext ( DbContextOptions < ApplicationDbContext > options ) : base ( options ) { } public DbSet < Product > Products { get ; set ; } } } To populate the database initially with some data, we use SeedData.cs class: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 using System.Linq ; using Microsoft.AspNetCore.Builder ; using Microsoft.Extensions.DependencyInjection ; namespace SportsStore.Models { public static class SeedData { public static void EnsurePopulated ( IApplicationBuilder app ) { ApplicationDbContext context = app . ApplicationServices . GetRequiredService < ApplicationDbContext >(); if (! context . Products . Any ()) { context . Products . AddRange ( new Product { Name = \"Kayak\" , Description = \"A boat for one person\" , Category = \"Watersports\" , Price = 275 }, ... context . SaveChanges (); } } } } The static EnsurePopulated method receives an IApplicationBuilder argument, which is the class used in the Configure method of the Startup class to register middleware classes to handle HTTP requests, which is where we ensure that the database has content. The EnsurePopulated method obtains an ApplicationDbContext object through the IApplicationBuilder interface and uses it to check whether there are any Product objects in the database. If there are no objects, then the database is populated using a collection of Product objects using the AddRange method and then written to the database using the SaveChanges method. The next step is to create a class that implements the IProductRepository interface and gets its data using Entity Framework Core from the ApplicationDbContext . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 using System.Collections.Generic ; namespace SportsStore.Models { public class EFProductRepository : IProductRepository { private ApplicationDbContext context ; public EFProductRepository ( ApplicationDbContext ctx ) { context = ctx ; } public IEnumerable < Product > Products => context . Products ; } } create appsettings.json file in the project root folder based on the ASP.NET Configuration File template and configure the connection string: 1 2 3 4 5 6 7 { \"Data\" : { \"SportStoreProducts\" : { \"ConnectionString\" : \"Server=(localdb)\\\\MSSQLLocalDB;Database=SportsStore;Trusted_Connection=True;MultipleActiveResultSets=true\" } } } add a new dependency to read the json configuration file: 1 2 3 4 \"dependencies\" : { ... \"Microsoft.Extensions.Configuration.Json\" : \"1.0.0\" } , configure the Startup.cs : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 ... using Microsoft.EntityFrameworkCore ; using Microsoft.Extensions.Configuration ; namespace SportsStore { public class Startup { IConfigurationRoot Configuration ; public Startup ( IHostingEnvironment env ) { Configuration = new ConfigurationBuilder () . SetBasePath ( env . ContentRootPath ) . AddJsonFile ( \"appsettings.json\" ). Build (); } public void ConfigureServices ( IServiceCollection services ) { services . AddDbContext < ApplicationDbContext >( options => options . UseSqlServer ( Configuration [ \"Data:SportStoreProducts:ConnectionString\" ])); services . AddTransient < IProductRepository , EFProductRepository >(); ... } public void Configure ( IApplicationBuilder app , IHostingEnvironment env , ILoggerFactory loggerFactory ) { ... SeedData . EnsurePopulated ( app ); } } } open Tools | Nuget Package Manager | Package Manager Console to create and apply database migrations: 1 2 Add-Migration Initial Update-Database rebuild the solution and run - we will see the list of products loaded from the database.","title":"Setup the database"},{"location":"dotnet/notes/#viewmodels-and-taghelpers","text":"If we want to customize the information to be used in the view, we can do that with ViewModels . For that we create a ViewModels subfolder inside the Models folder. They can be registered in _ViewImports.cshtml . TagHelpers are one of the most useful ways that you can introduce C# logic into your views. The code for a tag helper can look tortured because C# and HTML don\u2019t mix easily. But using tag helpers is preferable to including blocks of C# code in a view because a tag helper can be easily unit tested . Most MVC components, such as controllers and views, are discovered automatically, but tag helpers have to be registered in _ViewImports.cshtml . To test the tag helper class, I call the Process method with test data and provide a TagHelperOutput object that is inspected to see the HTML that was generated. When we pass the data to the view via a view model, we need to replace the type. E.g. it can become @model ProductsListViewModel and Model.Products instead of @model IEnumerable<Product> and Model .","title":"ViewModels and TagHelpers"},{"location":"dotnet/notes/#installing-bootstrap-package","text":"Add bower.json file to the project root: 1 2 3 4 5 6 7 { \"name\" : \"asp.net\" , \"private\" : true , \"dependencies\" : { \"bootstrap\" : \"3.3.7\" } } This will add wwwroot/lib folder and inside it bootstrap and jquery sources.","title":"Installing Bootstrap package"},{"location":"dotnet/notes/#improving-the-urls","text":"Normally, the page links look like this: http://localhost/?page=2 But we can make them more user friendly by creating a scheme that follows the pattern of composable URLs , which look like this: http://localhost/Page2 To do that we register a new route in our MVC middleware ( Configure method in Startup.cs ): 1 2 3 4 routes . MapRoute ( name : \"pagination\" , template : \"Products/Page{page}\" , defaults : new { Controller = \"Product\" , action = \"List\" }); It is important that this route is added before the default route.","title":"Improving the URLs"},{"location":"dotnet/notes/#enabling-sessions","text":"Add these new packages to the package.json : 1 2 3 \"Microsoft.AspNetCore.Session\" : \"1.0.0\" , \"Microsoft.Extensions.Caching.Memory\" : \"1.0.0\" , \"Microsoft.AspNetCore.Http.Extensions\" : \"1.0.0\" Register new services and middleware to the Startup.cs : 1 2 3 4 5 6 7 8 9 10 11 12 public void ConfigureServices ( IServiceCollection services ) { ... services . AddMemoryCache (); services . AddSession (); services . AddMvc (); } public void Configure ( IApplicationBuilder app , ... app . UseSession (); app . UseMvc (...); } AddMemoryCache The AddMemoryCache method call sets up the in-memory data store. The AddSession method registers the services used to access session data, and the UseSession method allows the session system to automatically associate requests with sessions when they arrive from the client.","title":"Enabling Sessions"},{"location":"dotnet/notes/#annotations","text":"BindNever attribute prevents the user supplying values for these properties in an HTTP request.","title":"Annotations"},{"location":"dotnet/notes/#adding-migrations","text":"Suppose we add a new DbSet to our ApplicationDbContext.cs : 1 2 3 4 5 6 7 public class ApplicationDbContext : DbContext { public ApplicationDbContext ( DbContextOptions < ApplicationDbContext > options ) : base ( options ) { } ... public DbSet < Order > Orders { get ; set ; } } To create the migration , open the NuGet Package Manger Console from the Tools \u27a4 NuGet Package Manage menu and run the following command : Add-Migration Orders This command tells EF Core to take a new snapshot of the application, work out how it differs from the previous database version, and generate a new migration called Orders . The name Orders here is arbitrary but it is handy to let it reflect the change. To update the database schema, run the following command: Update-Database","title":"Adding migrations"},{"location":"dotnet/notes/#resetting-the-database","text":"When you are making frequent changes to the model, there will come a point when your migrations and your database schema get out of sync. The easiest thing to do is delete the database and start over. However, this applies only during development , of course, because you will lose any data you have stored. Select the SQL Server Object Explorer item from the Visual Studio View menu and click the Add Sql Server button. Enter (localdb)\\mssqllocaldb into the Server Name field and click the Connect button. A new item will appear in the SQL Server Object Explorer window, which you can expand to see the LocalDB databases that have been created. Right-click the database you want to remove and select Delete from the pop-up menu. Check the option to close the existing connections and then click the OK button to delete the database. Once the database has been removed, run the following command from the Package Manager Console to create the database and apply the migrations you have created by running the following command: Update-Database This will reset the database so that it accurately reflects your model and allow you to return to developing your application.","title":"Resetting the Database"},{"location":"dotnet/notes/#using-tempdata","text":"We are using TempData in the POST method in a controller: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [HttpPost] public IActionResult Edit ( Product product ) { if ( ModelState . IsValid ) { _repository . SaveProduct ( product ); TempData [ \"message\" ] = $ \"{product.Name} has been saved\" ; return RedirectToAction ( \"Index\" ); } else { // there is something wrong with the data values return View ( product ); } } We check that the model binding process has been able to validate the data submitted to the user by reading the value of the ModelState.IsValid property. If everything is OK, we save the changes to the repository and redirect the user to the Index action so they see the modified list of products. If there is a problem with the data, we render the default view again so that the user can make corrections. After we have saved the changes in the repository, we store a message using the TempData feature, which is part of the ASP.NET Core session state feature. This is a key/value dictionary similar to the session data and view bag features we used previously. The key difference from session data is that temp data persists until it is read. We cannot use ViewBag in this situation because ViewBag passes data between the controller and view , and it cannot hold data for longer than the current HTTP request . When an edit succeeds, the browser is redirected to a new URL, so the ViewBag data is lost. We could use the session data feature, but then the message would be persistent until we explicitly removed it, which we would rather not have to do. So, the temp data feature is the perfect fit. The data is restricted to a single user\u2019s session (so that users do not see each other\u2019s TempData ) and will persist long enough for us to read it. We will read the data in the view rendered by the action method to which we redirect the user The message will be displayed once and disappear if you reload the screen with the template using this temp data , because TempData is deleted when it is read. That is convenient since we do not want old messages hanging around.","title":"Using TempData"},{"location":"dotnet/notes/#localization-hell","text":"By the time we get to editing with validation, something bad happens. It looks that by default the jQuery-validation (client side validation) expects \"en-US\" as its culture and the server side validation expects \"nl-NL\" . Therefore, when I see \u20ac as currency and \",\" as decimal separator, I cannot change the price. Neither \",\" nor \".\" are accepted. One is rejected by the client side and the other by the server side validation. Temporary workaround was to configure \"en-US\" as the default culture, so that \"$\" and \".\" are displayed on the screen. Then the validation works.","title":"Localization hell"},{"location":"dotnet/notes/#adding-identity","text":"Add a new dependency to project.json : 1 2 3 4 \"dependencies\" : { ... \"Microsoft.AspNetCore.Identity.EntityFrameworkCore\" : \"1.0.0\" } Add a new AppIdentityDbContext class to Models folder: 1 2 3 4 5 6 7 8 9 10 11 using Microsoft.AspNetCore.Identity.EntityFrameworkCore ; using Microsoft.EntityFrameworkCore ; namespace SportsStore.Models { public class AppIdentityDbContext : IdentityDbContext < IdentityUser > { public AppIdentityDbContext ( DbContextOptions < AppIdentityDbContext > options ) : base ( options ) { } } } and a new connection string in appsettings.json file: 1 2 3 4 5 6 7 8 { \"Data\" : { ... \"SportStoreIdentity\" : { \"ConnectionString\" : \"Server=(localdb)\\\\MSSQLLocalDB;Database=Identity;Trusted_Connection=True;MultipleActiveResultSets=true\" } } } Add new services to ConfigureServices in Startup.cs : 1 2 3 4 5 6 7 8 9 10 public void ConfigureServices ( IServiceCollection services ) { ... services . AddDbContext < AppIdentityDbContext >( options => options . UseSqlServer ( Configuration [ \"Data:SportStoreIdentity:ConnectionString\" ])); services . AddIdentity < IdentityUser , IdentityRole >() . AddEntityFrameworkStores < AppIdentityDbContext >(); ... } and new entries in Configure : 1 2 3 4 5 6 public void Configure () app . UseIdentity (); app . UseMvc (); SeedData . EnsurePopulated ( app ); IdentitySeedData . EnsurePopulated ( app ); } IdentitySeedData should be created in the Models folder to create an administrative account. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 using Microsoft.AspNetCore.Builder ; using Microsoft.AspNetCore.Identity ; using Microsoft.AspNetCore.Identity.EntityFrameworkCore ; using Microsoft.Extensions.DependencyInjection ; namespace SportsStore.Models { public static class IdentitySeedData { private const string adminUser = \"Admin\" ; private const string adminPassword = \"Secret123$\" ; public static async void EnsurePopulated ( IApplicationBuilder app ) { UserManager < IdentityUser > userManager = app . ApplicationServices . GetRequiredService < UserManager < IdentityUser >>(); IdentityUser user = await userManager . FindByIdAsync ( adminUser ); if ( user == null ) { user = new IdentityUser ( \"Admin\" ); await userManager . CreateAsync ( user , adminPassword ); } } } }","title":"Adding Identity"},{"location":"dotnet/notes/#adding-identity-migrations","text":"Add-Migration Initial -Context AppIdentityDbContext Update-Database -Context AppIdentityDbContext This will create the new database and add the AspNetUsers and AspNetRoles in it.","title":"Adding Identity migrations"},{"location":"dotnet/notes/#adding-authorization","text":"When ASP.NET Core Identity is in place, we can apply Authorization . We don\u2019t want to stop unauthenticated users from accessing the other action methods in the Order controller, so we have applied the Authorize attribute only to the List and MarkShipped methods. 1 2 3 4 5 6 7 [Authorize] public ViewResult List () => View ( _repository . Orders . Where ( o => ! o . Shipped )); [HttpPost] [Authorize] public IActionResult MarkShipped ( int orderID ) {...} We want to protect all of the action methods defined by the Admin controller, and we can do this by applying the Authorize attribute to the controller class, which then applies the authorization policy to all the action methods it contains. 1 2 3 [Authorize] public class AdminController : Controller {...} Caution In general, using client-side data validation is a good idea. It offloads some of the work from your server and gives users immediate feedback about the data they are providing. However, you should not be tempted to perform authentication at the client, as this would typically involve sending valid credentials to the client so they can be used to check the username and password that the user has entered, or at least trusting the client\u2019s report of whether they have successfully authenticated. Authentication should always be done at the server.","title":"Adding Authorization"},{"location":"dotnet/notes/#sources-used","text":"Adam Freeman - Pro ASP.NET Core MVC (2016) Christian Nagel - Professional C# 6 and .NET Core 1.0 (2016)","title":"Sources used"},{"location":"dotnet/tips/","text":".NET Core Tips \u00b6 dotnet command prompt \u00b6 Run the web application on a specified port, e.g. 10000, via 1 dotnet run --server.urls http://127.0.0.1:10000 Dotnet NuGet Packages \u00b6 Using command dotnet pack we can actually create a NuGet package from our project. This command will create two files in bin/debug/[runtime] directory: DNXConsoleDemo.1.0.0.nupkg DNXConsoleDemo.1.0.0.symbols.nupkg Actually, the .nupkg files are just .zip files. If you rename the extension, you can see what is inside the package. Application as a NuGet package It should now be possible to install your project as a NuGet package. Some Definitions \u00b6 ASP.NET Services = objects that provide functionality to other parts of the application. Services registered in the Startup.ConfigureServices method can be accessed by creating a constructor that accepts an argument of the required service type. ConfigureServices method hooks into the service registry all of the services we want our application to make use of. It is configuring the types of services that can be used in the infrastructur altogether. Configure methods configures the behavior of the registered services. Middleware = components that are combined to form the request pipeline . AddTransient = every time we call for the service to be used, we would get a new instance of the service from the DI Framework . AddScoped = same instance of the service is used in all stages of the middleware pipeline for the same request. AddSingleton = one instance of the service is created for the entire lifetime of the application across all user requests. AddInstance = similar to AddSingleton but we need to new up the instance of this service explicitly. Some Facts \u00b6 JSON schema of the project.json file: json.schemastore.org/project It is possible to use more that one Startup class, e.g. Startup , StartupFoo , StartupBar , and to specify the one we need to be activated in the Program.cs : 1 2 3 4 5 6 7 public static void Main ( string [] args ) { var host = new WebHostBuilder () ... . UseStartup < Startup >() ... }","title":"Tips"},{"location":"dotnet/tips/#net-core-tips","text":"","title":".NET Core Tips"},{"location":"dotnet/tips/#dotnet-command-prompt","text":"Run the web application on a specified port, e.g. 10000, via 1 dotnet run --server.urls http://127.0.0.1:10000","title":"dotnet command prompt"},{"location":"dotnet/tips/#dotnet-nuget-packages","text":"Using command dotnet pack we can actually create a NuGet package from our project. This command will create two files in bin/debug/[runtime] directory: DNXConsoleDemo.1.0.0.nupkg DNXConsoleDemo.1.0.0.symbols.nupkg Actually, the .nupkg files are just .zip files. If you rename the extension, you can see what is inside the package. Application as a NuGet package It should now be possible to install your project as a NuGet package.","title":"Dotnet NuGet Packages"},{"location":"dotnet/tips/#some-definitions","text":"ASP.NET Services = objects that provide functionality to other parts of the application. Services registered in the Startup.ConfigureServices method can be accessed by creating a constructor that accepts an argument of the required service type. ConfigureServices method hooks into the service registry all of the services we want our application to make use of. It is configuring the types of services that can be used in the infrastructur altogether. Configure methods configures the behavior of the registered services. Middleware = components that are combined to form the request pipeline . AddTransient = every time we call for the service to be used, we would get a new instance of the service from the DI Framework . AddScoped = same instance of the service is used in all stages of the middleware pipeline for the same request. AddSingleton = one instance of the service is created for the entire lifetime of the application across all user requests. AddInstance = similar to AddSingleton but we need to new up the instance of this service explicitly.","title":"Some Definitions"},{"location":"dotnet/tips/#some-facts","text":"JSON schema of the project.json file: json.schemastore.org/project It is possible to use more that one Startup class, e.g. Startup , StartupFoo , StartupBar , and to specify the one we need to be activated in the Program.cs : 1 2 3 4 5 6 7 public static void Main ( string [] args ) { var host = new WebHostBuilder () ... . UseStartup < Startup >() ... }","title":"Some Facts"},{"location":"engine/cheatsheet/","text":"Markdown Cheatsheet \u00b6 Hereunder are some of the most common examples to illustrate the Markdown syntax. Table of Contents \u00b6 Headers Emphasis Lists Links Images Code and Syntax Highlighting Tables Blockquotes Inline HTML Horizontal Rule Line Breaks Youtube videos This is intended as a quick reference and showcase. Here is also the same information as a pdf document : Markdown Cheatsheet . Headers \u00b6 The following syntax in your Markdown text: 1 2 3 4 5 6 # H1 ## H2 ### H3 #### H4 ##### H5 ###### H6 produce this: H1 \u00b6 H2 \u00b6 H3 \u00b6 H4 \u00b6 H5 \u00b6 H6 \u00b6 Alternatively, for H1 and H2, an underline-ish style: 1 2 3 4 5 Alt-H1 ====== Alt-H2 ------ produces this: Alt-H1 \u00b6 Alt-H2 \u00b6 Emphasis \u00b6 1 2 3 4 5 6 7 Emphasis, aka italics, with *asterisks- or _underscores_. Strong emphasis, aka bold, with **asterisks*- or __underscores__. Combined emphasis with **asterisks and _underscores_**. Strikethrough uses two tildes. ~~Scratch this.~~ Emphasis, aka italics, with *asterisks- or underscores . Strong emphasis, aka bold, with **asterisks*- or underscores . Combined emphasis with asterisks and underscores . Strikethrough uses two tildes. Scratch this. Lists \u00b6 (In this example, leading and trailing spaces are shown with with dots: \u22c5) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 1. First ordered list item 2. Another item \u22c5\u22c5- Unordered sub-list. 1. Actual numbers don't matter, just that it's a number \u22c5\u22c51. Ordered sub-list 4. And another item. \u22c5\u22c5\u22c5You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we'll use three here to also align the raw Markdown). \u22c5\u22c5\u22c5To have a line break without a paragraph, you will need to use two trailing spaces.\u22c5\u22c5 \u22c5\u22c5\u22c5Note that this line is separate, but within the same paragraph.\u22c5\u22c5 \u22c5\u22c5\u22c5(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.) - Unordered list can use asterisks - Or minuses + Or pluses First ordered list item Another item Unordered sub-list. Actual numbers don\u2019t matter, just that it\u2019s a number Ordered sub-list And another item. You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we\u2019ll use three here to also align the raw Markdown). To have a line break without a paragraph, you will need to use two trailing spaces. Note that this line is separate, but within the same paragraph. (This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.) Unordered list can use asterisks Or minuses Or pluses Links \u00b6 There are two ways to create links. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [I'm an inline-style link](https://www.google.com) [I'm an inline-style link with title](https://www.google.com \"Google's Homepage\") [I'm a reference-style link][Arbitrary case-insensitive reference text] [I'm a relative reference to a repository file](../blob/master/LICENSE) [You can use numbers for reference-style link definitions][1] Or leave it empty and use the [link text itself]. URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or <http://www.example.com> and sometimes example.com (but not on Github, for example). Some text to show that the reference links can follow later. [arbitrary case-insensitive reference text]: https://www.mozilla.org [1]: http://slashdot.org [link text itself]: http://www.reddit.com I\u2019m an inline-style link I\u2019m an inline-style link with title I\u2019m a reference-style link I\u2019m a relative reference to a repository file You can use numbers for reference-style link definitions Or leave it empty and use the link text itself . URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or http://www.example.com and sometimes example.com (but not on Github, for example). Some text to show that the reference links can follow later. Images \u00b6 1 2 3 4 5 6 7 8 9 Here's our logo (hover to see the title text): Inline-style: ![alt text](https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png \"Logo Title Text 1\") Reference-style: ![alt text][logo] [logo]: https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png \"Logo Title Text 2\" Here\u2019s our logo (hover to see the title text): Inline-style: Reference-style: Code and Syntax Highlighting \u00b6 Code blocks are part of the Markdown spec, but syntax highlighting isn\u2019t. However, many renderers \u2013 like Github\u2019s and *Markdown Here- \u2013 support syntax highlighting. Which languages are supported and how those language names should be written will vary from renderer to renderer. *Markdown Here- supports highlighting for dozens of languages (and not-really-languages, like diffs and HTTP headers); to see the complete list, and how to write the language names, see the highlight.js demo page . 1 Inline `code` has `back-ticks around` it. Inline code has back-ticks around it. Blocks of code are either fenced by lines with three back-ticks ``` , or are indented with four spaces. I recommend only using the fenced code blocks \u2013 they\u2019re easier and only they support syntax highlighting. TODO: The following block has to be fixed. \u0002wzxhzdk:7\u0003 \u0002wzxhzdk:8\u0003 \u0002wzxhzdk:9\u0003 1 2 var s = \"JavaScript syntax highlighting\" ; alert ( s ); 1 2 s = \"Python syntax highlighting\" print s 1 2 No language indicated, so no syntax highlighting in Markdown Here (varies on Github). But let's throw in a <b>tag</b>. Tables \u00b6 Tables aren\u2019t part of the core Markdown spec, but they are part of GFM and *Markdown Here- supports them. They are an easy way of adding tables to your email \u2013 a task that would otherwise require copy-pasting from another application. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Colons can be used to align columns. | Tables | Are | Cool | | ------------- |:-------------:| -----:| | col 3 is | right-aligned | $1600 | | col 2 is | centered | $12 | | zebra stripes | are neat | $1 | There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily. You can also use inline Markdown. Markdown | Less | Pretty --- | --- | --- *Still- | `renders` | **nicely** 1 | 2 | 3 Colons can be used to align columns. Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don\u2019t need to make the raw Markdown line up prettily. You can also use inline Markdown. Markdown Less Pretty *Still- renders nicely 1 2 3 Blockquotes \u00b6 1 2 3 4 5 6 > Blockquotes are very handy in email to emulate reply text. > This line is part of the same quote. Quote break. > This is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can *put- **Markdown*- into a blockquote. Blockquotes are very handy in email to emulate reply text. This line is part of the same quote. Quote break. This is a very long line that will still be quoted properly when it wraps. Oh boy let\u2019s keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can put- **Markdown - into a blockquote. Inline HTML \u00b6 You can also use raw HTML in your Markdown, and it\u2019ll mostly work pretty well. 1 2 3 4 5 6 7 <dl> <dt>Definition list</dt> <dd>Is something people use sometimes.</dd> <dt>Markdown in HTML</dt> <dd>Does *not- work **very*- well. Use HTML <em>tags</em>.</dd> </dl> Definition list Is something people use sometimes. Markdown in HTML Does *not- work **very*- well. Use HTML tags . Horizontal Rule \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 Three or more... --- Hyphens *** Asterisks ___ Underscores Three or more\u2026 Hyphens Asterisks Underscores Line Breaks \u00b6 My basic recommendation for learning how line breaks work is to experiment and discover \u2013 hit <Enter> once (i.e., insert one newline), then hit it twice (i.e., insert two newlines), see what happens. You\u2019ll soon learn to get what you want. \u201cMarkdown Toggle\u201d is your friend. Here are some things to try out: 1 2 3 4 5 6 Here's a line for us to start with. This line is separated from the one above by two newlines, so it will be a *separate paragraph*. This line is also a separate paragraph, but... This line is only separated by a single newline, so it's a separate line in the *same paragraph*. Here\u2019s a line for us to start with. This line is separated from the one above by two newlines, so it will be a separate paragraph . This line is also begins a separate paragraph, but\u2026 This line is only separated by a single newline, so it\u2019s a separate line in the same paragraph . (Technical note: *Markdown Here- uses GFM line breaks, so there\u2019s no need to use MD\u2019s two-space line breaks.) Youtube videos \u00b6 They can\u2019t be added directly but you can add an image with a link to the video like this: 1 2 3 < a href = \"http://www.youtube.com/watch?feature=player_embedded&v=YOUTUBE_VIDEO_ID_HERE \" target = \"_blank\" >< img src = \"http://images.youtube.com/vi/YOUTUBE_VIDEO_ID_HERE/0.jpg\" alt = \"IMAGE ALT TEXT HERE\" width = \"240\" height = \"180\" border = \"10\" /></ a > Or, in pure Markdown, but losing the image sizing and border: 1 [![IMAGE ALT TEXT HERE](http://images.youtube.com/vi/YOUTUBE_VIDEO_ID_HERE/0.jpg)](http://www.youtube.com/watch?v=YOUTUBE_VIDEO_ID_HERE) References \u00b6 Markdown Emoji Codes Extentions PyMdown CodeHilite","title":"Markdown Cheatsheet"},{"location":"engine/cheatsheet/#markdown-cheatsheet","text":"Hereunder are some of the most common examples to illustrate the Markdown syntax.","title":"Markdown Cheatsheet"},{"location":"engine/cheatsheet/#table-of-contents","text":"Headers Emphasis Lists Links Images Code and Syntax Highlighting Tables Blockquotes Inline HTML Horizontal Rule Line Breaks Youtube videos This is intended as a quick reference and showcase. Here is also the same information as a pdf document : Markdown Cheatsheet .","title":"Table of Contents"},{"location":"engine/cheatsheet/#headers","text":"The following syntax in your Markdown text: 1 2 3 4 5 6 # H1 ## H2 ### H3 #### H4 ##### H5 ###### H6 produce this:","title":"Headers"},{"location":"engine/cheatsheet/#h1","text":"","title":"H1"},{"location":"engine/cheatsheet/#h2","text":"","title":"H2"},{"location":"engine/cheatsheet/#h3","text":"","title":"H3"},{"location":"engine/cheatsheet/#h4","text":"","title":"H4"},{"location":"engine/cheatsheet/#h5","text":"","title":"H5"},{"location":"engine/cheatsheet/#h6","text":"Alternatively, for H1 and H2, an underline-ish style: 1 2 3 4 5 Alt-H1 ====== Alt-H2 ------ produces this:","title":"H6"},{"location":"engine/cheatsheet/#alt-h1","text":"","title":"Alt-H1"},{"location":"engine/cheatsheet/#alt-h2","text":"","title":"Alt-H2"},{"location":"engine/cheatsheet/#emphasis","text":"1 2 3 4 5 6 7 Emphasis, aka italics, with *asterisks- or _underscores_. Strong emphasis, aka bold, with **asterisks*- or __underscores__. Combined emphasis with **asterisks and _underscores_**. Strikethrough uses two tildes. ~~Scratch this.~~ Emphasis, aka italics, with *asterisks- or underscores . Strong emphasis, aka bold, with **asterisks*- or underscores . Combined emphasis with asterisks and underscores . Strikethrough uses two tildes. Scratch this.","title":"Emphasis"},{"location":"engine/cheatsheet/#lists","text":"(In this example, leading and trailing spaces are shown with with dots: \u22c5) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 1. First ordered list item 2. Another item \u22c5\u22c5- Unordered sub-list. 1. Actual numbers don't matter, just that it's a number \u22c5\u22c51. Ordered sub-list 4. And another item. \u22c5\u22c5\u22c5You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we'll use three here to also align the raw Markdown). \u22c5\u22c5\u22c5To have a line break without a paragraph, you will need to use two trailing spaces.\u22c5\u22c5 \u22c5\u22c5\u22c5Note that this line is separate, but within the same paragraph.\u22c5\u22c5 \u22c5\u22c5\u22c5(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.) - Unordered list can use asterisks - Or minuses + Or pluses First ordered list item Another item Unordered sub-list. Actual numbers don\u2019t matter, just that it\u2019s a number Ordered sub-list And another item. You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we\u2019ll use three here to also align the raw Markdown). To have a line break without a paragraph, you will need to use two trailing spaces. Note that this line is separate, but within the same paragraph. (This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.) Unordered list can use asterisks Or minuses Or pluses","title":"Lists"},{"location":"engine/cheatsheet/#links","text":"There are two ways to create links. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [I'm an inline-style link](https://www.google.com) [I'm an inline-style link with title](https://www.google.com \"Google's Homepage\") [I'm a reference-style link][Arbitrary case-insensitive reference text] [I'm a relative reference to a repository file](../blob/master/LICENSE) [You can use numbers for reference-style link definitions][1] Or leave it empty and use the [link text itself]. URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or <http://www.example.com> and sometimes example.com (but not on Github, for example). Some text to show that the reference links can follow later. [arbitrary case-insensitive reference text]: https://www.mozilla.org [1]: http://slashdot.org [link text itself]: http://www.reddit.com I\u2019m an inline-style link I\u2019m an inline-style link with title I\u2019m a reference-style link I\u2019m a relative reference to a repository file You can use numbers for reference-style link definitions Or leave it empty and use the link text itself . URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or http://www.example.com and sometimes example.com (but not on Github, for example). Some text to show that the reference links can follow later.","title":"Links"},{"location":"engine/cheatsheet/#images","text":"1 2 3 4 5 6 7 8 9 Here's our logo (hover to see the title text): Inline-style: ![alt text](https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png \"Logo Title Text 1\") Reference-style: ![alt text][logo] [logo]: https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png \"Logo Title Text 2\" Here\u2019s our logo (hover to see the title text): Inline-style: Reference-style:","title":"Images"},{"location":"engine/cheatsheet/#code-and-syntax-highlighting","text":"Code blocks are part of the Markdown spec, but syntax highlighting isn\u2019t. However, many renderers \u2013 like Github\u2019s and *Markdown Here- \u2013 support syntax highlighting. Which languages are supported and how those language names should be written will vary from renderer to renderer. *Markdown Here- supports highlighting for dozens of languages (and not-really-languages, like diffs and HTTP headers); to see the complete list, and how to write the language names, see the highlight.js demo page . 1 Inline `code` has `back-ticks around` it. Inline code has back-ticks around it. Blocks of code are either fenced by lines with three back-ticks ``` , or are indented with four spaces. I recommend only using the fenced code blocks \u2013 they\u2019re easier and only they support syntax highlighting. TODO: The following block has to be fixed. \u0002wzxhzdk:7\u0003 \u0002wzxhzdk:8\u0003 \u0002wzxhzdk:9\u0003 1 2 var s = \"JavaScript syntax highlighting\" ; alert ( s ); 1 2 s = \"Python syntax highlighting\" print s 1 2 No language indicated, so no syntax highlighting in Markdown Here (varies on Github). But let's throw in a <b>tag</b>.","title":"Code and Syntax Highlighting"},{"location":"engine/cheatsheet/#tables","text":"Tables aren\u2019t part of the core Markdown spec, but they are part of GFM and *Markdown Here- supports them. They are an easy way of adding tables to your email \u2013 a task that would otherwise require copy-pasting from another application. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Colons can be used to align columns. | Tables | Are | Cool | | ------------- |:-------------:| -----:| | col 3 is | right-aligned | $1600 | | col 2 is | centered | $12 | | zebra stripes | are neat | $1 | There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily. You can also use inline Markdown. Markdown | Less | Pretty --- | --- | --- *Still- | `renders` | **nicely** 1 | 2 | 3 Colons can be used to align columns. Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don\u2019t need to make the raw Markdown line up prettily. You can also use inline Markdown. Markdown Less Pretty *Still- renders nicely 1 2 3","title":"Tables"},{"location":"engine/cheatsheet/#blockquotes","text":"1 2 3 4 5 6 > Blockquotes are very handy in email to emulate reply text. > This line is part of the same quote. Quote break. > This is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can *put- **Markdown*- into a blockquote. Blockquotes are very handy in email to emulate reply text. This line is part of the same quote. Quote break. This is a very long line that will still be quoted properly when it wraps. Oh boy let\u2019s keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can put- **Markdown - into a blockquote.","title":"Blockquotes"},{"location":"engine/cheatsheet/#inline-html","text":"You can also use raw HTML in your Markdown, and it\u2019ll mostly work pretty well. 1 2 3 4 5 6 7 <dl> <dt>Definition list</dt> <dd>Is something people use sometimes.</dd> <dt>Markdown in HTML</dt> <dd>Does *not- work **very*- well. Use HTML <em>tags</em>.</dd> </dl> Definition list Is something people use sometimes. Markdown in HTML Does *not- work **very*- well. Use HTML tags .","title":"Inline HTML"},{"location":"engine/cheatsheet/#horizontal-rule","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 Three or more... --- Hyphens *** Asterisks ___ Underscores Three or more\u2026 Hyphens Asterisks Underscores","title":"Horizontal Rule"},{"location":"engine/cheatsheet/#line-breaks","text":"My basic recommendation for learning how line breaks work is to experiment and discover \u2013 hit <Enter> once (i.e., insert one newline), then hit it twice (i.e., insert two newlines), see what happens. You\u2019ll soon learn to get what you want. \u201cMarkdown Toggle\u201d is your friend. Here are some things to try out: 1 2 3 4 5 6 Here's a line for us to start with. This line is separated from the one above by two newlines, so it will be a *separate paragraph*. This line is also a separate paragraph, but... This line is only separated by a single newline, so it's a separate line in the *same paragraph*. Here\u2019s a line for us to start with. This line is separated from the one above by two newlines, so it will be a separate paragraph . This line is also begins a separate paragraph, but\u2026 This line is only separated by a single newline, so it\u2019s a separate line in the same paragraph . (Technical note: *Markdown Here- uses GFM line breaks, so there\u2019s no need to use MD\u2019s two-space line breaks.)","title":"Line Breaks"},{"location":"engine/cheatsheet/#youtube-videos","text":"They can\u2019t be added directly but you can add an image with a link to the video like this: 1 2 3 < a href = \"http://www.youtube.com/watch?feature=player_embedded&v=YOUTUBE_VIDEO_ID_HERE \" target = \"_blank\" >< img src = \"http://images.youtube.com/vi/YOUTUBE_VIDEO_ID_HERE/0.jpg\" alt = \"IMAGE ALT TEXT HERE\" width = \"240\" height = \"180\" border = \"10\" /></ a > Or, in pure Markdown, but losing the image sizing and border: 1 [![IMAGE ALT TEXT HERE](http://images.youtube.com/vi/YOUTUBE_VIDEO_ID_HERE/0.jpg)](http://www.youtube.com/watch?v=YOUTUBE_VIDEO_ID_HERE)","title":"Youtube videos"},{"location":"engine/cheatsheet/#references","text":"Markdown Emoji Codes Extentions PyMdown CodeHilite","title":"References"},{"location":"engine/colors/","text":"Theme Color Styling \u00b6 Martin Donath a.k.a. SquidFunc , the author of the beautiful MkDocs Material theme for the famous MkDocs documentation site generator has written a big Getting Started guide. I have used this theme and this guide to set up this website with my personal documentation. I was fascinated by the styling section in relation to colors and accents. The big question however was how to achieve the effect of rows of color swatches instead of one long column. I have not figured out how Martin did it on his website. Instead, I have managed to achieve the same by using <div class=\"flex-container\"> inline in the Markdown document (see the source code of this page in my repo). So, I have included the color sections of the official guide to demo this alternative approach. Color palette \u00b6 A default hue is defined for every primary and accent color on Google\u2019s Material Design color palette , which makes it very easy to change the overall look of the theme. Just set the primary and accent colors using the following variables: 1 2 3 4 theme : palette : primary : 'indigo' accent : 'indigo' Color names are case-insensitive, but must match the names of the Material Design color palette. Valid values are: red , pink , purple , deep purple , indigo , blue , light blue , cyan , teal , green , light green , lime , yellow , amber , orange , deep orange , brown , grey , blue grey and white . The last four colors can only be used as a primary color. If the color is set via this configuration, an additional CSS file that defines the color palette is automatically included. If you want to keep things lean, clone the repository and recompile the theme with your custom colors set. Primary colors \u00b6 Default: indigo Click on a tile to change the primary color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange Brown Grey Blue Grey White var buttons = document.querySelectorAll(\"button[data-md-color-primary]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorPrimary = this.dataset.mdColorPrimary; }) }) Accent colors \u00b6 Default: indigo Click on a tile to change the accent color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange var buttons = document.querySelectorAll(\"button[data-md-color-accent]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorAccent = this.dataset.mdColorAccent; }) }) A default hue is defined for every primary and accent color on Google\u2019s Material Design color palette, which makes it very easy to change the overall look of the theme. Just set the primary and accent colors using the following variables: 1 2 3 4 theme : palette : primary : 'indigo' accent : 'indigo' Color names are case-insensitive, but must match the names of the Material Design color palette. Valid values are: red , pink , purple , deep purple , indigo , blue , light blue , cyan , teal , green , light green , lime , yellow , amber , orange , deep orange , brown , grey , blue grey and white . The last four colors can only be used as a primary color. Compile your own custom color theme If the color is set via this configuration, an additional CSS file that defines the color palette is automatically included. If you want to keep things lean, clone the repository and recompile the theme with your custom colors set . See the guide on customization for more information.","title":"Color Styling"},{"location":"engine/colors/#theme-color-styling","text":"Martin Donath a.k.a. SquidFunc , the author of the beautiful MkDocs Material theme for the famous MkDocs documentation site generator has written a big Getting Started guide. I have used this theme and this guide to set up this website with my personal documentation. I was fascinated by the styling section in relation to colors and accents. The big question however was how to achieve the effect of rows of color swatches instead of one long column. I have not figured out how Martin did it on his website. Instead, I have managed to achieve the same by using <div class=\"flex-container\"> inline in the Markdown document (see the source code of this page in my repo). So, I have included the color sections of the official guide to demo this alternative approach.","title":"Theme Color Styling"},{"location":"engine/colors/#color-palette","text":"A default hue is defined for every primary and accent color on Google\u2019s Material Design color palette , which makes it very easy to change the overall look of the theme. Just set the primary and accent colors using the following variables: 1 2 3 4 theme : palette : primary : 'indigo' accent : 'indigo' Color names are case-insensitive, but must match the names of the Material Design color palette. Valid values are: red , pink , purple , deep purple , indigo , blue , light blue , cyan , teal , green , light green , lime , yellow , amber , orange , deep orange , brown , grey , blue grey and white . The last four colors can only be used as a primary color. If the color is set via this configuration, an additional CSS file that defines the color palette is automatically included. If you want to keep things lean, clone the repository and recompile the theme with your custom colors set.","title":"Color palette"},{"location":"engine/colors/#primary-colors","text":"Default: indigo Click on a tile to change the primary color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange Brown Grey Blue Grey White var buttons = document.querySelectorAll(\"button[data-md-color-primary]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorPrimary = this.dataset.mdColorPrimary; }) })","title":"Primary colors"},{"location":"engine/colors/#accent-colors","text":"Default: indigo Click on a tile to change the accent color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange var buttons = document.querySelectorAll(\"button[data-md-color-accent]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorAccent = this.dataset.mdColorAccent; }) }) A default hue is defined for every primary and accent color on Google\u2019s Material Design color palette, which makes it very easy to change the overall look of the theme. Just set the primary and accent colors using the following variables: 1 2 3 4 theme : palette : primary : 'indigo' accent : 'indigo' Color names are case-insensitive, but must match the names of the Material Design color palette. Valid values are: red , pink , purple , deep purple , indigo , blue , light blue , cyan , teal , green , light green , lime , yellow , amber , orange , deep orange , brown , grey , blue grey and white . The last four colors can only be used as a primary color. Compile your own custom color theme If the color is set via this configuration, an additional CSS file that defines the color palette is automatically included. If you want to keep things lean, clone the repository and recompile the theme with your custom colors set . See the guide on customization for more information.","title":"Accent colors"},{"location":"engine/deployments/","text":"PowerShell Deployments \u00b6 This section describes some tips for Windows users. Deployment to your local IIS \u00b6 You can host the website automatically in the local IIS as http://localhost:1111 . That is done by the deploy_to_local_iis.ps1 script. Here are the steps: make sure you have IIS installed on your notebook; if necessary, add the corresponding Windows 10 features run Visual Studio Code as Administrator (necessary for running PowerShell scripts with elevated rights) open the project in Visual Studio Code from the file tree on the left, open the deploy_to_local_iis.ps1 script (you can find in the root of the project) and keep it as your currently open window go to the debugger mode in the menu on the left (click the bug icon) in the debug options above, choose PowerShell Launch Current File and click on the green triangle Alternatively, open a PowerShell console as Administrator and run the following commands: 1 2 Change-Location C : \\ To \\ The \\ Project \\ Root \\ Folder .\\ deploy_to_local_iis . ps1 Now, you should be able to see the website by browsing to http://localhost:1111 . Possible Issues \u00b6 Cannot find drive \u2018IIS\u2019 \u00b6 When running a deployment PowerShell script, you get the error message: 1 Cannot find drive. A drive with the name 'IIS' does not exist. You are probably running the script without the elevated rights. Try running the script as Administrator . Missing MIME-types \u00b6 If the search does not work and in the DevTools you see a 404-error on ./mkdocs/js/search-results-template.mustache , this can mean that a mime-type is missing for .mustache Open the IIS Manager and click on the root node. Among the features on the right, find and double-click MIME Types . If you miss the mime-type for .mustache , add it as mustache: text/template .","title":"PowerShell Deployments"},{"location":"engine/deployments/#powershell-deployments","text":"This section describes some tips for Windows users.","title":"PowerShell Deployments"},{"location":"engine/deployments/#deployment-to-your-local-iis","text":"You can host the website automatically in the local IIS as http://localhost:1111 . That is done by the deploy_to_local_iis.ps1 script. Here are the steps: make sure you have IIS installed on your notebook; if necessary, add the corresponding Windows 10 features run Visual Studio Code as Administrator (necessary for running PowerShell scripts with elevated rights) open the project in Visual Studio Code from the file tree on the left, open the deploy_to_local_iis.ps1 script (you can find in the root of the project) and keep it as your currently open window go to the debugger mode in the menu on the left (click the bug icon) in the debug options above, choose PowerShell Launch Current File and click on the green triangle Alternatively, open a PowerShell console as Administrator and run the following commands: 1 2 Change-Location C : \\ To \\ The \\ Project \\ Root \\ Folder .\\ deploy_to_local_iis . ps1 Now, you should be able to see the website by browsing to http://localhost:1111 .","title":"Deployment to your local IIS"},{"location":"engine/deployments/#possible-issues","text":"","title":"Possible Issues"},{"location":"engine/deployments/#cannot-find-drive-iis","text":"When running a deployment PowerShell script, you get the error message: 1 Cannot find drive. A drive with the name 'IIS' does not exist. You are probably running the script without the elevated rights. Try running the script as Administrator .","title":"Cannot find drive 'IIS'"},{"location":"engine/deployments/#missing-mime-types","text":"If the search does not work and in the DevTools you see a 404-error on ./mkdocs/js/search-results-template.mustache , this can mean that a mime-type is missing for .mustache Open the IIS Manager and click on the root node. Among the features on the right, find and double-click MIME Types . If you miss the mime-type for .mustache , add it as mustache: text/template .","title":"Missing MIME-types"},{"location":"engine/install/","text":"Installation \u00b6 Taken from this website . Installing MkDocs \u00b6 Before installing MkDocs , you need to make sure you have Python and pip \u2013 the Python package manager \u2013 up and running. You can verify if you\u2019re already good to go with the following commands: 1 2 3 4 python --version # Python 2.7.13 pip --version # pip 9.0.1 Installing and verifying MkDocs is as simple as: 1 2 pip install mkdocs && mkdocs --version # mkdocs, version 0.17.1 Material requires MkDocs >= 0.17.1. Installing Material \u00b6 using pip \u00b6 Material can be installed with pip: 1 pip install mkdocs-material using choco \u00b6 If you\u2019re on Windows you can use Chocolatey to install Material: 1 choco install mkdocs-material This will install all required dependencies like Python and MkDocs. cloning from GitHub \u00b6 Material can also be used without a system-wide installation by cloning the repository into a subfolder of your project\u2019s root directory: 1 git clone https://github.com/squidfunk/mkdocs-material.git This is especially useful if you want to extend the theme and override some parts of the theme. The theme will reside in the folder mkdocs-material/material . Troubleshooting \u00b6 Installation on macOS When you\u2019re running the pre-installed version of Python on macOS, pip tries to install packages in a folder for which your user might not have the adequate permissions. There are two possible solutions for this: Installing in user space (recommended): Provide the \u2013user flag to the install command and pip will install the package in a user-site location. This is the recommended way. Switching to a homebrewed Python: Upgrade your Python installation to a self-contained solution by installing Python with Homebrew. This should eliminate a lot of problems you may be having with pip. Error: unrecognized theme \u2018material\u2019 If you run into this error, the most common reason is that you installed MkDocs through some package manager (e.g. Homebrew or apt-get) and the Material theme through pip, so both packages end up in different locations. MkDocs only checks its install location for themes. Alternative: Using Docker \u00b6 If you\u2019re familiar with Docker , the official Docker image for Material comes with all dependencies pre-installed and ready-to-use with the latest version published on PyPI , packaged in a very small image. Pull it with: 1 docker pull squidfunk/mkdocs-material The mkdocs executable is provided as an entrypoint, serve is the default command. Start the development server in your project root with: 1 docker run --rm -it -p 8000:8000 -v `pwd`:/docs squidfunk/mkdocs-material Usage \u00b6 In order to enable the theme just add one of the following lines to your project\u2019s mkdocs.yml . If you installed Material using pip: 1 2 theme : name : 'material' If you cloned Material from GitHub: 1 2 3 theme : name : null custom_dir : 'mkdocs-material/material' MkDocs includes a development server, so you can review your changes as you go. The development server can be started with the following command: 1 mkdocs serve Now you can point your browser to http://localhost:8000 and the Material theme should be visible. From here on, you can start writing your documentation, or read on and customize the theme. Configuration \u00b6 Color palette \u00b6 A default hue is defined for every primary and accent color on Google\u2019s Material Design color palette , which makes it very easy to change the overall look of the theme. Just set the primary and accent colors using the following variables: 1 2 3 4 theme : palette : primary : 'indigo' accent : 'indigo' Color names are case-insensitive, but must match the names of the Material Design color palette. Valid values are: red , pink , purple , deep purple , indigo , blue , light blue , cyan , teal , green , light green , lime , yellow , amber , orange , deep orange , brown , grey , blue grey and white . The last four colors can only be used as a primary color. If the color is set via this configuration, an additional CSS file that defines the color palette is automatically included. If you want to keep things lean, clone the repository and recompile the theme with your custom colors set. Primary colors \u00b6 Default: indigo Click on a tile to change the primary color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange Brown Grey Blue Grey White var buttons = document.querySelectorAll(\"button[data-md-color-primary]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorPrimary = this.dataset.mdColorPrimary; }) }) Accent colors \u00b6 Default: indigo Click on a tile to change the accent color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange var buttons = document.querySelectorAll(\"button[data-md-color-accent]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorAccent = this.dataset.mdColorAccent; }) }) A default hue is defined for every primary and accent color on Google\u2019s Material Design color palette, which makes it very easy to change the overall look of the theme. Just set the primary and accent colors using the following variables: 1 2 3 4 theme : palette : primary : 'indigo' accent : 'indigo' Color names are case-insensitive, but must match the names of the Material Design color palette. Valid values are: red , pink , purple , deep purple , indigo , blue , light blue , cyan , teal , green , light green , lime , yellow , amber , orange , deep orange , brown , grey , blue grey and white . The last four colors can only be used as a primary color. Compile your own custom color theme If the color is set via this configuration, an additional CSS file that defines the color palette is automatically included. If you want to keep things lean, clone the repository and recompile the theme with your custom colors set . See the guide on customization for more information. Font family \u00b6 Default: Roboto and Roboto Mono By default the Roboto font family is included with the theme, specifically the regular sans-serif type for text and the monospaced type for code. Both fonts are loaded from Google Fonts and can be changed to other fonts, like for example the Ubuntu font family : 1 2 3 4 theme : font : text : 'Ubuntu' code : 'Ubuntu Mono' The text font will be loaded in weights 400 and 700, the monospaced font in regular weight. If you want to load fonts from other destinations or don\u2019t want to use the Google Fonts loading magic, just set font to false : 1 2 theme : font : false Logo \u00b6 Default icon: school Your logo should have rectangular shape with a minimum resolution of 128x128, leave some room towards the edges and be composed of high contrast areas on a transparent ground, as it will be placed on the colored header bar and drawer. Simply create the folder docs/images , add your logo and embed it with: 1 2 theme : logo : 'images/logo.svg' Additionally, the default icon can be changed by setting an arbitrary ligature (or Unicode code point) from the Material Design icon font , e.g. 1 2 3 theme : logo : icon : 'cloud' Language \u00b6 Localization \u00b6 Default: en Material for MkDocs supports internationalization ( i18n ) and provides translations for all template variables and labels in English en , French fr , German de , Spanish es , Italian it , Danish da , Portugese pt , Polish pl , Norwegian no , Dutch nl , Swedish sv , Korean kr , Russian ru , Japanese ja , Chinese (Simplified) zh and Chinese (Traditional) zh-Hant . Specify the language with: 1 2 theme : language : 'en' Make your own translations If the language is not specified, Material falls back to English. To create a translation for another language, copy the localization file of an existing language, name the new file using the 2-letter language code and adjust all translations: 1 cp partials/language/en.html partials/language/jp.html Feel free to contribute your localization to Material for MkDocs by opening a Pull Request. Site search \u00b6 Default: en Site search is implemented using lunr.js , which includes stemmers for the English language by default, while stemmers for other languages are included with lunr-languages , both of which are integrated with this theme. Support for other languages and even multilingual search can be activated in your project\u2019s mkdocs.yml : 1 2 3 extra : search : language : 'en, de, ru' All defined languages are used only for stemming. This will automatically load the stemmers for the specified languages and set them up with site search. At the time of writing, the following languages are supported: English en , French fr , German de , Spanish es , Italian it , Danish da , Portugese pt , Finnish fi, Romanian ro, Hungarian hu, Russian ru , Norwegian no , Swedish sv , Japanese ja and Turkish tr . Only specify the languages you really need Be aware that including support for other languages increases the general JavaScript payload by around 20kb (without gzip) and by another 15-30kb per language. The separator for tokenization can be customized which makes it possible to index parts of words that are separated by - or . : 1 2 3 extra : search : tokenizer : '[\\s\\-\\.]+' Favicon \u00b6 Default: assets/images/favicon.png The default favicon can be changed by setting the favicon variable to an .ico or image file: 1 2 theme : favicon : 'assets/images/favicon.ico' Features \u00b6 Tabs \u00b6 Default: false Material supports another layer on top of the main navigation for larger screens in the form of tabs. This is especially useful for larger documentation projects with only few top-level sections. Tabs can be enabled by setting the respective feature flag to true: 1 2 3 theme : feature : tabs : true Customization \u00b6 Adding a source repository \u00b6 To include a link to the repository of your project within your documentation, set the following variables via your project\u2019s mkdocs.yml : 1 2 repo_name : 'squidfunk/mkdocs-material' repo_url : 'https://github.com/squidfunk/mkdocs-material' The name of the repository will be rendered next to the search bar on big screens and as part of the main navigation drawer on smaller screen sizes. Furthermore, if repo_url points to a GitHub , BitBucket or GitLab repository, the respective service logo will be shown next to the name of the repository. Additionally, for GitHub , the number of stars and forks is shown. If the repository is hosted in a private environment, the service logo can be set explicitly by setting extra.repo_icon to github , gitlab or bitbucket . Why is there an edit button at the top of every article? If the repo_url is set to a GitHub or BitBucket repository, and the repo_name is set to GitHub or BitBucket (implied by default), an edit button will appear at the top of every article. This is the automatic behavior that MkDocs implements. Set edit_uri to an empty string to disable this automatic behavior. See the MkDocs documentation on more guidance regarding the edit_uri attribute, which defines whether the edit button is shown or not. Adding social links \u00b6 Social accounts can be linked in the footer of the documentation using the automatically included FontAwesome webfont . The type must denote the name of the social service, e.g. github , twitter or linkedin and the link must contain the URL you want to link to: 1 2 3 4 5 6 7 8 extra : social : - type : 'github' link : 'https://github.com/squidfunk' - type : 'twitter' link : 'https://twitter.com/squidfunk' - type : 'linkedin' link : 'https://linkedin.com/in/squidfunk' The links are generated in order and the type of the links must match the name of the FontAwesome glyph. The fa is automatically added, so github will result in fa fa-github . More advanced customization \u00b6 If you want to change the general appearance of the Material theme, see this article for more information on advanced customization. Integrations \u00b6 Google Analytics \u00b6 MkDocs makes it easy to integrate site tracking with Google Analytics. Besides basic tracking, clicks on all outgoing links can be tracked as well as how site search is used. Tracking can be activated in your project\u2019s mkdocs.yml : 1 2 3 google_analytics : - 'UA-XXXXXXXX-X' - 'auto' Disqus \u00b6 Material for MkDocs is integrated with Disqus , so if you want to add a comments section to your documentation set the shortname of your Disqus project in your mkdocs.yml : 1 2 extra : disqus : 'mkdocs-material' The comments section is inserted on every page, except the index page. Additionally, a new entry at the bottom of the table of contents is generated that is linking to the comments section. The necessary JavaScript is automatically included. Requirements site_url value must be set in mkdocs.yml for the Disqus integration to load properly. Extensions \u00b6 MkDocs supports several Markdown extensions . The following extensions are not enabled by default (see the link for which are enabled by default) but highly recommended, so they should be switched on at all times: 1 2 3 4 5 6 markdown_extensions : - admonition - codehilite : guess_lang : false - toc : permalink : true For more information, see the following list of extensions supported by the Material theme including more information regarding installation and usage: Admonition Codehilite Footnotes Metadata Permalinks PyMdown Extensions Full example \u00b6 Below is a full example configuration for a mkdocs.yml : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # Project information site_name : 'Material for MkDocs' site_description : 'A Material Design theme for MkDocs' site_author : 'Martin Donath' site_url : 'https://squidfunk.github.io/mkdocs-material/' # Repository repo_name : 'squidfunk/mkdocs-material' repo_url : 'https://github.com/squidfunk/mkdocs-material' # Copyright copyright : 'Copyright &copy; 2016 - 2017 Martin Donath' # Configuration theme : name : 'material' language : 'en' palette : primary : 'indigo' accent : 'indigo' font : text : 'Roboto' code : 'Roboto Mono' # Customization extra : social : - type : 'github' link : 'https://github.com/squidfunk' - type : 'twitter' link : 'https://twitter.com/squidfunk' - type : 'linkedin' link : 'https://linkedin.com/in/squidfunk' # Google Analytics google_analytics : - 'UA-XXXXXXXX-X' - 'auto' # Extensions markdown_extensions : - admonition - codehilite : guess_lang : false - toc : permalink : true","title":"Installation"},{"location":"engine/install/#installation","text":"Taken from this website .","title":"Installation"},{"location":"engine/install/#installing-mkdocs","text":"Before installing MkDocs , you need to make sure you have Python and pip \u2013 the Python package manager \u2013 up and running. You can verify if you\u2019re already good to go with the following commands: 1 2 3 4 python --version # Python 2.7.13 pip --version # pip 9.0.1 Installing and verifying MkDocs is as simple as: 1 2 pip install mkdocs && mkdocs --version # mkdocs, version 0.17.1 Material requires MkDocs >= 0.17.1.","title":"Installing MkDocs"},{"location":"engine/install/#installing-material","text":"","title":"Installing Material"},{"location":"engine/install/#using-pip","text":"Material can be installed with pip: 1 pip install mkdocs-material","title":"using pip"},{"location":"engine/install/#using-choco","text":"If you\u2019re on Windows you can use Chocolatey to install Material: 1 choco install mkdocs-material This will install all required dependencies like Python and MkDocs.","title":"using choco"},{"location":"engine/install/#cloning-from-github","text":"Material can also be used without a system-wide installation by cloning the repository into a subfolder of your project\u2019s root directory: 1 git clone https://github.com/squidfunk/mkdocs-material.git This is especially useful if you want to extend the theme and override some parts of the theme. The theme will reside in the folder mkdocs-material/material .","title":"cloning from GitHub"},{"location":"engine/install/#troubleshooting","text":"Installation on macOS When you\u2019re running the pre-installed version of Python on macOS, pip tries to install packages in a folder for which your user might not have the adequate permissions. There are two possible solutions for this: Installing in user space (recommended): Provide the \u2013user flag to the install command and pip will install the package in a user-site location. This is the recommended way. Switching to a homebrewed Python: Upgrade your Python installation to a self-contained solution by installing Python with Homebrew. This should eliminate a lot of problems you may be having with pip. Error: unrecognized theme \u2018material\u2019 If you run into this error, the most common reason is that you installed MkDocs through some package manager (e.g. Homebrew or apt-get) and the Material theme through pip, so both packages end up in different locations. MkDocs only checks its install location for themes.","title":"Troubleshooting"},{"location":"engine/install/#alternative-using-docker","text":"If you\u2019re familiar with Docker , the official Docker image for Material comes with all dependencies pre-installed and ready-to-use with the latest version published on PyPI , packaged in a very small image. Pull it with: 1 docker pull squidfunk/mkdocs-material The mkdocs executable is provided as an entrypoint, serve is the default command. Start the development server in your project root with: 1 docker run --rm -it -p 8000:8000 -v `pwd`:/docs squidfunk/mkdocs-material","title":"Alternative: Using Docker"},{"location":"engine/install/#usage","text":"In order to enable the theme just add one of the following lines to your project\u2019s mkdocs.yml . If you installed Material using pip: 1 2 theme : name : 'material' If you cloned Material from GitHub: 1 2 3 theme : name : null custom_dir : 'mkdocs-material/material' MkDocs includes a development server, so you can review your changes as you go. The development server can be started with the following command: 1 mkdocs serve Now you can point your browser to http://localhost:8000 and the Material theme should be visible. From here on, you can start writing your documentation, or read on and customize the theme.","title":"Usage"},{"location":"engine/install/#configuration","text":"","title":"Configuration"},{"location":"engine/install/#color-palette","text":"A default hue is defined for every primary and accent color on Google\u2019s Material Design color palette , which makes it very easy to change the overall look of the theme. Just set the primary and accent colors using the following variables: 1 2 3 4 theme : palette : primary : 'indigo' accent : 'indigo' Color names are case-insensitive, but must match the names of the Material Design color palette. Valid values are: red , pink , purple , deep purple , indigo , blue , light blue , cyan , teal , green , light green , lime , yellow , amber , orange , deep orange , brown , grey , blue grey and white . The last four colors can only be used as a primary color. If the color is set via this configuration, an additional CSS file that defines the color palette is automatically included. If you want to keep things lean, clone the repository and recompile the theme with your custom colors set.","title":"Color palette"},{"location":"engine/install/#primary-colors","text":"Default: indigo Click on a tile to change the primary color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange Brown Grey Blue Grey White var buttons = document.querySelectorAll(\"button[data-md-color-primary]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorPrimary = this.dataset.mdColorPrimary; }) })","title":"Primary colors"},{"location":"engine/install/#accent-colors","text":"Default: indigo Click on a tile to change the accent color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange var buttons = document.querySelectorAll(\"button[data-md-color-accent]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorAccent = this.dataset.mdColorAccent; }) }) A default hue is defined for every primary and accent color on Google\u2019s Material Design color palette, which makes it very easy to change the overall look of the theme. Just set the primary and accent colors using the following variables: 1 2 3 4 theme : palette : primary : 'indigo' accent : 'indigo' Color names are case-insensitive, but must match the names of the Material Design color palette. Valid values are: red , pink , purple , deep purple , indigo , blue , light blue , cyan , teal , green , light green , lime , yellow , amber , orange , deep orange , brown , grey , blue grey and white . The last four colors can only be used as a primary color. Compile your own custom color theme If the color is set via this configuration, an additional CSS file that defines the color palette is automatically included. If you want to keep things lean, clone the repository and recompile the theme with your custom colors set . See the guide on customization for more information.","title":"Accent colors"},{"location":"engine/install/#font-family","text":"Default: Roboto and Roboto Mono By default the Roboto font family is included with the theme, specifically the regular sans-serif type for text and the monospaced type for code. Both fonts are loaded from Google Fonts and can be changed to other fonts, like for example the Ubuntu font family : 1 2 3 4 theme : font : text : 'Ubuntu' code : 'Ubuntu Mono' The text font will be loaded in weights 400 and 700, the monospaced font in regular weight. If you want to load fonts from other destinations or don\u2019t want to use the Google Fonts loading magic, just set font to false : 1 2 theme : font : false","title":"Font family"},{"location":"engine/install/#logo","text":"Default icon: school Your logo should have rectangular shape with a minimum resolution of 128x128, leave some room towards the edges and be composed of high contrast areas on a transparent ground, as it will be placed on the colored header bar and drawer. Simply create the folder docs/images , add your logo and embed it with: 1 2 theme : logo : 'images/logo.svg' Additionally, the default icon can be changed by setting an arbitrary ligature (or Unicode code point) from the Material Design icon font , e.g. 1 2 3 theme : logo : icon : 'cloud'","title":"Logo"},{"location":"engine/install/#language","text":"","title":"Language"},{"location":"engine/install/#localization","text":"Default: en Material for MkDocs supports internationalization ( i18n ) and provides translations for all template variables and labels in English en , French fr , German de , Spanish es , Italian it , Danish da , Portugese pt , Polish pl , Norwegian no , Dutch nl , Swedish sv , Korean kr , Russian ru , Japanese ja , Chinese (Simplified) zh and Chinese (Traditional) zh-Hant . Specify the language with: 1 2 theme : language : 'en' Make your own translations If the language is not specified, Material falls back to English. To create a translation for another language, copy the localization file of an existing language, name the new file using the 2-letter language code and adjust all translations: 1 cp partials/language/en.html partials/language/jp.html Feel free to contribute your localization to Material for MkDocs by opening a Pull Request.","title":"Localization"},{"location":"engine/install/#site-search","text":"Default: en Site search is implemented using lunr.js , which includes stemmers for the English language by default, while stemmers for other languages are included with lunr-languages , both of which are integrated with this theme. Support for other languages and even multilingual search can be activated in your project\u2019s mkdocs.yml : 1 2 3 extra : search : language : 'en, de, ru' All defined languages are used only for stemming. This will automatically load the stemmers for the specified languages and set them up with site search. At the time of writing, the following languages are supported: English en , French fr , German de , Spanish es , Italian it , Danish da , Portugese pt , Finnish fi, Romanian ro, Hungarian hu, Russian ru , Norwegian no , Swedish sv , Japanese ja and Turkish tr . Only specify the languages you really need Be aware that including support for other languages increases the general JavaScript payload by around 20kb (without gzip) and by another 15-30kb per language. The separator for tokenization can be customized which makes it possible to index parts of words that are separated by - or . : 1 2 3 extra : search : tokenizer : '[\\s\\-\\.]+'","title":"Site search"},{"location":"engine/install/#favicon","text":"Default: assets/images/favicon.png The default favicon can be changed by setting the favicon variable to an .ico or image file: 1 2 theme : favicon : 'assets/images/favicon.ico'","title":"Favicon"},{"location":"engine/install/#features","text":"","title":"Features"},{"location":"engine/install/#tabs","text":"Default: false Material supports another layer on top of the main navigation for larger screens in the form of tabs. This is especially useful for larger documentation projects with only few top-level sections. Tabs can be enabled by setting the respective feature flag to true: 1 2 3 theme : feature : tabs : true","title":"Tabs"},{"location":"engine/install/#customization","text":"","title":"Customization"},{"location":"engine/install/#adding-a-source-repository","text":"To include a link to the repository of your project within your documentation, set the following variables via your project\u2019s mkdocs.yml : 1 2 repo_name : 'squidfunk/mkdocs-material' repo_url : 'https://github.com/squidfunk/mkdocs-material' The name of the repository will be rendered next to the search bar on big screens and as part of the main navigation drawer on smaller screen sizes. Furthermore, if repo_url points to a GitHub , BitBucket or GitLab repository, the respective service logo will be shown next to the name of the repository. Additionally, for GitHub , the number of stars and forks is shown. If the repository is hosted in a private environment, the service logo can be set explicitly by setting extra.repo_icon to github , gitlab or bitbucket . Why is there an edit button at the top of every article? If the repo_url is set to a GitHub or BitBucket repository, and the repo_name is set to GitHub or BitBucket (implied by default), an edit button will appear at the top of every article. This is the automatic behavior that MkDocs implements. Set edit_uri to an empty string to disable this automatic behavior. See the MkDocs documentation on more guidance regarding the edit_uri attribute, which defines whether the edit button is shown or not.","title":"Adding a source repository"},{"location":"engine/install/#adding-social-links","text":"Social accounts can be linked in the footer of the documentation using the automatically included FontAwesome webfont . The type must denote the name of the social service, e.g. github , twitter or linkedin and the link must contain the URL you want to link to: 1 2 3 4 5 6 7 8 extra : social : - type : 'github' link : 'https://github.com/squidfunk' - type : 'twitter' link : 'https://twitter.com/squidfunk' - type : 'linkedin' link : 'https://linkedin.com/in/squidfunk' The links are generated in order and the type of the links must match the name of the FontAwesome glyph. The fa is automatically added, so github will result in fa fa-github .","title":"Adding social links"},{"location":"engine/install/#more-advanced-customization","text":"If you want to change the general appearance of the Material theme, see this article for more information on advanced customization.","title":"More advanced customization"},{"location":"engine/install/#integrations","text":"","title":"Integrations"},{"location":"engine/install/#google-analytics","text":"MkDocs makes it easy to integrate site tracking with Google Analytics. Besides basic tracking, clicks on all outgoing links can be tracked as well as how site search is used. Tracking can be activated in your project\u2019s mkdocs.yml : 1 2 3 google_analytics : - 'UA-XXXXXXXX-X' - 'auto'","title":"Google Analytics"},{"location":"engine/install/#disqus","text":"Material for MkDocs is integrated with Disqus , so if you want to add a comments section to your documentation set the shortname of your Disqus project in your mkdocs.yml : 1 2 extra : disqus : 'mkdocs-material' The comments section is inserted on every page, except the index page. Additionally, a new entry at the bottom of the table of contents is generated that is linking to the comments section. The necessary JavaScript is automatically included. Requirements site_url value must be set in mkdocs.yml for the Disqus integration to load properly.","title":"Disqus"},{"location":"engine/install/#extensions","text":"MkDocs supports several Markdown extensions . The following extensions are not enabled by default (see the link for which are enabled by default) but highly recommended, so they should be switched on at all times: 1 2 3 4 5 6 markdown_extensions : - admonition - codehilite : guess_lang : false - toc : permalink : true For more information, see the following list of extensions supported by the Material theme including more information regarding installation and usage: Admonition Codehilite Footnotes Metadata Permalinks PyMdown Extensions","title":"Extensions"},{"location":"engine/install/#full-example","text":"Below is a full example configuration for a mkdocs.yml : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # Project information site_name : 'Material for MkDocs' site_description : 'A Material Design theme for MkDocs' site_author : 'Martin Donath' site_url : 'https://squidfunk.github.io/mkdocs-material/' # Repository repo_name : 'squidfunk/mkdocs-material' repo_url : 'https://github.com/squidfunk/mkdocs-material' # Copyright copyright : 'Copyright &copy; 2016 - 2017 Martin Donath' # Configuration theme : name : 'material' language : 'en' palette : primary : 'indigo' accent : 'indigo' font : text : 'Roboto' code : 'Roboto Mono' # Customization extra : social : - type : 'github' link : 'https://github.com/squidfunk' - type : 'twitter' link : 'https://twitter.com/squidfunk' - type : 'linkedin' link : 'https://linkedin.com/in/squidfunk' # Google Analytics google_analytics : - 'UA-XXXXXXXX-X' - 'auto' # Extensions markdown_extensions : - admonition - codehilite : guess_lang : false - toc : permalink : true","title":"Full example"},{"location":"engine/start/","text":"Getting Started \u00b6 Installing prerequisites \u00b6 If you want to participate in development of this project, you need to carry out a couple of simple steps described below. Clone the repository to your local machine. Have the latest version of Python 3.6 installed, which can be downloaded from here . Add the following two paths to your Windows Path user environment variable: C:\\Users\\YourUserName\\AppData\\Local\\Programs\\Python\\Python36-32 C:\\Users\\YourUserName\\AppData\\Local\\Programs\\Python\\Python36-32\\Scripts Now, run any shell script ( cmd , git-bash or PowerShell ) and install/upgrade mkdocs and related packages: 1 pip install -U mkdocs mkdocs-material fontawesome-markdown pymdown-extensions Project Layout \u00b6 1 2 3 4 5 mkdocs.yml # The configuration file docs/ index.md # The documentation homepage ... # Other markdown pages, and other files /images # Images used in the documents Running the project in DEV \u00b6 Open the command prompt in the project root directory and type: 1 mkdocs serve Or, if you need to run it on a specific port, e.g. 8080, you can do one of the following: 1 2 mkdocs serve --dev-addr:8080 mkdocs serve -a :8080 Then open your browser and navigate to http://localhost:8000 or whatever port number you have configured. Useful Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. FontAwesome \u00b6 Up to Python 3.4? Python versions above 3.4 are probably not supported yet. See the setup.py file for the classifiers section, it mentions Python versions up to 3.4. Does not work on my website (yet) FontAwesome Markdown does not work on this documentation website. I am trying to figure out why but so far no success. FontAwesome gives you scalable vector icons that can instantly be customized \u2013 size, color, drop shadow, and anything that can be done with the power of CSS. For more inpiration see these examples . FontAwesome Markdown is a Markdown extension that looks for things like :fa-coffee: ( ) or :fa-beer: ( ) and replaces them with the FontAwesome icon markup. Examples \u00b6 This example uses the fontawesome_markdown extension: 1 What would you drink, :fa-coffee: or :fa-beer:? What would you drink, or ? For this example, you must install the fontawesome_markdown extension with pip . Right now version 0.2.5 is the latest but it doesn\u2019t work out of the box. Instead, you have to install the latest version from the github repository. You can do that with the command below: 1 pip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip You may need to include -U in the above command if you already have this extension installed. Then add the below to your mkdocs.yml file. 1 2 markdown_extensions: - fontawesome_markdown Deployment to GitHub Pages \u00b6 Direct Deployment \u00b6 To publish the project to GitHub Pages as a subdomain, e.g. /mdocs of the main website, you need first to create a repository with that name, e.g. mdocs and add it to your project as a remote. Next make sure you have a gh-pages branch that exists. If it doesn\u2019t: 1 2 3 git checkout -b gh-pages git rm -rf . git push --set-upstream origin gh-pages Now, open the command prompt in the root directory (on the master branch) and type: 1 mkdocs gh-deploy This will push the master branch to the remote gh-pages . After that, the project website is available at your-github-login.github.io/mdocs . Travis CI Deployment \u00b6 Go to your GitHub account and create a new Personal access token in your Developer settings. Copy the hash string. Keep well the hash string! You will see it only once when you create it. In the Travis CI settings of your project add a new GITHUB_TOKEN environment variable with the value of the hash string your have just copied. Don\u2019t forget to turn in ON and to ADD . Configure the .travis.yml file. You may start with something like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 sudo : false language : python python : '3.6' install : - pip install -U pip - pip install -r requirements.txt - pip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip script : - git config credential.helper \"store --file=.git/credentials\" - echo \"https://${GITHUB_TOKEN}:@github.com\" > .git/credentials - mkdocs build --verbose --clean --strict - if [ $TRAVIS_TEST_RESULT == 0 ]; then mkdocs gh-deploy --force; fi The credentials here are necessary for the Travis agent to be able to connect to your Github repository and perform the necessary actions with it. Note that the credentials are based on the Personal access token you have created. Also, I have put deployment inside the script fase instead of after_success as a workaround (see the tip of Chronial on this Travis issue #758 ). Otherwise, the batch succeeds with a successful build even if deploy fails after it. Next, you need to have travis Rubygem installed on your local machine. If not, install it: 1 gem install travis Using travis , add the encrypted token to .travis.yml : 1 travis encrypt GITHUB_TOKEN = \"the-token-from-github\" --add This will add the following block at the end of the file: 1 2 3 env : global : - secure : \"lots-of-seemingly-random-characters\" Now, when you push your changes to the remote master , Travis CI should publish the compiled website to GitHub Pages if the build succeeds. References \u00b6 Here are the most important links that have inspired me: Latest official MkDocs documentation MkDocs User Guide","title":"Getting started"},{"location":"engine/start/#getting-started","text":"","title":"Getting Started"},{"location":"engine/start/#installing-prerequisites","text":"If you want to participate in development of this project, you need to carry out a couple of simple steps described below. Clone the repository to your local machine. Have the latest version of Python 3.6 installed, which can be downloaded from here . Add the following two paths to your Windows Path user environment variable: C:\\Users\\YourUserName\\AppData\\Local\\Programs\\Python\\Python36-32 C:\\Users\\YourUserName\\AppData\\Local\\Programs\\Python\\Python36-32\\Scripts Now, run any shell script ( cmd , git-bash or PowerShell ) and install/upgrade mkdocs and related packages: 1 pip install -U mkdocs mkdocs-material fontawesome-markdown pymdown-extensions","title":"Installing prerequisites"},{"location":"engine/start/#project-layout","text":"1 2 3 4 5 mkdocs.yml # The configuration file docs/ index.md # The documentation homepage ... # Other markdown pages, and other files /images # Images used in the documents","title":"Project Layout"},{"location":"engine/start/#running-the-project-in-dev","text":"Open the command prompt in the project root directory and type: 1 mkdocs serve Or, if you need to run it on a specific port, e.g. 8080, you can do one of the following: 1 2 mkdocs serve --dev-addr:8080 mkdocs serve -a :8080 Then open your browser and navigate to http://localhost:8000 or whatever port number you have configured.","title":"Running the project in DEV"},{"location":"engine/start/#useful-commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Useful Commands"},{"location":"engine/start/#fontawesome","text":"Up to Python 3.4? Python versions above 3.4 are probably not supported yet. See the setup.py file for the classifiers section, it mentions Python versions up to 3.4. Does not work on my website (yet) FontAwesome Markdown does not work on this documentation website. I am trying to figure out why but so far no success. FontAwesome gives you scalable vector icons that can instantly be customized \u2013 size, color, drop shadow, and anything that can be done with the power of CSS. For more inpiration see these examples . FontAwesome Markdown is a Markdown extension that looks for things like :fa-coffee: ( ) or :fa-beer: ( ) and replaces them with the FontAwesome icon markup.","title":"FontAwesome"},{"location":"engine/start/#examples","text":"This example uses the fontawesome_markdown extension: 1 What would you drink, :fa-coffee: or :fa-beer:? What would you drink, or ? For this example, you must install the fontawesome_markdown extension with pip . Right now version 0.2.5 is the latest but it doesn\u2019t work out of the box. Instead, you have to install the latest version from the github repository. You can do that with the command below: 1 pip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip You may need to include -U in the above command if you already have this extension installed. Then add the below to your mkdocs.yml file. 1 2 markdown_extensions: - fontawesome_markdown","title":"Examples"},{"location":"engine/start/#deployment-to-github-pages","text":"","title":"Deployment to GitHub Pages"},{"location":"engine/start/#direct-deployment","text":"To publish the project to GitHub Pages as a subdomain, e.g. /mdocs of the main website, you need first to create a repository with that name, e.g. mdocs and add it to your project as a remote. Next make sure you have a gh-pages branch that exists. If it doesn\u2019t: 1 2 3 git checkout -b gh-pages git rm -rf . git push --set-upstream origin gh-pages Now, open the command prompt in the root directory (on the master branch) and type: 1 mkdocs gh-deploy This will push the master branch to the remote gh-pages . After that, the project website is available at your-github-login.github.io/mdocs .","title":"Direct Deployment"},{"location":"engine/start/#travis-ci-deployment","text":"Go to your GitHub account and create a new Personal access token in your Developer settings. Copy the hash string. Keep well the hash string! You will see it only once when you create it. In the Travis CI settings of your project add a new GITHUB_TOKEN environment variable with the value of the hash string your have just copied. Don\u2019t forget to turn in ON and to ADD . Configure the .travis.yml file. You may start with something like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 sudo : false language : python python : '3.6' install : - pip install -U pip - pip install -r requirements.txt - pip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip script : - git config credential.helper \"store --file=.git/credentials\" - echo \"https://${GITHUB_TOKEN}:@github.com\" > .git/credentials - mkdocs build --verbose --clean --strict - if [ $TRAVIS_TEST_RESULT == 0 ]; then mkdocs gh-deploy --force; fi The credentials here are necessary for the Travis agent to be able to connect to your Github repository and perform the necessary actions with it. Note that the credentials are based on the Personal access token you have created. Also, I have put deployment inside the script fase instead of after_success as a workaround (see the tip of Chronial on this Travis issue #758 ). Otherwise, the batch succeeds with a successful build even if deploy fails after it. Next, you need to have travis Rubygem installed on your local machine. If not, install it: 1 gem install travis Using travis , add the encrypted token to .travis.yml : 1 travis encrypt GITHUB_TOKEN = \"the-token-from-github\" --add This will add the following block at the end of the file: 1 2 3 env : global : - secure : \"lots-of-seemingly-random-characters\" Now, when you push your changes to the remote master , Travis CI should publish the compiled website to GitHub Pages if the build succeeds.","title":"Travis CI Deployment"},{"location":"engine/start/#references","text":"Here are the most important links that have inspired me: Latest official MkDocs documentation MkDocs User Guide","title":"References"},{"location":"engine/styling/","text":"Custom Styling \u00b6 Theme Customization \u00b6 A lot can be found on the main website itself. The color table to choose the main and accent colors can be found on the Getting Started page. Themes \u00b6 MkDocs Themes 12 Bootswatch themes Cinder theme Alabaster theme (quite simple) Bootstrap theme Custom Theme \u00b6 Note If you are looking for third party themes, they are listed in the MkDocs community wiki . It is possible to add extra customization via a Custom Theme option. create custom_theme and custom_theme/css directories parallel to the docs directory inside the custom_theme/css directory create extra.less file with your styles use any LESS compiler to compile the extra.less file to the minified extra.min.css and its map extra.min.css.map add the following lines to mkdoc.yml under the theme variable: 1 2 3 4 theme theme_dir : custom_theme extra_css : - css/extra.min.css now when you build and serve the website, you should see the custom styling in action Similarly, it is possible to add extra JavaScript inside the custom_theme/js directory. You add the corresponding setting to the mkdocs.yml file: 1 2 3 4 theme theme_dir : custom_theme extra_javascript : - js/your-js-file.min.js The 10 Tips for Writing JavaScript without jQuery article is a good read to write custom JavaScript without using jQuery. Extensions \u00b6 Admonition \u00b6 Admonition extension for the MkDocs Markdown provides for a way to draw attention of the reader. In order to use this extension Syntax \u00b6 1 2 !!! special_word \"some text within double quotes\" Any number of lines aligned with the special_word 3 exclamation marks ( !!! ) at the beginning of the line 1 space 1 special word (see below) 1 space (optional) some text within double quotes (optional) 1 empty line (optional) any number of lines beginning at pos. 4 (aligned with the special word after the exclamation marks) Special words \u00b6 These special words result in a colored adminition blocks. It is nice to experiment with them. note , seealso - light blue important , hint , tip - green warning , caution , attention - beige/brown danger , error - pink/red Note The special word can be also any other word. In that case, the color will always be light blue. Examples \u00b6 A custom text message on the first line\u2026 \u00b6 1 2 3 4 !!! note \"Explicit title within double quotes\" Any number of other indented markdown elements. And this is the second paragraph. \u2026replaces the 1 st word: Explicit title within double quotes Any number of other indented markdown elements. And this is the second paragraph. Any single word on the first line\u2026 \u00b6 1 2 3 !!! hint You should note that the title will be automatically capitalized. \u2026will be capitalized: Hint You should note that the title will be automatically capitalized. The empty custom title\u2026 \u00b6 1 2 3 !!! warning \"\" This is an admonition box without a title. \u2026results in no title: This is an admonition box without a title. The word \u201cdanger\u201d plus custom title\u2026 \u00b6 1 2 3 !!! danger \"Don't try this at home\" Or you will regret it for the rest of your life! \u2026results in the red background: Don\u2019t try this at home Or you will regret it for the rest of your life! SmartyPants \u00b6 Adding 1 2 - smarty : smart_angled_quotes : true to markdown_extentions gives you the possibility to print out nicely looking ASCII dashes, quotes and ellipes: you write you get 'single quotes' \u2018single quotes\u2019 \"double qoutes\" \u201cdouble qoutes\u201d <<angled quotes>> \u00abangled quotes\u00bb ... ellipsis \u2026 ellipsis -- ndash \u2013 ndash --- mdash \u2014 mdash nl2br extension \u00b6 Adding 1 - nl2br to markdown_extentions creates a newline within fences when you make a newline in Markdown. You type: 1 2 line 1 line 2 Without nl2br you see this: 1 line 1 line 2 With nl2br you see this: 1 2 line 1 line 2 Lato Font \u00b6 This font is one of the free Google fonts: Lato Google Font . In order to use it, the following line should be added to the /spreadsheets/extra.css file: 1 @ import url ( 'https://fonts.googleapis.com/css?family=Lato' ) ;","title":"Custom Styling"},{"location":"engine/styling/#custom-styling","text":"","title":"Custom Styling"},{"location":"engine/styling/#theme-customization","text":"A lot can be found on the main website itself. The color table to choose the main and accent colors can be found on the Getting Started page.","title":"Theme Customization"},{"location":"engine/styling/#themes","text":"MkDocs Themes 12 Bootswatch themes Cinder theme Alabaster theme (quite simple) Bootstrap theme","title":"Themes"},{"location":"engine/styling/#custom-theme","text":"Note If you are looking for third party themes, they are listed in the MkDocs community wiki . It is possible to add extra customization via a Custom Theme option. create custom_theme and custom_theme/css directories parallel to the docs directory inside the custom_theme/css directory create extra.less file with your styles use any LESS compiler to compile the extra.less file to the minified extra.min.css and its map extra.min.css.map add the following lines to mkdoc.yml under the theme variable: 1 2 3 4 theme theme_dir : custom_theme extra_css : - css/extra.min.css now when you build and serve the website, you should see the custom styling in action Similarly, it is possible to add extra JavaScript inside the custom_theme/js directory. You add the corresponding setting to the mkdocs.yml file: 1 2 3 4 theme theme_dir : custom_theme extra_javascript : - js/your-js-file.min.js The 10 Tips for Writing JavaScript without jQuery article is a good read to write custom JavaScript without using jQuery.","title":"Custom Theme"},{"location":"engine/styling/#extensions","text":"","title":"Extensions"},{"location":"engine/styling/#admonition","text":"Admonition extension for the MkDocs Markdown provides for a way to draw attention of the reader. In order to use this extension","title":"Admonition"},{"location":"engine/styling/#syntax","text":"1 2 !!! special_word \"some text within double quotes\" Any number of lines aligned with the special_word 3 exclamation marks ( !!! ) at the beginning of the line 1 space 1 special word (see below) 1 space (optional) some text within double quotes (optional) 1 empty line (optional) any number of lines beginning at pos. 4 (aligned with the special word after the exclamation marks)","title":"Syntax"},{"location":"engine/styling/#special-words","text":"These special words result in a colored adminition blocks. It is nice to experiment with them. note , seealso - light blue important , hint , tip - green warning , caution , attention - beige/brown danger , error - pink/red Note The special word can be also any other word. In that case, the color will always be light blue.","title":"Special words"},{"location":"engine/styling/#examples","text":"","title":"Examples"},{"location":"engine/styling/#a-custom-text-message-on-the-first-line","text":"1 2 3 4 !!! note \"Explicit title within double quotes\" Any number of other indented markdown elements. And this is the second paragraph. \u2026replaces the 1 st word: Explicit title within double quotes Any number of other indented markdown elements. And this is the second paragraph.","title":"A custom text message on the first line..."},{"location":"engine/styling/#any-single-word-on-the-first-line","text":"1 2 3 !!! hint You should note that the title will be automatically capitalized. \u2026will be capitalized: Hint You should note that the title will be automatically capitalized.","title":"Any single word on the first line..."},{"location":"engine/styling/#the-empty-custom-title","text":"1 2 3 !!! warning \"\" This is an admonition box without a title. \u2026results in no title: This is an admonition box without a title.","title":"The empty custom title..."},{"location":"engine/styling/#the-word-danger-plus-custom-title","text":"1 2 3 !!! danger \"Don't try this at home\" Or you will regret it for the rest of your life! \u2026results in the red background: Don\u2019t try this at home Or you will regret it for the rest of your life!","title":"The word \"danger\" plus custom title..."},{"location":"engine/styling/#smartypants","text":"Adding 1 2 - smarty : smart_angled_quotes : true to markdown_extentions gives you the possibility to print out nicely looking ASCII dashes, quotes and ellipes: you write you get 'single quotes' \u2018single quotes\u2019 \"double qoutes\" \u201cdouble qoutes\u201d <<angled quotes>> \u00abangled quotes\u00bb ... ellipsis \u2026 ellipsis -- ndash \u2013 ndash --- mdash \u2014 mdash","title":"SmartyPants"},{"location":"engine/styling/#nl2br-extension","text":"Adding 1 - nl2br to markdown_extentions creates a newline within fences when you make a newline in Markdown. You type: 1 2 line 1 line 2 Without nl2br you see this: 1 line 1 line 2 With nl2br you see this: 1 2 line 1 line 2","title":"nl2br extension"},{"location":"engine/styling/#lato-font","text":"This font is one of the free Google fonts: Lato Google Font . In order to use it, the following line should be added to the /spreadsheets/extra.css file: 1 @ import url ( 'https://fonts.googleapis.com/css?family=Lato' ) ;","title":"Lato Font"},{"location":"engine/technicalities/","text":"Technical Information \u00b6 Installing prerequisites \u00b6 if you want to create your own project like this one, you need to have the latest version of Python 2.7 installed, which can be downloaded from here . After that, install mkdocs and related packages: 1 2 3 pip install -U mkdocs mkdocs-material pip install -U fontawesome-markdown pip install -U pygments pymdown-extensions Project Layout \u00b6 1 2 3 4 5 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, and other files. /images # Images used in the documents Running the project in DEV \u00b6 Open the command prompt in the project root directory and type: 1 mkdocs serve Or, if you need to run it on a specific port, e.g. 8080, you can do one of the following: 1 2 mkdocs serve --dev-addr:8080 mkdocs serve -a :8080 Then open your browser and navigate to http://localhost:8000 or whatever port number you have configured. Some Useful Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Font Awesome \u00b6 Font Awesome gives you scalable vector icons that can instantly be customized \u2013 size, color, drop shadow, and anything that can be done with the power of CSS. For more inpiration see these examples . Font Awesome Markdown is a Markdown extension that looks for things like :fa-coffee: ( ) or :fa-beer: ( ) and replaces them with the Font Awesome icon markup. Examples \u00b6 This examples use the fontawesome_markdown extension: 1 What would you drink, :fa-coffee: or :fa-beer: ? What would you drink, or ? For this example, you must install the fontawesome_markdown extension with pip or install the latest version directly from the github repository: 1 pip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip You may need to include -U in the above command if you already have this extension installed. Then add the below to your mkdocs.yml file. 1 2 markdown_extensions : - fontawesome_markdown In my case, this appeared to be not enough. I had to add the link to the Font Awesome stylesheet inside the main.html of my custom theme: 1 2 3 4 5 6 7 8 {% extends \"base.html\" %} {% block styles %} {{ super() }} ... < link rel = \"stylesheet\" href = \"https://use.fontawesome.com/releases/v5.6.3/css/all.css\" integrity = \"sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/\" crossorigin = \"anonymous\" > {% endblock %} Deployment \u00b6 Deployment to GitHub Pages directly \u00b6 To publish the project to GitHub Pages as a subdomain, e.g. /mdocs of the main website, you need first to create a repository with that name, e.g. mdocs and add it to your project as a remote. Next make sure you have a gh-pages branch that exists. If it doesn\u2019t: 1 2 3 git checkout -b gh-pages git rm -rf . git push --set-upstream origin gh-pages Now, open the command prompt in the root directory (on the master branch) and type: 1 mkdocs gh-deploy This will push the master branch to the remote gh-pages . After that, the project website is available at . Deployment to GitHub pages via Travis CI \u00b6 Go to your GitHub account and create a new Personal access token in your Developer settings. Copy the hash string. Keep well the hash string! You will see it only once when you create it. In the Travis CI settings of your project add a new GITHUB_TOKEN environment variable with the value of the hash string your have just copied. Don\u2019t forget to turn in ON and to ADD . Configure the .travis.yml file. You may start with something like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 sudo : false language : python python : '2.7' install : - pip install --upgrade pip - pip install -r requirements.txt - pip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip script : - git config credential.helper \"store --file=.git/credentials\" - echo \"https://${GITHUB_TOKEN}:@github.com\" > .git/credentials - mkdocs build - if [ $TRAVIS_TEST_RESULT == 0 ]; then mkdocs gh-deploy --force; fi The credentials here are necessary for the Travis agent to be able to connect to your Github repository and perform the necessary actions with it. Note that the credentials are based on the Personal access token you have created. Also, I have put deployment inside the script fase instead of after_success as a workaround (see the tip of Chronial on this Travis issue #758 ). Otherwise, the batch succeeds with a successful build even if deploy fails after it. Next, you need to have travis Rubygem installed on your local machine. If not, install it: 1 gem install travis Using travis , add the encrypted token to .travis.yml : 1 travis encrypt GITHUB_TOKEN = \"the-token-from-github\" --add This will add the following block at the end of the file: 1 2 3 env : global : - secure : \"lots-of-seemingly-random-characters\" Now, when you push your changes to the remote master , Travis CI should publish the compiled website to GitHub Pages if the build succeeds.","title":"Technicalities"},{"location":"engine/technicalities/#technical-information","text":"","title":"Technical Information"},{"location":"engine/technicalities/#installing-prerequisites","text":"if you want to create your own project like this one, you need to have the latest version of Python 2.7 installed, which can be downloaded from here . After that, install mkdocs and related packages: 1 2 3 pip install -U mkdocs mkdocs-material pip install -U fontawesome-markdown pip install -U pygments pymdown-extensions","title":"Installing prerequisites"},{"location":"engine/technicalities/#project-layout","text":"1 2 3 4 5 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, and other files. /images # Images used in the documents","title":"Project Layout"},{"location":"engine/technicalities/#running-the-project-in-dev","text":"Open the command prompt in the project root directory and type: 1 mkdocs serve Or, if you need to run it on a specific port, e.g. 8080, you can do one of the following: 1 2 mkdocs serve --dev-addr:8080 mkdocs serve -a :8080 Then open your browser and navigate to http://localhost:8000 or whatever port number you have configured.","title":"Running the project in DEV"},{"location":"engine/technicalities/#some-useful-commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Some Useful Commands"},{"location":"engine/technicalities/#font-awesome","text":"Font Awesome gives you scalable vector icons that can instantly be customized \u2013 size, color, drop shadow, and anything that can be done with the power of CSS. For more inpiration see these examples . Font Awesome Markdown is a Markdown extension that looks for things like :fa-coffee: ( ) or :fa-beer: ( ) and replaces them with the Font Awesome icon markup.","title":"Font Awesome"},{"location":"engine/technicalities/#examples","text":"This examples use the fontawesome_markdown extension: 1 What would you drink, :fa-coffee: or :fa-beer: ? What would you drink, or ? For this example, you must install the fontawesome_markdown extension with pip or install the latest version directly from the github repository: 1 pip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip You may need to include -U in the above command if you already have this extension installed. Then add the below to your mkdocs.yml file. 1 2 markdown_extensions : - fontawesome_markdown In my case, this appeared to be not enough. I had to add the link to the Font Awesome stylesheet inside the main.html of my custom theme: 1 2 3 4 5 6 7 8 {% extends \"base.html\" %} {% block styles %} {{ super() }} ... < link rel = \"stylesheet\" href = \"https://use.fontawesome.com/releases/v5.6.3/css/all.css\" integrity = \"sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/\" crossorigin = \"anonymous\" > {% endblock %}","title":"Examples"},{"location":"engine/technicalities/#deployment","text":"","title":"Deployment"},{"location":"engine/technicalities/#deployment-to-github-pages-directly","text":"To publish the project to GitHub Pages as a subdomain, e.g. /mdocs of the main website, you need first to create a repository with that name, e.g. mdocs and add it to your project as a remote. Next make sure you have a gh-pages branch that exists. If it doesn\u2019t: 1 2 3 git checkout -b gh-pages git rm -rf . git push --set-upstream origin gh-pages Now, open the command prompt in the root directory (on the master branch) and type: 1 mkdocs gh-deploy This will push the master branch to the remote gh-pages . After that, the project website is available at .","title":"Deployment to GitHub Pages directly"},{"location":"engine/technicalities/#deployment-to-github-pages-via-travis-ci","text":"Go to your GitHub account and create a new Personal access token in your Developer settings. Copy the hash string. Keep well the hash string! You will see it only once when you create it. In the Travis CI settings of your project add a new GITHUB_TOKEN environment variable with the value of the hash string your have just copied. Don\u2019t forget to turn in ON and to ADD . Configure the .travis.yml file. You may start with something like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 sudo : false language : python python : '2.7' install : - pip install --upgrade pip - pip install -r requirements.txt - pip install https://github.com/bmcorser/fontawesome-markdown/archive/master.zip script : - git config credential.helper \"store --file=.git/credentials\" - echo \"https://${GITHUB_TOKEN}:@github.com\" > .git/credentials - mkdocs build - if [ $TRAVIS_TEST_RESULT == 0 ]; then mkdocs gh-deploy --force; fi The credentials here are necessary for the Travis agent to be able to connect to your Github repository and perform the necessary actions with it. Note that the credentials are based on the Personal access token you have created. Also, I have put deployment inside the script fase instead of after_success as a workaround (see the tip of Chronial on this Travis issue #758 ). Otherwise, the batch succeeds with a successful build even if deploy fails after it. Next, you need to have travis Rubygem installed on your local machine. If not, install it: 1 gem install travis Using travis , add the encrypted token to .travis.yml : 1 travis encrypt GITHUB_TOKEN = \"the-token-from-github\" --add This will add the following block at the end of the file: 1 2 3 env : global : - secure : \"lots-of-seemingly-random-characters\" Now, when you push your changes to the remote master , Travis CI should publish the compiled website to GitHub Pages if the build succeeds.","title":"Deployment to GitHub pages via Travis CI"},{"location":"git/gitdiff/","text":"How to solve Git differences \u00b6 https://developer.atlassian.com/blog/2015/12/tips-tools-to-solve-git-conflicts/","title":"GitDiff"},{"location":"git/gitdiff/#how-to-solve-git-differences","text":"https://developer.atlassian.com/blog/2015/12/tips-tools-to-solve-git-conflicts/","title":"How to solve Git differences"},{"location":"git/gitflow/","text":"Introduction Installation Prerequisites Prepare the GitFlow local repository Install GitFlow Test GitFlow installation Introduction \u00b6 GitFlow is a Git Workflow Extension. The following diagram gives a good idea how it works. Installation \u00b6 Prerequisites \u00b6 Make sure you have Git installed. Note the path to the Git directory. In this manual, we will use C:\\Program Files\\Git . Prepare the GitFlow local repository \u00b6 External dependencies Submodule dependency on shFlags 3 files from the util-linux-package Go to the util-linux-ng for Windows website. Download the Binaries and Dependencies in zip-format. Retrieve getopt.exe file from the bin folder in the Binaries . Retrieve libintl3.dll , and libiconv2.dll from the bin folder in the Dependencies packages. (This link has them all in one place.) Copy all three files to the bin folder of your Git installation, e.g. C:\\Program Files\\Git\\bin . Open an Administrator command window and run these commands (make sure you also get the right diagnostic messages): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 git clone https://github.com/nvie/gitflow.git cd gitflow git submodule -2fb06af13de884e9680f14a00c82e52a67c867f1 shFlags git submodule init Submodule 'shFlags' ( git://github.com/nvie/shFlags.git ) registered for path 'shFlags' git submodule update Cloning into 'shFlags' ... remote: Counting objects: 454 , done . remote: Compressing objects: 100 % ( 55 /55 ) , done . remote: Total 454 ( delta 389 ) , reused 454 ( delta 389 ) Receiving objects: 100 % ( 454 /454 ) , 101 .19 KiB, done . Resolving deltas: 100 % ( 389 /389 ) , done . Submodule path 'shFlags' : checked out '2fb06af13de884e9680f14a00c82e52a67c867f1' git submodule status 2fb06af13de884e9680f14a00c82e52a67c867f1 shFlags ( 1 .0.3 ) Install GitFlow \u00b6 Run the following commands with the correct path to your Git installation: 1 2 cd contrib msysgit-install.cmd \"C:\\Program Files\\Git\" Test GitFlow installation \u00b6 Test the installation by running 1 git flow help You should see something like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 usage: git flow <subcommand> Available subcommands are: init Initialize a new git repo with support for the branching model. feature Manage your feature branches. bugfix Manage your bugfix branches. release Manage your release branches. hotfix Manage your hotfix branches. support Manage your support branches. version Shows version information. config Manage your git-flow configuration. log Show log deviating from base branch. Try 'git flow <subcommand> help' for details.","title":"GitFlow"},{"location":"git/gitflow/#introduction","text":"GitFlow is a Git Workflow Extension. The following diagram gives a good idea how it works.","title":"Introduction"},{"location":"git/gitflow/#installation","text":"","title":"Installation"},{"location":"git/gitflow/#prerequisites","text":"Make sure you have Git installed. Note the path to the Git directory. In this manual, we will use C:\\Program Files\\Git .","title":"Prerequisites"},{"location":"git/gitflow/#prepare-the-gitflow-local-repository","text":"External dependencies Submodule dependency on shFlags 3 files from the util-linux-package Go to the util-linux-ng for Windows website. Download the Binaries and Dependencies in zip-format. Retrieve getopt.exe file from the bin folder in the Binaries . Retrieve libintl3.dll , and libiconv2.dll from the bin folder in the Dependencies packages. (This link has them all in one place.) Copy all three files to the bin folder of your Git installation, e.g. C:\\Program Files\\Git\\bin . Open an Administrator command window and run these commands (make sure you also get the right diagnostic messages): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 git clone https://github.com/nvie/gitflow.git cd gitflow git submodule -2fb06af13de884e9680f14a00c82e52a67c867f1 shFlags git submodule init Submodule 'shFlags' ( git://github.com/nvie/shFlags.git ) registered for path 'shFlags' git submodule update Cloning into 'shFlags' ... remote: Counting objects: 454 , done . remote: Compressing objects: 100 % ( 55 /55 ) , done . remote: Total 454 ( delta 389 ) , reused 454 ( delta 389 ) Receiving objects: 100 % ( 454 /454 ) , 101 .19 KiB, done . Resolving deltas: 100 % ( 389 /389 ) , done . Submodule path 'shFlags' : checked out '2fb06af13de884e9680f14a00c82e52a67c867f1' git submodule status 2fb06af13de884e9680f14a00c82e52a67c867f1 shFlags ( 1 .0.3 )","title":"Prepare the GitFlow local repository"},{"location":"git/gitflow/#install-gitflow","text":"Run the following commands with the correct path to your Git installation: 1 2 cd contrib msysgit-install.cmd \"C:\\Program Files\\Git\"","title":"Install GitFlow"},{"location":"git/gitflow/#test-gitflow-installation","text":"Test the installation by running 1 git flow help You should see something like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 usage: git flow <subcommand> Available subcommands are: init Initialize a new git repo with support for the branching model. feature Manage your feature branches. bugfix Manage your bugfix branches. release Manage your release branches. hotfix Manage your hotfix branches. support Manage your support branches. version Shows version information. config Manage your git-flow configuration. log Show log deviating from base branch. Try 'git flow <subcommand> help' for details.","title":"Test GitFlow installation"},{"location":"git/ssh/","text":"Requirements Manage SSH keys on your local Windows machine Add a new SSH key via PUTTYGEN Add a new SSH key via SSH-KEYGEN Add config file for SSH Test the connection How to clone the remote private repo via SSH Requirements \u00b6 The latest (full) version of Git Extenstions is installed git --version shows no errors; if not, add the location of the Git folder to the PATH There exists the GIT_SSH Windows environment variable (necessary for plink ): C:\\Program Files (x86)\\GitExtensions\\PuTTY PuTTY directory is on the system PATH : C:\\Program Files (x86)\\GitExtensions\\PuTTY where ssh command shows the location of ssh.exe ; if not, add the location of the Git\\usr\\bin folder to the system PATH Manage SSH keys on your local Windows machine \u00b6 SSH keys are stored locally in %USERPROFILE%/.ssh directory. If it does not exist, create one. Add a new SSH key via PUTTYGEN \u00b6 Open your command prompt and type puttygen . This will open the generator screen. Click Generate to generate a new key and move your mouse across the white area. Type in the passphrase ( remember it wel! ) and save the private key to %USERPROFILE%\\.ssh directory as id_rsa.ppk . Also, save the OpenSSH version of the key as id_rsa file via the top menu Conversions -> Export OpenSSH key . Add a new SSH key via SSH-KEYGEN \u00b6 Alternatively, you can generate the key via ssh-keygen command Save the key as id_rsa file in .ssh directory Open puttygen and load the generated key Save the corresponding private key as above for Puttygen Add config file for SSH \u00b6 In your .ssh directory create an empty config textfile (no extension) For your remote host, e.g. BitBucket, add the configuration information. It will look something like this: 1 2 3 4 5 Host BITBUCKET Hostname bitbucket.org User your-user-name-on-bitbucket PubKeyAuthentication yes IdentityFile id_rsa Test the connection \u00b6 run ssh -T git@bitbucket.org you may see something like this: 1 2 3 4 5 key_load_public: invalid format Enter passphrase for key '/c/Users/Andre/.ssh/id_rsa': logged in as Madrusnl. You can use git or hg to connect to Bitbucket. Shell access is disabled. you may ignore the invalid format error if you see the rest otherwise you can do some troubleshooting : use -vvv option: ssh -T git@bitbucket.org -vvv make sure you have registered your PUBLIC key (.pub) on the (BitBucket) server make sure your IdentiyFile variable in the config file points to your PRIVATE key (without extension). How to clone the remote private repo via SSH \u00b6 make sure you have the private key for the remote repo in .ssh folder, e.g. id_rsa.ppk (otherwise create it as described hereabove) create the local folder to which you wish to clone the remote repo initialize the empty git repo in it by git init open the repo with Git Extensions in its menu, go to Repository , Remote repositories... and create a new remote repository. Call it origin (or any other name you like). Copy the SSH url of the BitBucket repo and paste it in the Url field For the PuTTY SSH field, browse to the private key in .ssh directory and pick it up Click on Load SSH key and type in your passphrase for the private key Test connection with Test connection If everything is ok, save changes and close Click on the light blue down arrow, choose Pull , fill in the right remote branch, e.g. master and choose Merge remote branch into current branch Click the Pull button If everything went fine, you should now see the branch tree with all the commits","title":"Set up SSH"},{"location":"git/ssh/#requirements","text":"The latest (full) version of Git Extenstions is installed git --version shows no errors; if not, add the location of the Git folder to the PATH There exists the GIT_SSH Windows environment variable (necessary for plink ): C:\\Program Files (x86)\\GitExtensions\\PuTTY PuTTY directory is on the system PATH : C:\\Program Files (x86)\\GitExtensions\\PuTTY where ssh command shows the location of ssh.exe ; if not, add the location of the Git\\usr\\bin folder to the system PATH","title":"Requirements"},{"location":"git/ssh/#manage-ssh-keys-on-your-local-windows-machine","text":"SSH keys are stored locally in %USERPROFILE%/.ssh directory. If it does not exist, create one.","title":"Manage SSH keys on your local Windows machine"},{"location":"git/ssh/#add-a-new-ssh-key-via-puttygen","text":"Open your command prompt and type puttygen . This will open the generator screen. Click Generate to generate a new key and move your mouse across the white area. Type in the passphrase ( remember it wel! ) and save the private key to %USERPROFILE%\\.ssh directory as id_rsa.ppk . Also, save the OpenSSH version of the key as id_rsa file via the top menu Conversions -> Export OpenSSH key .","title":"Add a new SSH key via PUTTYGEN"},{"location":"git/ssh/#add-a-new-ssh-key-via-ssh-keygen","text":"Alternatively, you can generate the key via ssh-keygen command Save the key as id_rsa file in .ssh directory Open puttygen and load the generated key Save the corresponding private key as above for Puttygen","title":"Add a new SSH key via SSH-KEYGEN"},{"location":"git/ssh/#add-config-file-for-ssh","text":"In your .ssh directory create an empty config textfile (no extension) For your remote host, e.g. BitBucket, add the configuration information. It will look something like this: 1 2 3 4 5 Host BITBUCKET Hostname bitbucket.org User your-user-name-on-bitbucket PubKeyAuthentication yes IdentityFile id_rsa","title":"Add config file for SSH"},{"location":"git/ssh/#test-the-connection","text":"run ssh -T git@bitbucket.org you may see something like this: 1 2 3 4 5 key_load_public: invalid format Enter passphrase for key '/c/Users/Andre/.ssh/id_rsa': logged in as Madrusnl. You can use git or hg to connect to Bitbucket. Shell access is disabled. you may ignore the invalid format error if you see the rest otherwise you can do some troubleshooting : use -vvv option: ssh -T git@bitbucket.org -vvv make sure you have registered your PUBLIC key (.pub) on the (BitBucket) server make sure your IdentiyFile variable in the config file points to your PRIVATE key (without extension).","title":"Test the connection"},{"location":"git/ssh/#how-to-clone-the-remote-private-repo-via-ssh","text":"make sure you have the private key for the remote repo in .ssh folder, e.g. id_rsa.ppk (otherwise create it as described hereabove) create the local folder to which you wish to clone the remote repo initialize the empty git repo in it by git init open the repo with Git Extensions in its menu, go to Repository , Remote repositories... and create a new remote repository. Call it origin (or any other name you like). Copy the SSH url of the BitBucket repo and paste it in the Url field For the PuTTY SSH field, browse to the private key in .ssh directory and pick it up Click on Load SSH key and type in your passphrase for the private key Test connection with Test connection If everything is ok, save changes and close Click on the light blue down arrow, choose Pull , fill in the right remote branch, e.g. master and choose Merge remote branch into current branch Click the Pull button If everything went fine, you should now see the branch tree with all the commits","title":"How to clone the remote private repo via SSH"},{"location":"git/styling/","text":"Powerline Fonts Cmder Main Font Color Scheme Powerline Fonts \u00b6 Taken from the Powerline fonts repository. Start by cloning: 1 2 git clone https://github.com/powerline/fonts.git cd fonts In bash prompt install the fonts like this: 1 ./install.sh and in Powershell as Administrator like this: 1 ./install.ps1 Install for Python: 1 pip install powerline-status or just for the current user: 1 pip install --user powerline-status Cmder \u00b6 Main Font \u00b6 I like these fonts for the terminal: Roboto Mono for Powerline Droid Sans Mono Slashed for Powerline Anonymice Powerline Color Scheme \u00b6 I like Murena Scheme with some tweaks in Features/Colors : Position Color Code Role 0 0 43 54 screen background color idem 38 42 47 idem \u00bc 0 65 100 path background color 2 60 154 6 clean branch - green 6/3 196 160 0 dirty branch - yellow","title":"Git Prompt Styling"},{"location":"git/styling/#powerline-fonts","text":"Taken from the Powerline fonts repository. Start by cloning: 1 2 git clone https://github.com/powerline/fonts.git cd fonts In bash prompt install the fonts like this: 1 ./install.sh and in Powershell as Administrator like this: 1 ./install.ps1 Install for Python: 1 pip install powerline-status or just for the current user: 1 pip install --user powerline-status","title":"Powerline Fonts"},{"location":"git/styling/#cmder","text":"","title":"Cmder"},{"location":"git/styling/#main-font","text":"I like these fonts for the terminal: Roboto Mono for Powerline Droid Sans Mono Slashed for Powerline Anonymice Powerline","title":"Main Font"},{"location":"git/styling/#color-scheme","text":"I like Murena Scheme with some tweaks in Features/Colors : Position Color Code Role 0 0 43 54 screen background color idem 38 42 47 idem \u00bc 0 65 100 path background color 2 60 154 6 clean branch - green 6/3 196 160 0 dirty branch - yellow","title":"Color Scheme"},{"location":"git/tools/","text":"Handy Tools \u00b6 ConEmu \u00b6 Here is the main link to Conemu website. Show Branch Name on Command Line \u00b6 Run GitShowBranch /i to install showing branch, GitShowBranch /u to uninstall. Also, you may run your cmd as following (within Task contents or ConEmu\u2019s Command line) 1 cmd /k ver & GitShowBranch /i Don\u2019t forget to recreate the console window! If you changed the command line in the settings, you have to completely recreate the console window. Otherwise, you will not see the changes. Add ConEmu to the Windows context menu \u00b6 It is convenient to be able to open the ConEmu console at the current location. You would then want to be able to either right click either on the folder itself, or right click inside the white area within the folder open in the Windows Explorer . Create (if not already created by the ConEmu installation itself) the same group of keys and string values in the Windows Registry in the following two locations respectively: HCR/Directory/shell HCR/Directory/Background/shell Key: ConEmu Here Name Type Data (Default) REG_SZ (value not set) Icon REG_SZ C:\\Program Files\\ConEmu\\ConEmu64.exe,0 Subkey: command Name Type Data (Default) REG_SZ \"C:\\Program Files\\ConEmu\\ConEmu64.exe\" -here -run {cmd} -cur_console:n You can also create the Admin version of the same command with minimal changes: Key: ConEmu Here (Admin) replace :n with :a at the end of the command Data value: -cur_console:a TODO It would also be nice to be able to open the ConEmu folder from within the Far Manager window. Cmder \u00b6 This tool combines most of the features of Conemu and Clink . Environment variables \u00b6 No spaces in the path names! Make sure there are no spaces in the path. If necessary, substitute those paths with their short versions. You can find them by running dir /X in their parent directory. Add the following environment system variables to Windows according to your specific situation: CMDER_ROOT = C:\\PROGRA~1\\Cmder Add the path to Cmder.exe to the PATH variable: C:\\PROGRA~1\\Cmder Shortcut to open Cmder in a chosen folder \u00b6 Open a terminal as an Administrator Navigate to the directory in which you have placed Cmder Execute .\\cmder.exe /REGISTER ALL . If you get \u201cAccess Denied\u201d ensure you are executing the command in an Administrator prompt In the Windows explorer window right click in or on a directory to see Cmder Here in the context menu. Configuring Tasks \u00b6 Here is a good example of how to configure the environment for editing files not related to Visual Studio and .NET. Another neat functionality are customized Tasks. Use those to store different project workspaces. One task equals one workspace. Thanks to that it is possible to easily start another \u2018project\u2019 and initialize it by opening specific folders and specific files in Vim. It is a lot faster than doing everything manually. In the Settings navigate to Startup -> Tasks and create a new predefined task with a \u201c+\u201d sign. Then add this code: 1 2 3 4 -new_console:d:C: \\U sers \\m franc \\D ropbox \"%ProgramFiles(x86)%\\Vim\\vim80\\vim.exe\" /k -new_console:d:D: \\ \"%ProgramFiles%\\Vim\\vim74\\vim.exe\" /k -cur_console:n -cur_console:d:D: \\ \"%ProgramFiles%\\Git\\bin\\sh.exe\" --login -i -cur_console:n:sT25V -cur_console:d:D: \\ \"%ProgramFiles%\\Git\\bin\\sh.exe\" --login -i cur_console:n:sT66H cmd.exe -new_console:d:D: \\ -i -cur_console:n:sT50H What those commands do \u00b6 Creates new screen and opens Vim in my Dropbox folder context Creates new screen with Vim pointing to D:\\ Initializes shell in this new window and splits current screen into 75%/25% horizontaly Initializes shell in new (25%) window and splits it up into 33.3%/66.6% vertically . Then initializes shell in the new (66.6%) window and splits it up into 50%/50% vertically . Aliases \u00b6 You can create an alias to any command by an alias command, e.g.: 1 alias push = git push -u $* No space in between! Make sure there is no space between the alias and the equality sign = Undo the alias by unalias push . The aliases can be found in config subdirectory of the cmder install directory in the user-aliases.cmd file or by running alias command with no parameters. Standard Aliases \u00b6 cmderr - open cmder window in the cmder install directory, e.g. C:\\Program Files\\Cmder history - show latest commands How to update ConEmu within Cmder \u00b6 Maximus5 , the author of Cmder, explains how to update ConEmu to a new version. Current Cmder can contain an older ConEmu version. To update ConEmu, get the new package from the ConEmu website and copy its content to \u2018your cmder installation\u2019/vendor/conemu-maximus5 folder. Links \u00b6 Cmder: Super Command Line Tool Window Far Manager \u00b6 Add Far Manager to the Windows context menu \u00b6 It is convenient to be able to open the Far Manager at the current location. You would then want to be able to either right click either on the folder itself, or right click inside the white area within the folder open in the Windows Explorer . Create or rename (if already created by the Far Manager installation) the same group of keys and string values in the Windows Registry in the following two locations respectively: HCR/Directory/shell HCR/Directory/Background/shell Key: Far Here Name Type Data (Default) REG_SZ (value not set) Icon REG_SZ C:\\Program Files\\Far Manager\\Far.exe,0 Subkey: command Name Type Data (Default) REG_SZ \"C:\\Program Files\\Far Manager\\Far.exe\" \"% X \" \"% X \" Replace X with a number! In the shell , replace X with 1 and in the Background/shell with 2 . POSH-GIT for PowerShell \u00b6 POSH-GIT is a PowerShell module that shows the current branch of the git repository and understands git commands. Installation \u00b6 The easiest way is to use PowerShell of Chocolatey. PowerShell \u00b6 1 PowerShellGet \\ Install-Module posh-git -Scope CurrentUser Note: If you get an error message from Install-Module about NuGet being required to interact with NuGet-based repositories, execute the following commands to bootstrap the NuGet provider: 1 2 Install-PackageProvider NuGet -Force Import-PackageProvider NuGet -Force Then retry the Install-Module command above. Chocolatey \u00b6 1 choco install poshgit Updates \u00b6 Update to a newer version by executing the command: 1 Update-Module posh-git How to use \u00b6 Open the PowerShell command prompt and run: 1 Import-Module posh-git If you are lazy to do it every time, add the command to your profile. Here is how. start PowerShell command prompt and run $profile you will see the path and name of your profile file, e.g. C:\\Users\\YourUserName\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1 if this file does not exist, create it add Import-Module posh-git to that file Use it with Integrated Terminal in VS Code \u00b6 Add the following setting to the VS Code User Settings: 1 \"terminal.integrated.shell.windows\" : \"C:\\\\Windows\\\\System 32 \\\\WindowsPowerShell\\\\v 1.0 \\\\powershell.exe, Toggle the Integrated Terminal window with Ctrl + ` .","title":"Git Command Line Tools"},{"location":"git/tools/#handy-tools","text":"","title":"Handy Tools"},{"location":"git/tools/#conemu","text":"Here is the main link to Conemu website.","title":"ConEmu"},{"location":"git/tools/#show-branch-name-on-command-line","text":"Run GitShowBranch /i to install showing branch, GitShowBranch /u to uninstall. Also, you may run your cmd as following (within Task contents or ConEmu\u2019s Command line) 1 cmd /k ver & GitShowBranch /i Don\u2019t forget to recreate the console window! If you changed the command line in the settings, you have to completely recreate the console window. Otherwise, you will not see the changes.","title":"Show Branch Name on Command Line"},{"location":"git/tools/#add-conemu-to-the-windows-context-menu","text":"It is convenient to be able to open the ConEmu console at the current location. You would then want to be able to either right click either on the folder itself, or right click inside the white area within the folder open in the Windows Explorer . Create (if not already created by the ConEmu installation itself) the same group of keys and string values in the Windows Registry in the following two locations respectively: HCR/Directory/shell HCR/Directory/Background/shell Key: ConEmu Here Name Type Data (Default) REG_SZ (value not set) Icon REG_SZ C:\\Program Files\\ConEmu\\ConEmu64.exe,0 Subkey: command Name Type Data (Default) REG_SZ \"C:\\Program Files\\ConEmu\\ConEmu64.exe\" -here -run {cmd} -cur_console:n You can also create the Admin version of the same command with minimal changes: Key: ConEmu Here (Admin) replace :n with :a at the end of the command Data value: -cur_console:a TODO It would also be nice to be able to open the ConEmu folder from within the Far Manager window.","title":"Add ConEmu to the Windows context menu"},{"location":"git/tools/#cmder","text":"This tool combines most of the features of Conemu and Clink .","title":"Cmder"},{"location":"git/tools/#environment-variables","text":"No spaces in the path names! Make sure there are no spaces in the path. If necessary, substitute those paths with their short versions. You can find them by running dir /X in their parent directory. Add the following environment system variables to Windows according to your specific situation: CMDER_ROOT = C:\\PROGRA~1\\Cmder Add the path to Cmder.exe to the PATH variable: C:\\PROGRA~1\\Cmder","title":"Environment variables"},{"location":"git/tools/#shortcut-to-open-cmder-in-a-chosen-folder","text":"Open a terminal as an Administrator Navigate to the directory in which you have placed Cmder Execute .\\cmder.exe /REGISTER ALL . If you get \u201cAccess Denied\u201d ensure you are executing the command in an Administrator prompt In the Windows explorer window right click in or on a directory to see Cmder Here in the context menu.","title":"Shortcut to open Cmder in a chosen folder"},{"location":"git/tools/#configuring-tasks","text":"Here is a good example of how to configure the environment for editing files not related to Visual Studio and .NET. Another neat functionality are customized Tasks. Use those to store different project workspaces. One task equals one workspace. Thanks to that it is possible to easily start another \u2018project\u2019 and initialize it by opening specific folders and specific files in Vim. It is a lot faster than doing everything manually. In the Settings navigate to Startup -> Tasks and create a new predefined task with a \u201c+\u201d sign. Then add this code: 1 2 3 4 -new_console:d:C: \\U sers \\m franc \\D ropbox \"%ProgramFiles(x86)%\\Vim\\vim80\\vim.exe\" /k -new_console:d:D: \\ \"%ProgramFiles%\\Vim\\vim74\\vim.exe\" /k -cur_console:n -cur_console:d:D: \\ \"%ProgramFiles%\\Git\\bin\\sh.exe\" --login -i -cur_console:n:sT25V -cur_console:d:D: \\ \"%ProgramFiles%\\Git\\bin\\sh.exe\" --login -i cur_console:n:sT66H cmd.exe -new_console:d:D: \\ -i -cur_console:n:sT50H","title":"Configuring Tasks"},{"location":"git/tools/#what-those-commands-do","text":"Creates new screen and opens Vim in my Dropbox folder context Creates new screen with Vim pointing to D:\\ Initializes shell in this new window and splits current screen into 75%/25% horizontaly Initializes shell in new (25%) window and splits it up into 33.3%/66.6% vertically . Then initializes shell in the new (66.6%) window and splits it up into 50%/50% vertically .","title":"What those commands do"},{"location":"git/tools/#aliases","text":"You can create an alias to any command by an alias command, e.g.: 1 alias push = git push -u $* No space in between! Make sure there is no space between the alias and the equality sign = Undo the alias by unalias push . The aliases can be found in config subdirectory of the cmder install directory in the user-aliases.cmd file or by running alias command with no parameters.","title":"Aliases"},{"location":"git/tools/#standard-aliases","text":"cmderr - open cmder window in the cmder install directory, e.g. C:\\Program Files\\Cmder history - show latest commands","title":"Standard Aliases"},{"location":"git/tools/#how-to-update-conemu-within-cmder","text":"Maximus5 , the author of Cmder, explains how to update ConEmu to a new version. Current Cmder can contain an older ConEmu version. To update ConEmu, get the new package from the ConEmu website and copy its content to \u2018your cmder installation\u2019/vendor/conemu-maximus5 folder.","title":"How to update ConEmu within Cmder"},{"location":"git/tools/#links","text":"Cmder: Super Command Line Tool Window","title":"Links"},{"location":"git/tools/#far-manager","text":"","title":"Far Manager"},{"location":"git/tools/#add-far-manager-to-the-windows-context-menu","text":"It is convenient to be able to open the Far Manager at the current location. You would then want to be able to either right click either on the folder itself, or right click inside the white area within the folder open in the Windows Explorer . Create or rename (if already created by the Far Manager installation) the same group of keys and string values in the Windows Registry in the following two locations respectively: HCR/Directory/shell HCR/Directory/Background/shell Key: Far Here Name Type Data (Default) REG_SZ (value not set) Icon REG_SZ C:\\Program Files\\Far Manager\\Far.exe,0 Subkey: command Name Type Data (Default) REG_SZ \"C:\\Program Files\\Far Manager\\Far.exe\" \"% X \" \"% X \" Replace X with a number! In the shell , replace X with 1 and in the Background/shell with 2 .","title":"Add Far Manager to the Windows context menu"},{"location":"git/tools/#posh-git-for-powershell","text":"POSH-GIT is a PowerShell module that shows the current branch of the git repository and understands git commands.","title":"POSH-GIT for PowerShell"},{"location":"git/tools/#installation","text":"The easiest way is to use PowerShell of Chocolatey.","title":"Installation"},{"location":"git/tools/#powershell","text":"1 PowerShellGet \\ Install-Module posh-git -Scope CurrentUser Note: If you get an error message from Install-Module about NuGet being required to interact with NuGet-based repositories, execute the following commands to bootstrap the NuGet provider: 1 2 Install-PackageProvider NuGet -Force Import-PackageProvider NuGet -Force Then retry the Install-Module command above.","title":"PowerShell"},{"location":"git/tools/#chocolatey","text":"1 choco install poshgit","title":"Chocolatey"},{"location":"git/tools/#updates","text":"Update to a newer version by executing the command: 1 Update-Module posh-git","title":"Updates"},{"location":"git/tools/#how-to-use","text":"Open the PowerShell command prompt and run: 1 Import-Module posh-git If you are lazy to do it every time, add the command to your profile. Here is how. start PowerShell command prompt and run $profile you will see the path and name of your profile file, e.g. C:\\Users\\YourUserName\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1 if this file does not exist, create it add Import-Module posh-git to that file","title":"How to use"},{"location":"git/tools/#use-it-with-integrated-terminal-in-vs-code","text":"Add the following setting to the VS Code User Settings: 1 \"terminal.integrated.shell.windows\" : \"C:\\\\Windows\\\\System 32 \\\\WindowsPowerShell\\\\v 1.0 \\\\powershell.exe, Toggle the Integrated Terminal window with Ctrl + ` .","title":"Use it with Integrated Terminal in VS Code"},{"location":"go/myinstall/","text":"Installation Notes \u00b6 MAC OS X \u00b6 On my MAC OS X, I ended up installing and using Go from the official .dmg package from the Go website . Installation Issues I have had bad experience when trying to use Homebrew or GVM . Probably because I tried to install new installation option without properly cleaning everything from the previous one. The following files may have \u201ctraces\u201d of different settings: ~/.bash_profile ~/.bashrc ~/.profile My Go environment variables are all defined in ~/.bash_profile . Troubleshooting \u00b6 Uninstalling Go \u00b6 Uninstalling Golang from Mac OS X machine can be done easily. All you to do is the remove this directory /usr/local/go . Doing this will remove the binaries for Golang but not the residue files which you have installed elsewhere. To remove the additional files, you need to check the environment variables for GOPATH and GOROOT . Those the files that you need to delete as well if you plan to remove Golang entirely. Version Mismatch During Build \u00b6 go build produces the following error message: 1 compile: version \"go1.10.3\" does not match go tool version \"go1.11\" Check if you have more than one version of Go installed (e.g. .dmg , Homebrew , or gvm ). If more than one, remove all except the one you want to use. Analyse: which go go version go env cat /usr/local/go/VERSION","title":"Installing Go"},{"location":"go/myinstall/#installation-notes","text":"","title":"Installation Notes"},{"location":"go/myinstall/#mac-os-x","text":"On my MAC OS X, I ended up installing and using Go from the official .dmg package from the Go website . Installation Issues I have had bad experience when trying to use Homebrew or GVM . Probably because I tried to install new installation option without properly cleaning everything from the previous one. The following files may have \u201ctraces\u201d of different settings: ~/.bash_profile ~/.bashrc ~/.profile My Go environment variables are all defined in ~/.bash_profile .","title":"MAC OS X"},{"location":"go/myinstall/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"go/myinstall/#uninstalling-go","text":"Uninstalling Golang from Mac OS X machine can be done easily. All you to do is the remove this directory /usr/local/go . Doing this will remove the binaries for Golang but not the residue files which you have installed elsewhere. To remove the additional files, you need to check the environment variables for GOPATH and GOROOT . Those the files that you need to delete as well if you plan to remove Golang entirely.","title":"Uninstalling Go"},{"location":"go/myinstall/#version-mismatch-during-build","text":"go build produces the following error message: 1 compile: version \"go1.10.3\" does not match go tool version \"go1.11\" Check if you have more than one version of Go installed (e.g. .dmg , Homebrew , or gvm ). If more than one, remove all except the one you want to use. Analyse: which go go version go env cat /usr/local/go/VERSION","title":"Version Mismatch During Build"},{"location":"go/notes/","text":"Go Notes \u00b6 Go Toolset \u00b6 Go Playground \u00b6 Go Playground is a great tool to try out your code snippets. Local Go Documentation \u00b6 The Go documentation is also available in a browsable format. This gives you godoc documentation as a local web server. To start your own documentation server, type: 1 godoc -http = :6060 This command instructs godoc to start a web server on local port 6060 . If you open your web browser and navigate to http://localhost:6060 , you\u2019ll see a web page with documentation for both the Go standard libraries and any Go source that lives in your GOPATH . The best part of Go\u2019s documentation tool is that it works for your code, too. If you follow simple conventions while writing your code, it will automatically include your comments in the Go documentation generated by godoc . To be included in the godoc generated documentation, your code needs to be documented by adding comments that follow a specific convention. Start by adding comments directly above the identifiers you want to document. This works for packages, functions, types, and global variables. Comments can be started using either two slashes, or using the slash-asterisk style. 1 2 3 4 5 6 // Retrieve connects to the configuration repository and gathers // various connection settings, usernames, passwords. It returns a // config struct on success, or an error. func Retrieve () ( config , error ) { // ... omitted } If you want to add a large body of text to document your package, include a file called doc.go that declares the same package as your project, and put your package introduction as a comment before the package declaration: 1 2 3 4 5 6 7 /* Package usb provides types and functions for working with USB devices. To connect to a USB device start by creating a new USB connection with NewConnection ... */ package usb This package documentation will be shown before any type or function documentation is displayed for your package. It also demonstrates using the slash-asterisk type of comment. You can read more about creating good documentation for your code by searching for golang documentation in Google. Dependency Management \u00b6 GODEP \u00b6 GODEP is a dependency tool for go . GB \u00b6 GB is a project based build tool for the Go programming language. Syntax \u00b6 Slice Capacity \u00b6 By having the option to set the capacity of a new slice to be the same as the length, you can force the first append operation to detach the new slice from the underlying array. Detaching the new slice from its original source array makes it safe to change. 1 2 3 4 5 6 7 8 // Create a slice of strings. // Contains a length and capacity of 5 elements. source := [] string { \"Apple\" , \"Orange\" , \"Plum\" , \"Banana\" , \"Grape\" } // Slice the third element and restrict the capacity. // Contains a length and capacity of 1 element. slice := source [ 2 : 3 : 3 ] // Append a new string to the slice. slice = append ( slice , \"Kiwi\" ) Without this third index, appending Kiwi to our slice would\u2019ve changed the value of Banana in index 3 of the underlying array, because all of the remaining capacity would still belong to the slice. But we restricted the capacity of the slice to 1. When we call append for the first time on the slice, it will create a new underlying array of two elements, copy the fruit Plum, add the new fruit Kiwi, and return a new slice that references this underlying array, append function \u00b6 The built-in function append is also a variadic function. This means you can pass multiple values to be appended in a single slice call. If you use the \u2026 operator, you can append all the elements of one slice into another. 1 2 3 4 5 6 7 8 // Create two slices each initialized with two integers. s1 := [] int { 1 , 2 } s2 := [] int { 3 , 4 } // Append the two slices together and display the results. fmt . Printf ( \"%v\\n\" , append ( s1 , s2 ... )) Output : [ 1 2 3 4 ]","title":"Go Notes"},{"location":"go/notes/#go-notes","text":"","title":"Go Notes"},{"location":"go/notes/#go-toolset","text":"","title":"Go Toolset"},{"location":"go/notes/#go-playground","text":"Go Playground is a great tool to try out your code snippets.","title":"Go Playground"},{"location":"go/notes/#local-go-documentation","text":"The Go documentation is also available in a browsable format. This gives you godoc documentation as a local web server. To start your own documentation server, type: 1 godoc -http = :6060 This command instructs godoc to start a web server on local port 6060 . If you open your web browser and navigate to http://localhost:6060 , you\u2019ll see a web page with documentation for both the Go standard libraries and any Go source that lives in your GOPATH . The best part of Go\u2019s documentation tool is that it works for your code, too. If you follow simple conventions while writing your code, it will automatically include your comments in the Go documentation generated by godoc . To be included in the godoc generated documentation, your code needs to be documented by adding comments that follow a specific convention. Start by adding comments directly above the identifiers you want to document. This works for packages, functions, types, and global variables. Comments can be started using either two slashes, or using the slash-asterisk style. 1 2 3 4 5 6 // Retrieve connects to the configuration repository and gathers // various connection settings, usernames, passwords. It returns a // config struct on success, or an error. func Retrieve () ( config , error ) { // ... omitted } If you want to add a large body of text to document your package, include a file called doc.go that declares the same package as your project, and put your package introduction as a comment before the package declaration: 1 2 3 4 5 6 7 /* Package usb provides types and functions for working with USB devices. To connect to a USB device start by creating a new USB connection with NewConnection ... */ package usb This package documentation will be shown before any type or function documentation is displayed for your package. It also demonstrates using the slash-asterisk type of comment. You can read more about creating good documentation for your code by searching for golang documentation in Google.","title":"Local Go Documentation"},{"location":"go/notes/#dependency-management","text":"","title":"Dependency Management"},{"location":"go/notes/#godep","text":"GODEP is a dependency tool for go .","title":"GODEP"},{"location":"go/notes/#gb","text":"GB is a project based build tool for the Go programming language.","title":"GB"},{"location":"go/notes/#syntax","text":"","title":"Syntax"},{"location":"go/notes/#slice-capacity","text":"By having the option to set the capacity of a new slice to be the same as the length, you can force the first append operation to detach the new slice from the underlying array. Detaching the new slice from its original source array makes it safe to change. 1 2 3 4 5 6 7 8 // Create a slice of strings. // Contains a length and capacity of 5 elements. source := [] string { \"Apple\" , \"Orange\" , \"Plum\" , \"Banana\" , \"Grape\" } // Slice the third element and restrict the capacity. // Contains a length and capacity of 1 element. slice := source [ 2 : 3 : 3 ] // Append a new string to the slice. slice = append ( slice , \"Kiwi\" ) Without this third index, appending Kiwi to our slice would\u2019ve changed the value of Banana in index 3 of the underlying array, because all of the remaining capacity would still belong to the slice. But we restricted the capacity of the slice to 1. When we call append for the first time on the slice, it will create a new underlying array of two elements, copy the fruit Plum, add the new fruit Kiwi, and return a new slice that references this underlying array,","title":"Slice Capacity"},{"location":"go/notes/#append-function","text":"The built-in function append is also a variadic function. This means you can pass multiple values to be appended in a single slice call. If you use the \u2026 operator, you can append all the elements of one slice into another. 1 2 3 4 5 6 7 8 // Create two slices each initialized with two integers. s1 := [] int { 1 , 2 } s2 := [] int { 3 , 4 } // Append the two slices together and display the results. fmt . Printf ( \"%v\\n\" , append ( s1 , s2 ... )) Output : [ 1 2 3 4 ]","title":"append function"},{"location":"graphql/ten_principles/","text":"10 GraphQL Principles \u00b6 (from Principled GraphQL by Matt DeBergalis, Co-Founder of Apollo on 21-02-2019) At Apollo , we\u2019ve been building industry-leading data graph technology since 2015 and now estimate that our software is used in over 90% of GraphQL implementations. Over the years, we\u2019ve had thousands of conversations with developers using GraphQL and worked side-by-side with teams putting it into production at companies of all sizes. To share what we\u2019ve learned, my co-founder Geoff Schmidt and I published Principled GraphQL \u2014- a list of 10 GraphQL Principles that distill the experiences of those teams into a set of best practices for creating, maintaining, and operating a data graph. We encourage you to check them out and share them with anyone building a GraphQL layer. One Graph \u00b6 Your company should have one unified graph, rather than each team creating their own graph. Federated Implementation \u00b6 Though there is only one graph, the implementation of that graph should be federated across multiple teams. Track the Schema in a Registry \u00b6 There should be a single source of truth that defines the makeup of the graph. Abstract, Demand-Oriented Schema \u00b6 The schema should act as an abstraction layer that provides flexibility to consumers while hiding service implementation details. Use an Agile Approach to Schema Development \u00b6 The schema should be built incrementally based on actual requirements, and rather than being versioned should evolve smoothly over time. Iteratively Improve Performance \u00b6 Performance management should be a continuous, data-driven process, adapting smoothly to changing query loads and service implementations. Use Graph Metadata to Empower Developers \u00b6 Developers should be equipped with rich awareness of the graph throughout the entire development process. Access and Demand Control \u00b6 Grant access to the graph on a per-client basis, and manage not just what a client can access but how they can access it. Structured Logging \u00b6 Capture structured logs of all graph operations and leverage them as the primary tool for understanding graph usage. Separate the GraphQL layer from the Service Layer \u00b6 Adopt a layered architecture with data graph functionality broken into a separate tier rather than baked into every service. You will find more detail on each principle here . Matt DeBergalis Co-Founder, Apollo","title":"10 Principles"},{"location":"graphql/ten_principles/#10-graphql-principles","text":"(from Principled GraphQL by Matt DeBergalis, Co-Founder of Apollo on 21-02-2019) At Apollo , we\u2019ve been building industry-leading data graph technology since 2015 and now estimate that our software is used in over 90% of GraphQL implementations. Over the years, we\u2019ve had thousands of conversations with developers using GraphQL and worked side-by-side with teams putting it into production at companies of all sizes. To share what we\u2019ve learned, my co-founder Geoff Schmidt and I published Principled GraphQL \u2014- a list of 10 GraphQL Principles that distill the experiences of those teams into a set of best practices for creating, maintaining, and operating a data graph. We encourage you to check them out and share them with anyone building a GraphQL layer.","title":"10 GraphQL Principles"},{"location":"graphql/ten_principles/#one-graph","text":"Your company should have one unified graph, rather than each team creating their own graph.","title":"One Graph"},{"location":"graphql/ten_principles/#federated-implementation","text":"Though there is only one graph, the implementation of that graph should be federated across multiple teams.","title":"Federated Implementation"},{"location":"graphql/ten_principles/#track-the-schema-in-a-registry","text":"There should be a single source of truth that defines the makeup of the graph.","title":"Track the Schema in a Registry"},{"location":"graphql/ten_principles/#abstract-demand-oriented-schema","text":"The schema should act as an abstraction layer that provides flexibility to consumers while hiding service implementation details.","title":"Abstract, Demand-Oriented Schema"},{"location":"graphql/ten_principles/#use-an-agile-approach-to-schema-development","text":"The schema should be built incrementally based on actual requirements, and rather than being versioned should evolve smoothly over time.","title":"Use an Agile Approach to Schema Development"},{"location":"graphql/ten_principles/#iteratively-improve-performance","text":"Performance management should be a continuous, data-driven process, adapting smoothly to changing query loads and service implementations.","title":"Iteratively Improve Performance"},{"location":"graphql/ten_principles/#use-graph-metadata-to-empower-developers","text":"Developers should be equipped with rich awareness of the graph throughout the entire development process.","title":"Use Graph Metadata to Empower Developers"},{"location":"graphql/ten_principles/#access-and-demand-control","text":"Grant access to the graph on a per-client basis, and manage not just what a client can access but how they can access it.","title":"Access and Demand Control"},{"location":"graphql/ten_principles/#structured-logging","text":"Capture structured logs of all graph operations and leverage them as the primary tool for understanding graph usage.","title":"Structured Logging"},{"location":"graphql/ten_principles/#separate-the-graphql-layer-from-the-service-layer","text":"Adopt a layered architecture with data graph functionality broken into a separate tier rather than baked into every service. You will find more detail on each principle here . Matt DeBergalis Co-Founder, Apollo","title":"Separate the GraphQL layer from the Service Layer"},{"location":"mac/brew/","text":"Homebrew Utility \u00b6 Updates \u00b6 Here is a Terminal alias to get all the updating to happen with a single word brewery command: 1 alias brewery = 'brew update && brew upgrade && brew cleanup' Source: this tip of Konstantin Results of the first run \u00b6 When I ran it the first time, I got a lot of hints about various upgraded components. I have made note of those I considered important. openssl@1.1 -> 1.1.1 \u00b6 A CA file has been bootstrapped using certificates from the system keychain. To add additional certificates, place .pem files in /usr/local/etc/openssl@1.1/certs and run /usr/local/opt/openssl@1.1/bin/c_rehash openssl@1.1 is keg-only, which means it was not symlinked into /usr/local , because this is an alternate version of another formula. If you need to have openssl@1.1 first in your PATH run: 1 echo 'export PATH=\"/usr/local/opt/openssl@1.1/bin:$PATH\"' >> ~/.bash_profile For compilers to find openssl@1.1 you may need to set: 1 2 export LDFLAGS = \"-L/usr/local/opt/openssl@1.1/lib\" export CPPFLAGS = \"-I/usr/local/opt/openssl@1.1/include\" For pkg-config to find openssl@1.1 you may need to set: 1 export PKG_CONFIG_PATH = \"/usr/local/opt/openssl@1.1/lib/pkgconfig\" mariadb \u00b6 A /etc/my.cnf from another install may interfere with a Homebrew-built server starting up correctly. MySQL is configured to only allow connections from localhost by default. To connect: 1 mysql -uroot To have launchd start mariadb now and restart at login: 1 2 3 4 5 6 7 brew services start mariadb ```` Or, if you don \\' t want/need a background service you can just run: ``` bash mysql.server start nginx \u00b6 Docroot is: /usr/local/var/www The default port has been set in /usr/local/etc/nginx/nginx.conf to 8080 so that nginx can run without sudo. nginx will load all files in /usr/local/etc/nginx/servers/ . To have launchd start nginx now and restart at login: 1 brew services start nginx Or, if you don\u2019t want/need a background service you can just run: 1 nginx docker-machine \u00b6 Bash completion has been installed to: 1 /usr/local/etc/bash_completion.d zsh completions have been installed to: 1 /usr/local/share/zsh/site-functions To have it launched start docker-machine now and restart at login: 1 brew services start docker-machine Or, if you don\u2019t want/need a background service you can just run: 1 docker-machine start","title":"Homebrew"},{"location":"mac/brew/#homebrew-utility","text":"","title":"Homebrew Utility"},{"location":"mac/brew/#updates","text":"Here is a Terminal alias to get all the updating to happen with a single word brewery command: 1 alias brewery = 'brew update && brew upgrade && brew cleanup' Source: this tip of Konstantin","title":"Updates"},{"location":"mac/brew/#results-of-the-first-run","text":"When I ran it the first time, I got a lot of hints about various upgraded components. I have made note of those I considered important.","title":"Results of the first run"},{"location":"mac/brew/#openssl11-111","text":"A CA file has been bootstrapped using certificates from the system keychain. To add additional certificates, place .pem files in /usr/local/etc/openssl@1.1/certs and run /usr/local/opt/openssl@1.1/bin/c_rehash openssl@1.1 is keg-only, which means it was not symlinked into /usr/local , because this is an alternate version of another formula. If you need to have openssl@1.1 first in your PATH run: 1 echo 'export PATH=\"/usr/local/opt/openssl@1.1/bin:$PATH\"' >> ~/.bash_profile For compilers to find openssl@1.1 you may need to set: 1 2 export LDFLAGS = \"-L/usr/local/opt/openssl@1.1/lib\" export CPPFLAGS = \"-I/usr/local/opt/openssl@1.1/include\" For pkg-config to find openssl@1.1 you may need to set: 1 export PKG_CONFIG_PATH = \"/usr/local/opt/openssl@1.1/lib/pkgconfig\"","title":"openssl@1.1 -&gt; 1.1.1"},{"location":"mac/brew/#mariadb","text":"A /etc/my.cnf from another install may interfere with a Homebrew-built server starting up correctly. MySQL is configured to only allow connections from localhost by default. To connect: 1 mysql -uroot To have launchd start mariadb now and restart at login: 1 2 3 4 5 6 7 brew services start mariadb ```` Or, if you don \\' t want/need a background service you can just run: ``` bash mysql.server start","title":"mariadb"},{"location":"mac/brew/#nginx","text":"Docroot is: /usr/local/var/www The default port has been set in /usr/local/etc/nginx/nginx.conf to 8080 so that nginx can run without sudo. nginx will load all files in /usr/local/etc/nginx/servers/ . To have launchd start nginx now and restart at login: 1 brew services start nginx Or, if you don\u2019t want/need a background service you can just run: 1 nginx","title":"nginx"},{"location":"mac/brew/#docker-machine","text":"Bash completion has been installed to: 1 /usr/local/etc/bash_completion.d zsh completions have been installed to: 1 /usr/local/share/zsh/site-functions To have it launched start docker-machine now and restart at login: 1 brew services start docker-machine Or, if you don\u2019t want/need a background service you can just run: 1 docker-machine start","title":"docker-machine"},{"location":"mac/nginx/","text":"Web Server on MacBook Pro \u00b6 It is possible to run different web servers on a Mac. I prefer NGINX to Apache. NGINX \u00b6 Installation \u00b6 Prep work: 1 2 3 brew doctor brew update brew upgrade Installation: 1 2 3 brew install nginx brew services start nginx brew services stop nginx Use these commands to start, stop or restart the nginx server: 1 2 3 sudo nginx sudo nginx -s stop sudo nginx -s reload nginx.conf \u00b6 In the root of the main HDD, create a new www directory and inside it another two subdirectories: home and sites . Now, we can edit the nginx.conf file to point the root server at /www/sites and listen on port 80 . We can use VI or NANO for that: 1 2 sudo vi /usr/local/etc/nginx/nginx.conf sudo nano /usr/local/etc/nginx/nginx.conf Scroll to the second screen and you will see something like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 server { listen 8080 ; server_name localhost ; #charset koi8-r; #access_log logs/host.access.log main; location / { root html ; index index . html index . htm ; } ... } Change 8080 to 80 and root html; to /www/sites or whatever other root path we created. Errors 500 There is another chunk of code after location , which deals with \u201c500\u201d errors that also has root html setting. Possibly, it should also be changed in the same way. Anciliary Tools \u00b6 dsnmasq \u00b6 This is a great little tool that allows us to use wildcard subdomain names. With the default apache settings, we can add as many sites as we like in subfolders of the web root, e.g.: http://home.dev/client1 http://home.dev/client2 http://home.dev/client3 However, that creates a problem. When we have each site in a folder, it\u2019s more difficult to manage the settings for each site. Each one must then have a different absolute root. The solution is to create a subdomain for each site, and use URLs like these: http://client1.dev http://client2.dev http://client3.dev We can accomplish this by placing all three sites in our /private/etc/hosts file, but then we need to keep adding entries every time we add a new site. dnsmasq allows us to do this by interrupting each request that ends with .dev and forwarding it to a designated IP address (127.0.0.1 in our case). The following commands will install dnsmasq , configure it to point all requests to the .dev top-level domain to our local machine, and make sure it starts up and runs all of the time. 1 2 3 4 5 6 brew install dnsmasq cd $( brew --prefix ) ; mkdir etc ; echo 'address=/.dev/127.0.0.1' > etc/dnsmasq.conf sudo cp -v $( brew --prefix dnsmasq ) /homebrew.mxcl.dnsmasq.plist /Library/LaunchDaemons sudo launchctl load -w /Library/LaunchDaemons/homebrew.mxcl.dnsmasq.plist sudo mkdir /etc/resolver sudo bash -c 'echo \"nameserver 127.0.0.1\" > /etc/resolver/dev' If all goes well, we\u2019ll never need to think about it again.","title":"NGINX"},{"location":"mac/nginx/#web-server-on-macbook-pro","text":"It is possible to run different web servers on a Mac. I prefer NGINX to Apache.","title":"Web Server on MacBook Pro"},{"location":"mac/nginx/#nginx","text":"","title":"NGINX"},{"location":"mac/nginx/#installation","text":"Prep work: 1 2 3 brew doctor brew update brew upgrade Installation: 1 2 3 brew install nginx brew services start nginx brew services stop nginx Use these commands to start, stop or restart the nginx server: 1 2 3 sudo nginx sudo nginx -s stop sudo nginx -s reload","title":"Installation"},{"location":"mac/nginx/#nginxconf","text":"In the root of the main HDD, create a new www directory and inside it another two subdirectories: home and sites . Now, we can edit the nginx.conf file to point the root server at /www/sites and listen on port 80 . We can use VI or NANO for that: 1 2 sudo vi /usr/local/etc/nginx/nginx.conf sudo nano /usr/local/etc/nginx/nginx.conf Scroll to the second screen and you will see something like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 server { listen 8080 ; server_name localhost ; #charset koi8-r; #access_log logs/host.access.log main; location / { root html ; index index . html index . htm ; } ... } Change 8080 to 80 and root html; to /www/sites or whatever other root path we created. Errors 500 There is another chunk of code after location , which deals with \u201c500\u201d errors that also has root html setting. Possibly, it should also be changed in the same way.","title":"nginx.conf"},{"location":"mac/nginx/#anciliary-tools","text":"","title":"Anciliary Tools"},{"location":"mac/nginx/#dsnmasq","text":"This is a great little tool that allows us to use wildcard subdomain names. With the default apache settings, we can add as many sites as we like in subfolders of the web root, e.g.: http://home.dev/client1 http://home.dev/client2 http://home.dev/client3 However, that creates a problem. When we have each site in a folder, it\u2019s more difficult to manage the settings for each site. Each one must then have a different absolute root. The solution is to create a subdomain for each site, and use URLs like these: http://client1.dev http://client2.dev http://client3.dev We can accomplish this by placing all three sites in our /private/etc/hosts file, but then we need to keep adding entries every time we add a new site. dnsmasq allows us to do this by interrupting each request that ends with .dev and forwarding it to a designated IP address (127.0.0.1 in our case). The following commands will install dnsmasq , configure it to point all requests to the .dev top-level domain to our local machine, and make sure it starts up and runs all of the time. 1 2 3 4 5 6 brew install dnsmasq cd $( brew --prefix ) ; mkdir etc ; echo 'address=/.dev/127.0.0.1' > etc/dnsmasq.conf sudo cp -v $( brew --prefix dnsmasq ) /homebrew.mxcl.dnsmasq.plist /Library/LaunchDaemons sudo launchctl load -w /Library/LaunchDaemons/homebrew.mxcl.dnsmasq.plist sudo mkdir /etc/resolver sudo bash -c 'echo \"nameserver 127.0.0.1\" > /etc/resolver/dev' If all goes well, we\u2019ll never need to think about it again.","title":"dsnmasq"},{"location":"mac/ssh/","text":"SSH on Sierra \u00b6 These are short notes on how you can set up an SSH connection for GitLab (or any other secure server). 1 2 3 4 5 6 7 8 # check if you already have an ssh key cat ~/.ssh/id_rsa.pub # if not, generate a new key ssh-keygen -t rsa -C \"your.email@yourprovider.com\" -b 4096 # copy the new key to clipboard pbcopy < ~/.ssh/id_rsa.pub Go to GitLab and add your new key as explained in their help documentation. Test your SSH configuration: 1 2 3 4 5 # test the key ssh -T git@gitlab.com # debug the connection ssh -Tv git@gitlab.com When using SSH on my Mac with High Sierra, I noticed that I am required to enter my SSH password every time. This is a known issue on Sierra. I have found a good solution to it in this article by Rob Allen . Here are the steps I have taken based on his advice: 1 2 3 4 5 # add your key to id_rsa ssh-add -K ~/.ssh/id_rsa # make sure you see the saved key ssh-add -l Now you can check you don\u2019t need to enter your password by running git status on any GitLab repo. Update the SSH config by editing ~/.ssh/config and adding: 1 2 3 Host * AddKeysToAgent yes UseKeychain yes After reboot of your PC, you should still be able to use SSH without having to type in your password.","title":"SSH on Sierra"},{"location":"mac/ssh/#ssh-on-sierra","text":"These are short notes on how you can set up an SSH connection for GitLab (or any other secure server). 1 2 3 4 5 6 7 8 # check if you already have an ssh key cat ~/.ssh/id_rsa.pub # if not, generate a new key ssh-keygen -t rsa -C \"your.email@yourprovider.com\" -b 4096 # copy the new key to clipboard pbcopy < ~/.ssh/id_rsa.pub Go to GitLab and add your new key as explained in their help documentation. Test your SSH configuration: 1 2 3 4 5 # test the key ssh -T git@gitlab.com # debug the connection ssh -Tv git@gitlab.com When using SSH on my Mac with High Sierra, I noticed that I am required to enter my SSH password every time. This is a known issue on Sierra. I have found a good solution to it in this article by Rob Allen . Here are the steps I have taken based on his advice: 1 2 3 4 5 # add your key to id_rsa ssh-add -K ~/.ssh/id_rsa # make sure you see the saved key ssh-add -l Now you can check you don\u2019t need to enter your password by running git status on any GitLab repo. Update the SSH config by editing ~/.ssh/config and adding: 1 2 3 Host * AddKeysToAgent yes UseKeychain yes After reboot of your PC, you should still be able to use SSH without having to type in your password.","title":"SSH on Sierra"},{"location":"mac/tips/","text":"Tips & Tricks \u00b6 How to make file executable \u00b6 Suppose you have create a run.sh file and you want to be able to run it with bash . In the file, the first line should be like this: 1 #!/bin/sh or like this: 1 #!/bin/bash Then in the folder with your file run this command to add execute rights to the file: 1 chmod u+x ./run.sh Finally, you can run this file like this: 1 ./run.sh Hide/show hidden files \u00b6 The easy way \u00b6 Since the release of macOS Sierra , when in Finder, it is now possible to use the shortcut: 1 CMD + SHIFT + . Press once to show hidden files and again to hide them. The long way \u00b6 Open Terminal found in Finder > Applications > Utilities . In Terminal, paste the following and press Return : 1 defaults write com.apple.finder AppleShowAllFiles YES | NO Hold the \u2018Option/alt\u2019 key, then right click on the Finder icon in the dock and click Relaunch.","title":"Tips & Tricks"},{"location":"mac/tips/#tips-tricks","text":"","title":"Tips &amp; Tricks"},{"location":"mac/tips/#how-to-make-file-executable","text":"Suppose you have create a run.sh file and you want to be able to run it with bash . In the file, the first line should be like this: 1 #!/bin/sh or like this: 1 #!/bin/bash Then in the folder with your file run this command to add execute rights to the file: 1 chmod u+x ./run.sh Finally, you can run this file like this: 1 ./run.sh","title":"How to make file executable"},{"location":"mac/tips/#hideshow-hidden-files","text":"","title":"Hide/show hidden files"},{"location":"mac/tips/#the-easy-way","text":"Since the release of macOS Sierra , when in Finder, it is now possible to use the shortcut: 1 CMD + SHIFT + . Press once to show hidden files and again to hide them.","title":"The easy way"},{"location":"mac/tips/#the-long-way","text":"Open Terminal found in Finder > Applications > Utilities . In Terminal, paste the following and press Return : 1 defaults write com.apple.finder AppleShowAllFiles YES | NO Hold the \u2018Option/alt\u2019 key, then right click on the Finder icon in the dock and click Relaunch.","title":"The long way"},{"location":"powershell/vscode/","text":"This article describes the new version of PowerShell, PowerShell Core v6.0 , which is a new generation of Powershell. It is cross-platform and at the moment implements only the most important functionality. Unfortunately, it has no modules to manage IIS. Recommended Prerequisites \u00b6 To effectively debug PowerShell in Visual Studio Code you might consider to carry out the following steps: install PowerShell VS Code extension install the latest version of PowerShell Core (at the moment of writing this article, it was version 6.0.2 ) from its GitHub repo add the installation path to the Windows environment PATH variable: C:\\Program Files\\PowerShell\\<version>\\ add the corresponding line to your VS Code settings: 1 2 3 4 5 6 // On Windows: \"powershell.powerShellExePath\" : \"C:/Program Files/PowerShell/<version>/pwsh.exe\" // On Linux: \"powershell.powerShellExePath\" : \"/opt/microsoft/powershell/<version>/pwsh\" // On macOS: \"powershell.powerShellExePath\" : \"/usr/local/microsoft/powershell/<version>/pwsh\" Now, when you start the VS Code you will notice that it is using the installed PowerShell Core as its integrated terminal. Debugging \u00b6 When you open your PowerShell file in the VS Code window, you can run it in the debugger mode. If you have not done it yet, initialize the launch.json configuration file by choosing the bug icon in the left side menu. Now, click on the gear icon at the top of the screen. The launch.json file will be created if necessary and open in the editor window. Probably the second configuration with look something like this: 1 2 3 4 5 6 7 8 { \"type\" : \"PowerShell\" , \"request\" : \"launch\" , \"name\" : \"PowerShell Launch Current File\" , \"script\" : \"${file}\" , \"args\" : [], \"cwd\" : \"${file}\" } , Now, switch back to your PowerShell file in the editor window and set breakpoints where you need them. Choose PowerShell Launch Current File option in the Debug menu above, and click on the green triangle to run the script in the debugger mode. The debugger will stop at the first breakpoint it encounters. A nice feature of the PowerShell debugger is that it can also debug inside the invoked commands, e.g by Invoke-Command . Just stop the debugger at the line with Invoke-Command first. From that breakpoint, you can go inside the invoked block by stepping inside it, e.g with F11 .","title":"Debugging PowerShell in VS Code"},{"location":"powershell/vscode/#recommended-prerequisites","text":"To effectively debug PowerShell in Visual Studio Code you might consider to carry out the following steps: install PowerShell VS Code extension install the latest version of PowerShell Core (at the moment of writing this article, it was version 6.0.2 ) from its GitHub repo add the installation path to the Windows environment PATH variable: C:\\Program Files\\PowerShell\\<version>\\ add the corresponding line to your VS Code settings: 1 2 3 4 5 6 // On Windows: \"powershell.powerShellExePath\" : \"C:/Program Files/PowerShell/<version>/pwsh.exe\" // On Linux: \"powershell.powerShellExePath\" : \"/opt/microsoft/powershell/<version>/pwsh\" // On macOS: \"powershell.powerShellExePath\" : \"/usr/local/microsoft/powershell/<version>/pwsh\" Now, when you start the VS Code you will notice that it is using the installed PowerShell Core as its integrated terminal.","title":"Recommended Prerequisites"},{"location":"powershell/vscode/#debugging","text":"When you open your PowerShell file in the VS Code window, you can run it in the debugger mode. If you have not done it yet, initialize the launch.json configuration file by choosing the bug icon in the left side menu. Now, click on the gear icon at the top of the screen. The launch.json file will be created if necessary and open in the editor window. Probably the second configuration with look something like this: 1 2 3 4 5 6 7 8 { \"type\" : \"PowerShell\" , \"request\" : \"launch\" , \"name\" : \"PowerShell Launch Current File\" , \"script\" : \"${file}\" , \"args\" : [], \"cwd\" : \"${file}\" } , Now, switch back to your PowerShell file in the editor window and set breakpoints where you need them. Choose PowerShell Launch Current File option in the Debug menu above, and click on the green triangle to run the script in the debugger mode. The debugger will stop at the first breakpoint it encounters. A nice feature of the PowerShell debugger is that it can also debug inside the invoked commands, e.g by Invoke-Command . Just stop the debugger at the line with Invoke-Command first. From that breakpoint, you can go inside the invoked block by stepping inside it, e.g with F11 .","title":"Debugging"},{"location":"react/linting/","text":"Linting React Apps in VSCode \u00b6 Setup \u00b6 Install Eslint and Prettier \u00b6 1 yarn add -D eslint prettier eslint-config-prettier eslint-plugin-prettier .eslintrc \u00b6 1 2 3 4 5 6 { \"extends\" : [ \"react-app\" , \"plugin:prettier/recommended\" ] } VSCode User Settings \u00b6 Enable formatOnSave except for JavaScript files as those are taken care of by Eslint . 1 2 3 4 5 6 7 8 9 10 11 12 13 { \"editor.formatOnSave\" : true , \"[javascript]\" : { \"editor.formatOnSave\" : false }, \"eslint.autofixOnSave\" : true , \"eslint.alwaysShowStatus\" : true , \"prettier.disableLanguages\" : [ \"js\" ], \"files.autoSave\" : \"onFocusChange\" , ... } Prettier Command Line \u00b6 Install a couple of plugins: 1 yarn add -D husky lint-staged They will help to make prettier focus ONLY on the files not yet staged in Git by integrating to Git hooks. In package.json file, let us add a couple of things: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { ... \"scripts\" : { ... \"precommit\" : \"lint-staged\" }, \"lint-staged\" : { \"src/**/*.{js,jsx,json,css,scss,less}\" : [ \"prettier --write\" , \"git add\" ] }, ... } This can be simplified by pretty-quick plugin: 1 yarn add -D pretty-quick Now, the snippet above will look like this: 1 2 3 4 5 6 7 8 { ... \"scripts\" : { ... \"precommit\" : \"pretty-quick --staged\" }, ... } Voila, it done now. Stop worrying about formatting the code, it will be automatically formatted for you when you save or commit your files. Taken from: Add ESLint & Prettier to VS Code for a Create React App code snippets eslint.org prettier.io Maybe also this one: Setup ESLint and Prettier together for react and react-native projects in Visual Studio Code .","title":"Linting"},{"location":"react/linting/#linting-react-apps-in-vscode","text":"","title":"Linting React Apps in VSCode"},{"location":"react/linting/#setup","text":"","title":"Setup"},{"location":"react/linting/#install-eslint-and-prettier","text":"1 yarn add -D eslint prettier eslint-config-prettier eslint-plugin-prettier","title":"Install Eslint and Prettier"},{"location":"react/linting/#eslintrc","text":"1 2 3 4 5 6 { \"extends\" : [ \"react-app\" , \"plugin:prettier/recommended\" ] }","title":".eslintrc"},{"location":"react/linting/#vscode-user-settings","text":"Enable formatOnSave except for JavaScript files as those are taken care of by Eslint . 1 2 3 4 5 6 7 8 9 10 11 12 13 { \"editor.formatOnSave\" : true , \"[javascript]\" : { \"editor.formatOnSave\" : false }, \"eslint.autofixOnSave\" : true , \"eslint.alwaysShowStatus\" : true , \"prettier.disableLanguages\" : [ \"js\" ], \"files.autoSave\" : \"onFocusChange\" , ... }","title":"VSCode User Settings"},{"location":"react/linting/#prettier-command-line","text":"Install a couple of plugins: 1 yarn add -D husky lint-staged They will help to make prettier focus ONLY on the files not yet staged in Git by integrating to Git hooks. In package.json file, let us add a couple of things: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { ... \"scripts\" : { ... \"precommit\" : \"lint-staged\" }, \"lint-staged\" : { \"src/**/*.{js,jsx,json,css,scss,less}\" : [ \"prettier --write\" , \"git add\" ] }, ... } This can be simplified by pretty-quick plugin: 1 yarn add -D pretty-quick Now, the snippet above will look like this: 1 2 3 4 5 6 7 8 { ... \"scripts\" : { ... \"precommit\" : \"pretty-quick --staged\" }, ... } Voila, it done now. Stop worrying about formatting the code, it will be automatically formatted for you when you save or commit your files. Taken from: Add ESLint & Prettier to VS Code for a Create React App code snippets eslint.org prettier.io Maybe also this one: Setup ESLint and Prettier together for react and react-native projects in Visual Studio Code .","title":"Prettier Command Line"},{"location":"react/material-ui/","text":"Material-UI for React \u00b6 Main website for Material-UI for React can be found here . Possible Issues \u00b6 DatePicker \u00b6 If the built-in date picker (see date pickers ), one can also try the independent react-datepicker package.","title":"Material-UI for React"},{"location":"react/material-ui/#material-ui-for-react","text":"Main website for Material-UI for React can be found here .","title":"Material-UI for React"},{"location":"react/material-ui/#possible-issues","text":"","title":"Possible Issues"},{"location":"react/material-ui/#datepicker","text":"If the built-in date picker (see date pickers ), one can also try the independent react-datepicker package.","title":"DatePicker"},{"location":"react/mdx/","text":"MDX Tools \u00b6 MDX is a format that lets you seamlessly use JSX in your Markdown documents. You can import components, like interactive charts or notifs, and export metadata. For more details, see the official website and the Github repo . MDX-DECK \u00b6 mdx-deck is a great library for building slides using Markdown and JSX. It makes creation of dynamic slide presentations a breeze. See here a good live working example of it. Here are the most important features: \ud83d\udcdd Write presentations in markdown \u269b\ufe0f Import and use React components \ud83d\udc85 Customizable themes and components 0\ufe0f\u20e3 Zero-config CLI \ud83d\udc81 Presenter mode \ud83d\udcd3 Speaker notes More documentation can be found in a bunch of .mdx files here . Kent C. Dodds has a nice how-to video about mdx-deck: What is MDX . Another, maybe even better video has been published by Daniel Persson (see the code-surfer plugin section). Another presentation by Jason Gretz on mdx-deck can be found inside the Vue.js Developer Experience & MDX Slides video between 09:55 and 47:40 . It is called Sensational Slides with Markdown and JSX . Build a Custom Provider Component for MDX Deck \u00b6 Creating a custom Provider component allows you to change the markup of the entire deck. This lets you put things like logos and social media handles in each slide easily. Here is how to create a basic custom Provider that adds a Twitter handle to the bottom right corner of every slide. (This tutorial comes from this lesson: Build a Custom Provider Component for MDX Deck ) What you see here is that I have several slides in an mdx-deck . We\u2019re going to create a custom provider component in order to place markup on every single one of our slides. To do this requires three steps. Step one, we need to create a custom theme, step two, we need to create that custom provider component, and step three, we need to export our theme into the mdx-deck. 1. Create a Provider.js component \u00b6 Let\u2019s start by creating our custom theme. In order to get started, we\u2019re going to import a theme from mdx-deck theme, so we\u2019re going to use the default one. Next, we\u2019ll import our provider component even though we haven\u2019t created it yet. Finally, we\u2019ll export an object that\u2019s a combination of the theme provided by mdx-deck in our custom provider. In this step, we\u2019re going to create our custom provider. We\u2019ll start by importing React, since we\u2019ll need it for our JSX. We\u2019ll create a simple provider component that just passes the children down to a div. Let\u2019s make sure to export our provider. If you are like me, you might like putting your twitter handle on every slide in your deck, so that people can easily find you on social media. We\u2019ll create a div and we\u2019ll use the style object in order to position it in the bottom right. You could use style components or CSS. It doesn\u2019t really matter. Our position is absolutely, and I\u2019ll position it 1em from the bottom and 1em from the right. Next, I\u2019ll add a link that points to my twitter profile and add my handle as the text. We save it and we see that it\u2019s on every single slide. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import React from 'react' import ThemeProvider from 'mdx-deck/dist/Provider' const Provider = ({ children, ...rest }) => ( <ThemeProvider {...rest}> {children} <div style={{ position: 'absolute', bottom: '1em', right: '1em' }} > <a href=\"https://twitter.com/madrusnl\"> @madrusnl </a> </div> </ThemeProvider> ) export default Provider 2. Create a theme.js component \u00b6 1 2 3 4 5 6 7 import theme from 'mdx-deck/themes' import Provider from './Provider' export default { ...theme, Provider } 3. Use it in your deck \u00b6 The last step is to export our theme into our mdx-deck. 1 2 3 4 5 6 7 8 9 10 11 export { default as theme } from './theme.js' # Step 1: Create a Custom Theme --- # Step 2: Create a Custom Provider --- # Step 3: Export Our Theme in the mdx-deck Deploy MDX-Deck to Netlify \u00b6 Here is how: Deploy MDX-Deck to Netlify . Code Surfer Plugin \u00b6 Github repo MDX Deck example slide deck Highlight, Scroll, & Zoom Code Snippets in mdx-deck with Code Surfer <\ud83c\udfc4/> Daniel Persson has published a great video: Building a slide deck in mdx-deck . Here is a link to his corresponding repository using the code-surfer plugin. This repo contains a .mdx file showing different usages of the plugin. MDX DOCS \u00b6 MDX Docs is a live documentation creation environment based on MDX and Next.js . Here is a good example , see also this live demo based on it. MDX and Gatsby \u00b6 See these links: Gatsby+MDX: Bringing MDX to Gatsby for ambitious projects Official MDX Gatsby example Getting started gatsby-plugin-mdx Building a Video Blog with Gatsby and Markdown (MDX) (2019) Generate documentation for any React project using GatsbyJS and the corresponding Github repo Gatsby MDX Blog Starter Project gatsby-mdx plugin \u00b6 The gatsby-mdx plugin allows you to create pages in a Gatsby project using .mdx files. If you prefer the .md extension on your markdown files, then you can adjust the plugin options to allow that. 1 2 3 4 5 6 7 8 9 // gatsby-config.js plugins: [ { resolve: `gatsby-mdx`, options: { extensions: [\".mdx\", \".md\"] } } ] This tells gatsby-mdx to recognize both .mdx and .md extensions when processing files. (Taken from Allow md As An Extension With gatsby-mdx .) Docz \u00b6 Definitely watch the featured video on the Docz website ! Docz is good for React component documentation.","title":"MDX Tools"},{"location":"react/mdx/#mdx-tools","text":"MDX is a format that lets you seamlessly use JSX in your Markdown documents. You can import components, like interactive charts or notifs, and export metadata. For more details, see the official website and the Github repo .","title":"MDX Tools"},{"location":"react/mdx/#mdx-deck","text":"mdx-deck is a great library for building slides using Markdown and JSX. It makes creation of dynamic slide presentations a breeze. See here a good live working example of it. Here are the most important features: \ud83d\udcdd Write presentations in markdown \u269b\ufe0f Import and use React components \ud83d\udc85 Customizable themes and components 0\ufe0f\u20e3 Zero-config CLI \ud83d\udc81 Presenter mode \ud83d\udcd3 Speaker notes More documentation can be found in a bunch of .mdx files here . Kent C. Dodds has a nice how-to video about mdx-deck: What is MDX . Another, maybe even better video has been published by Daniel Persson (see the code-surfer plugin section). Another presentation by Jason Gretz on mdx-deck can be found inside the Vue.js Developer Experience & MDX Slides video between 09:55 and 47:40 . It is called Sensational Slides with Markdown and JSX .","title":"MDX-DECK"},{"location":"react/mdx/#build-a-custom-provider-component-for-mdx-deck","text":"Creating a custom Provider component allows you to change the markup of the entire deck. This lets you put things like logos and social media handles in each slide easily. Here is how to create a basic custom Provider that adds a Twitter handle to the bottom right corner of every slide. (This tutorial comes from this lesson: Build a Custom Provider Component for MDX Deck ) What you see here is that I have several slides in an mdx-deck . We\u2019re going to create a custom provider component in order to place markup on every single one of our slides. To do this requires three steps. Step one, we need to create a custom theme, step two, we need to create that custom provider component, and step three, we need to export our theme into the mdx-deck.","title":"Build a Custom Provider Component for MDX Deck"},{"location":"react/mdx/#1-create-a-providerjs-component","text":"Let\u2019s start by creating our custom theme. In order to get started, we\u2019re going to import a theme from mdx-deck theme, so we\u2019re going to use the default one. Next, we\u2019ll import our provider component even though we haven\u2019t created it yet. Finally, we\u2019ll export an object that\u2019s a combination of the theme provided by mdx-deck in our custom provider. In this step, we\u2019re going to create our custom provider. We\u2019ll start by importing React, since we\u2019ll need it for our JSX. We\u2019ll create a simple provider component that just passes the children down to a div. Let\u2019s make sure to export our provider. If you are like me, you might like putting your twitter handle on every slide in your deck, so that people can easily find you on social media. We\u2019ll create a div and we\u2019ll use the style object in order to position it in the bottom right. You could use style components or CSS. It doesn\u2019t really matter. Our position is absolutely, and I\u2019ll position it 1em from the bottom and 1em from the right. Next, I\u2019ll add a link that points to my twitter profile and add my handle as the text. We save it and we see that it\u2019s on every single slide. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import React from 'react' import ThemeProvider from 'mdx-deck/dist/Provider' const Provider = ({ children, ...rest }) => ( <ThemeProvider {...rest}> {children} <div style={{ position: 'absolute', bottom: '1em', right: '1em' }} > <a href=\"https://twitter.com/madrusnl\"> @madrusnl </a> </div> </ThemeProvider> ) export default Provider","title":"1. Create a Provider.js component"},{"location":"react/mdx/#2-create-a-themejs-component","text":"1 2 3 4 5 6 7 import theme from 'mdx-deck/themes' import Provider from './Provider' export default { ...theme, Provider }","title":"2. Create a theme.js component"},{"location":"react/mdx/#3-use-it-in-your-deck","text":"The last step is to export our theme into our mdx-deck. 1 2 3 4 5 6 7 8 9 10 11 export { default as theme } from './theme.js' # Step 1: Create a Custom Theme --- # Step 2: Create a Custom Provider --- # Step 3: Export Our Theme in the mdx-deck","title":"3. Use it in your deck"},{"location":"react/mdx/#deploy-mdx-deck-to-netlify","text":"Here is how: Deploy MDX-Deck to Netlify .","title":"Deploy MDX-Deck to Netlify"},{"location":"react/mdx/#code-surfer-plugin","text":"Github repo MDX Deck example slide deck Highlight, Scroll, & Zoom Code Snippets in mdx-deck with Code Surfer <\ud83c\udfc4/> Daniel Persson has published a great video: Building a slide deck in mdx-deck . Here is a link to his corresponding repository using the code-surfer plugin. This repo contains a .mdx file showing different usages of the plugin.","title":"Code Surfer Plugin"},{"location":"react/mdx/#mdx-docs","text":"MDX Docs is a live documentation creation environment based on MDX and Next.js . Here is a good example , see also this live demo based on it.","title":"MDX DOCS"},{"location":"react/mdx/#mdx-and-gatsby","text":"See these links: Gatsby+MDX: Bringing MDX to Gatsby for ambitious projects Official MDX Gatsby example Getting started gatsby-plugin-mdx Building a Video Blog with Gatsby and Markdown (MDX) (2019) Generate documentation for any React project using GatsbyJS and the corresponding Github repo Gatsby MDX Blog Starter Project","title":"MDX and Gatsby"},{"location":"react/mdx/#gatsby-mdx-plugin","text":"The gatsby-mdx plugin allows you to create pages in a Gatsby project using .mdx files. If you prefer the .md extension on your markdown files, then you can adjust the plugin options to allow that. 1 2 3 4 5 6 7 8 9 // gatsby-config.js plugins: [ { resolve: `gatsby-mdx`, options: { extensions: [\".mdx\", \".md\"] } } ] This tells gatsby-mdx to recognize both .mdx and .md extensions when processing files. (Taken from Allow md As An Extension With gatsby-mdx .)","title":"gatsby-mdx plugin"},{"location":"react/mdx/#docz","text":"Definitely watch the featured video on the Docz website ! Docz is good for React component documentation.","title":"Docz"},{"location":"react/performance/","text":"React App Performance \u00b6 CSR vs SSR \u00b6 CSR is Client Side Rendering , SSR is Server Side Rendering . E.g. create-react-app is a CSR tool, and next.js is a SSR tool. Here is an articles to start with: Next.js (SSR) vs. Create React App (CSR) by John Tucker. CSR Performance \u00b6 Important actor in making CSR more performant is react-snapshot , a zero-configuration pre-renderer for React apps. Read more on this in the following article: An Almost Static Stack by Charlie Gleason.","title":"Performance Considerations"},{"location":"react/performance/#react-app-performance","text":"","title":"React App Performance"},{"location":"react/performance/#csr-vs-ssr","text":"CSR is Client Side Rendering , SSR is Server Side Rendering . E.g. create-react-app is a CSR tool, and next.js is a SSR tool. Here is an articles to start with: Next.js (SSR) vs. Create React App (CSR) by John Tucker.","title":"CSR vs SSR"},{"location":"react/performance/#csr-performance","text":"Important actor in making CSR more performant is react-snapshot , a zero-configuration pre-renderer for React apps. Read more on this in the following article: An Almost Static Stack by Charlie Gleason.","title":"CSR Performance"},{"location":"react/redux/","text":"Redux \u00b6 Three Principles of Redux \u00b6 From the Egghead.io course of Dan Abramov: Application state is one single object no matter how big or small the application. State tree is immutable (read only). State changes can be added but not modified. State mutations are pure functions that take the previous state and the action being dispatched as its arguments, and returns the next state of the application. These functions are called reducers . Redux conventions \u00b6 If the reducer receives undefined as the state argument, it must return what it considers to be the initial state of the application. The Store \u00b6 The store binds together the three principles of Redux . It holds the current application\u2019s state object. It lets you dispatch actions. When you create it, you need to specify the reducer that tells how state is updated with actions. createStore() \u00b6 The createStore function from Redux and the store object it returns provide : the getState method to get the current application state; the dispatch method, to change the current application state by dispatching an action, and; the subscribe method to subscribe to the changes and re-render our application with the current state of the app. The following declarations are the same: 1 2 3 const { createStore } = React import { createStore } from 'redux' var createStore = Redux . createStore Three Store Methods \u00b6 getState() dispatch() subscribe() getState() \u00b6 1 2 // getState console . log ( store . getState ()) dispatch() \u00b6 1 2 3 // dispatch store . dispatch ({ type : 'INCREMENT' }) console . log ( store . getState ()) subscribe() \u00b6 1 2 // subscribe store . subscribe ( render )","title":"Redux"},{"location":"react/redux/#redux","text":"","title":"Redux"},{"location":"react/redux/#three-principles-of-redux","text":"From the Egghead.io course of Dan Abramov: Application state is one single object no matter how big or small the application. State tree is immutable (read only). State changes can be added but not modified. State mutations are pure functions that take the previous state and the action being dispatched as its arguments, and returns the next state of the application. These functions are called reducers .","title":"Three Principles of Redux"},{"location":"react/redux/#redux-conventions","text":"If the reducer receives undefined as the state argument, it must return what it considers to be the initial state of the application.","title":"Redux conventions"},{"location":"react/redux/#the-store","text":"The store binds together the three principles of Redux . It holds the current application\u2019s state object. It lets you dispatch actions. When you create it, you need to specify the reducer that tells how state is updated with actions.","title":"The Store"},{"location":"react/redux/#createstore","text":"The createStore function from Redux and the store object it returns provide : the getState method to get the current application state; the dispatch method, to change the current application state by dispatching an action, and; the subscribe method to subscribe to the changes and re-render our application with the current state of the app. The following declarations are the same: 1 2 3 const { createStore } = React import { createStore } from 'redux' var createStore = Redux . createStore","title":"createStore()"},{"location":"react/redux/#three-store-methods","text":"getState() dispatch() subscribe()","title":"Three Store Methods"},{"location":"react/redux/#getstate","text":"1 2 // getState console . log ( store . getState ())","title":"getState()"},{"location":"react/redux/#dispatch","text":"1 2 3 // dispatch store . dispatch ({ type : 'INCREMENT' }) console . log ( store . getState ())","title":"dispatch()"},{"location":"react/redux/#subscribe","text":"1 2 // subscribe store . subscribe ( render )","title":"subscribe()"},{"location":"umbraco/faq/","text":"Frequently Asked Questions \u00b6 Bundling and minifying \u00b6 Most of the information comes from two articles: How to bundle CSS and JS and Bundling and minification in Umbraco . Added App_Start folder Created BundleConfig.cs class with bundles for JavaScript and CSS files Added BundleTable.EnableOptimizations = true; in BundleConfig.cs to be able to test bundling and minification. At the same time, added <compilation debug=\"true\" /> in <system.web> section of Web.config , <compilation debug=\"false\" /> in web.Release.config . Important EnableOptimizations takes precedence of compilation debug value. It is also important to make sure that bundles are included in the umbracoReservedPaths : 1 2 3 4 5 <appSettings> ... <add key= \"umbracoReservedPaths\" value= \"~/umbraco,~/install/,~/bundles/\" /> ... </appSettings> Web Deployment - Could not find part of the path \u00b6 Question \u00b6 Error during web deploy Could not open Source file: Could not find a part of the path \u2018J:\\U\\Ed4u\\Ed4u\\App_Plugins\\LeBlender\\Web.config;\\App_Plugins\\LeBlender\\Web.config\u2019. Answer \u00b6 Find the deployment profile energydiet4u.nl - Web Deploy.pubxml and add the following key to the PropertyGroup section: 1 <AutoParameterizationWebConfigConnectionStrings> False </AutoParameterizationWebConfigConnectionStrings> Web Deployment - Group policy prevents Roslyn\u2019s csc.exe from running \u00b6 Question \u00b6 Website runtime error after deployment to GoDaddy: Answer \u00b6 Since the .NET 4.5 version, Roslyn compilation is the default way of compiling. This means if you create any web application either Web Forms or MVC using .NET 4.5 you get this Roslyn csc.exe compilation pre-installed in your project. Uninstall Microsoft.CodeDOM.Providers.DotNetCompilerPlatform NuGet package, rebuild and redeploy the website Delete the corresponding .dll\u2019s from the bin directory NOTE This will be probably necessary to do every time Umbraco is upgraded.","title":"FAQ"},{"location":"umbraco/faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"umbraco/faq/#bundling-and-minifying","text":"Most of the information comes from two articles: How to bundle CSS and JS and Bundling and minification in Umbraco . Added App_Start folder Created BundleConfig.cs class with bundles for JavaScript and CSS files Added BundleTable.EnableOptimizations = true; in BundleConfig.cs to be able to test bundling and minification. At the same time, added <compilation debug=\"true\" /> in <system.web> section of Web.config , <compilation debug=\"false\" /> in web.Release.config . Important EnableOptimizations takes precedence of compilation debug value. It is also important to make sure that bundles are included in the umbracoReservedPaths : 1 2 3 4 5 <appSettings> ... <add key= \"umbracoReservedPaths\" value= \"~/umbraco,~/install/,~/bundles/\" /> ... </appSettings>","title":"Bundling and minifying"},{"location":"umbraco/faq/#web-deployment-could-not-find-part-of-the-path","text":"","title":"Web Deployment - Could not find part of the path"},{"location":"umbraco/faq/#question","text":"Error during web deploy Could not open Source file: Could not find a part of the path \u2018J:\\U\\Ed4u\\Ed4u\\App_Plugins\\LeBlender\\Web.config;\\App_Plugins\\LeBlender\\Web.config\u2019.","title":"Question"},{"location":"umbraco/faq/#answer","text":"Find the deployment profile energydiet4u.nl - Web Deploy.pubxml and add the following key to the PropertyGroup section: 1 <AutoParameterizationWebConfigConnectionStrings> False </AutoParameterizationWebConfigConnectionStrings>","title":"Answer"},{"location":"umbraco/faq/#web-deployment-group-policy-prevents-roslyns-cscexe-from-running","text":"","title":"Web Deployment - Group policy prevents Roslyn's csc.exe from running"},{"location":"umbraco/faq/#question_1","text":"Website runtime error after deployment to GoDaddy:","title":"Question"},{"location":"umbraco/faq/#answer_1","text":"Since the .NET 4.5 version, Roslyn compilation is the default way of compiling. This means if you create any web application either Web Forms or MVC using .NET 4.5 you get this Roslyn csc.exe compilation pre-installed in your project. Uninstall Microsoft.CodeDOM.Providers.DotNetCompilerPlatform NuGet package, rebuild and redeploy the website Delete the corresponding .dll\u2019s from the bin directory NOTE This will be probably necessary to do every time Umbraco is upgraded.","title":"Answer"},{"location":"umbraco/technicalities/","text":"Using SSL in Production \u00b6 (This is a tip of Sebastiaan Janssen at Our Umbraco .) Our aim is to use SSL in Production and to issue an automatic 301-redirect for any non-secure url within the domain. For example, mydomain.com => https://mydomain.com www.mydomain.com => https://www.mydomain.com In order to achieve this, several things have to be done. This is based on GoDaddy\u2019s hosting, so for SSL one needs to buy their GoDaddy does not specialize on Windows hosting Unfortunately, the Windows hosting support of GoDaddy ends up when the place there minimal index.html file in the root directory and can successfully view that page in the browser. Step 1 \u2013 Configure the Production web server \u00b6 Go to Websites & Domains and choose Web Server Settings . Check Require SSL checkbox to prevent non-secure access to the website. Don\u2019t forget to save the changes. Step 2 \u2013 Create the SSL Certificate \u00b6 GoDaddy offers a SHA-2 type SSL-certificate. You can also place the SSL Certificate security seal on your website that looks like this: GoDaddy provides the snippet for this. When you click on the seal, you see the confirmation: Step 3 \u2013 Add transformations to the Web.Release.config file \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 <configuration xmlns:xdt= \"http://schemas.microsoft.com/XML-Document-Transform\" > <appSettings> <add key= \"debugWebErrors\" value= \"false\" xdt:Transform= \"SetAttributes\" xdt:Locator= \"Match(key)\" /> </appSettings> <rewrite xdt:Transform= \"InsertAfter(/configuration/system.webServer/validation)\" > <rules> <rule name= \"Redirect to https\" stopProcessing= \"true\" > <match url= \"(.*)\" /> <conditions> <add input= \"{HTTPS}\" pattern= \"off\" ignoreCase= \"true\" /> </conditions> <action type= \"Redirect\" url= \"https://{HTTP_HOST}{REQUEST_URI}\" redirectType= \"Permanent\" appendQueryString= \"false\" /> </rule> </rules> </rewrite> </configuration> URL Rewriting plugin Note that the above rewrite only works if the URL Rewriting plugin for IIS has been installed on the server. You\u2019ll also need to update all your templates if they refer to (for example) fonts on a CDN, the easiest way to do that is to not give it the scheme (http or https). So instead of: 1 2 < link href = \"http://fonts.googleapis.com/css?family=Open+Sans:400,700\" type = \"text/css\" rel = \"stylesheet\" /> you can make: 1 2 < link href = \"//fonts.googleapis.com/css?family=Open+Sans:400,700\" type = \"text/css\" rel = \"stylesheet\" /> Notice that http: has been removed. This way it will load over both https and also over http (if you ever decide to revert to http). robots.txt \u00b6 install Cultiv DynamicRobots and Robots.txt Editor packages in the Umbraco backend. (I am not yet sure if this is a good option) intall the Cultiv SearchEngineSitemap package, which supports multisite solutions out of the box. open Developer section in the backend and you will see Robots.txt option. Click on it. Now, you can enter the code you need. Here is an example of such file for Umbraco projects: 1 2 3 4 5 6 7 8 9 10 11 # robots.txt for Umbraco User-agent: * Disallow: /bin/ Disallow: /config/ Disallow: /css/ Disallow: /data/ Disallow: /scripts/ Disallow: /umbraco/ Disallow: /umbraco_client/ Disallow: /usercontrols/ Sitemap: http://{HTTP_HOST}/sitemap The interesting part here is that the {HTTP_HOST} template parameter here is dynamically substituted for the right URL when the project is deployed. Deployment error Currently the Cultiv.DynamicRobots.dll file in the bin directory is not being copied by the deployment process and has to be separately copied later. Alternatively, you could also create robots.txt manually in the project root directory and make sure the link /robots.txt is redirected to /robotstxt in ~\\Config\\UrlRewriting.config . For details see this article: How to create a robots.txt in Umbraco and edit it from the backoffice","title":"Technicalities"},{"location":"umbraco/technicalities/#using-ssl-in-production","text":"(This is a tip of Sebastiaan Janssen at Our Umbraco .) Our aim is to use SSL in Production and to issue an automatic 301-redirect for any non-secure url within the domain. For example, mydomain.com => https://mydomain.com www.mydomain.com => https://www.mydomain.com In order to achieve this, several things have to be done. This is based on GoDaddy\u2019s hosting, so for SSL one needs to buy their GoDaddy does not specialize on Windows hosting Unfortunately, the Windows hosting support of GoDaddy ends up when the place there minimal index.html file in the root directory and can successfully view that page in the browser.","title":"Using SSL in Production"},{"location":"umbraco/technicalities/#step-1-configure-the-production-web-server","text":"Go to Websites & Domains and choose Web Server Settings . Check Require SSL checkbox to prevent non-secure access to the website. Don\u2019t forget to save the changes.","title":"Step 1 -- Configure the Production web server"},{"location":"umbraco/technicalities/#step-2-create-the-ssl-certificate","text":"GoDaddy offers a SHA-2 type SSL-certificate. You can also place the SSL Certificate security seal on your website that looks like this: GoDaddy provides the snippet for this. When you click on the seal, you see the confirmation:","title":"Step 2 -- Create the SSL Certificate"},{"location":"umbraco/technicalities/#step-3-add-transformations-to-the-webreleaseconfig-file","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 <configuration xmlns:xdt= \"http://schemas.microsoft.com/XML-Document-Transform\" > <appSettings> <add key= \"debugWebErrors\" value= \"false\" xdt:Transform= \"SetAttributes\" xdt:Locator= \"Match(key)\" /> </appSettings> <rewrite xdt:Transform= \"InsertAfter(/configuration/system.webServer/validation)\" > <rules> <rule name= \"Redirect to https\" stopProcessing= \"true\" > <match url= \"(.*)\" /> <conditions> <add input= \"{HTTPS}\" pattern= \"off\" ignoreCase= \"true\" /> </conditions> <action type= \"Redirect\" url= \"https://{HTTP_HOST}{REQUEST_URI}\" redirectType= \"Permanent\" appendQueryString= \"false\" /> </rule> </rules> </rewrite> </configuration> URL Rewriting plugin Note that the above rewrite only works if the URL Rewriting plugin for IIS has been installed on the server. You\u2019ll also need to update all your templates if they refer to (for example) fonts on a CDN, the easiest way to do that is to not give it the scheme (http or https). So instead of: 1 2 < link href = \"http://fonts.googleapis.com/css?family=Open+Sans:400,700\" type = \"text/css\" rel = \"stylesheet\" /> you can make: 1 2 < link href = \"//fonts.googleapis.com/css?family=Open+Sans:400,700\" type = \"text/css\" rel = \"stylesheet\" /> Notice that http: has been removed. This way it will load over both https and also over http (if you ever decide to revert to http).","title":"Step 3 -- Add transformations to the Web.Release.config file"},{"location":"umbraco/technicalities/#robotstxt","text":"install Cultiv DynamicRobots and Robots.txt Editor packages in the Umbraco backend. (I am not yet sure if this is a good option) intall the Cultiv SearchEngineSitemap package, which supports multisite solutions out of the box. open Developer section in the backend and you will see Robots.txt option. Click on it. Now, you can enter the code you need. Here is an example of such file for Umbraco projects: 1 2 3 4 5 6 7 8 9 10 11 # robots.txt for Umbraco User-agent: * Disallow: /bin/ Disallow: /config/ Disallow: /css/ Disallow: /data/ Disallow: /scripts/ Disallow: /umbraco/ Disallow: /umbraco_client/ Disallow: /usercontrols/ Sitemap: http://{HTTP_HOST}/sitemap The interesting part here is that the {HTTP_HOST} template parameter here is dynamically substituted for the right URL when the project is deployed. Deployment error Currently the Cultiv.DynamicRobots.dll file in the bin directory is not being copied by the deployment process and has to be separately copied later. Alternatively, you could also create robots.txt manually in the project root directory and make sure the link /robots.txt is redirected to /robotstxt in ~\\Config\\UrlRewriting.config . For details see this article: How to create a robots.txt in Umbraco and edit it from the backoffice","title":"robots.txt"},{"location":"vuejs/basics/","text":"Installation \u00b6 Start by installing yarn from yarn website . Quick and dirty \u00b6 1 2 3 4 5 6 yarn global add vue-cli vue init webpack-simple my-app cd my-app yarn install yarn upgrade yarn run dev Normal Development \u00b6 1 2 3 4 5 6 yarn global add vue-cli vue init webpack my-app cd my-app yarn install yarn upgrade yarn run dev When answering questions, choose standard installation (not airbnb) unless you like to fight with eslint and prefer to use semicolons everywhere. Avoid Vue.js DOM templates \u00b6 This advice comes from the Anthony Gore\u2019s article: Why You Should Avoid Vue.js DOM Templates . The issue he writes about is that Vue.js DOM templates are not reliable in that they don\u2019t always render the DOM code you expect. In Short \u00b6 DOM templates are problematic as the DOM parser can mess with your markup. There\u2019s also a potential for clashes with templating engines and incompatibility with server-side rendering. To minimize your DOM template, abstract your markup into components. To completely eliminate your DOM template you\u2019ll need to mount your root-level component with a render function. So, how can you architect a Vue.js app without a DOM template, or at least a small one? Abstract markup to components \u00b6 Your root instance can hold some state, but generally, you want any presentational logic and markup to be abstracted to components so it\u2019s out of your DOM template. Single-file components are the superior choice. If you\u2019re unable to include a build step in your project and don\u2019t like writing your templates as JavaScript strings (who does), you can try x-templates . x-templates \u00b6 With x-templates , your template is still defined in the page, but within a script tag, and will, therefore, avoid processing by the DOM parser. The script tag is marked with text/x-template and referenced by an id in your component definition. 1 2 3 4 5 6 7 Vue . component ( 'my-component' , { template : '#my-component' } < script type = \"text/x-template\" id = \"my-component\" > < div > My component template < /div> < NonStandardMarkupIsFineHere /> < /script> Mount to an empty node with a render function \u00b6 Abstracting markup into components hits a wall when you realize you still need to declare your root-level component in the DOM template. 1 2 3 4 < div id = \"app\" > <!-- We still have a DOM template : ( --> < app >< /app> < /div> If you want to totally eliminate your DOM template, you can mount your root-level component(s) with a render function. Let\u2019s say you have one all-encompassing component that declares the other components called App . App can be declared with a render function and mounted to an empty node since render functions will replace their mount element. Autogenerated by vue-cli : 1 2 3 4 5 6 7 < div id = \"app\" >< /div> new Vue ({ el : '#app' , template : '<App/>' , components : { App } }) Replace with: 1 2 3 4 5 6 7 < div id = \"app\" >< /div> new Vue ({ el : '#app' , components : { App }, render : ( createElement ) => createElement ( App ) }) And with that, your app is free of any DOM templates! If you can eliminate all string and DOM templates from your app you can use the smaller runtime-only build of Vue. This is an ideal project architecture and is the one you\u2019ll see used in vue-cli templates.","title":"Vue.js Basics"},{"location":"vuejs/basics/#installation","text":"Start by installing yarn from yarn website .","title":"Installation"},{"location":"vuejs/basics/#quick-and-dirty","text":"1 2 3 4 5 6 yarn global add vue-cli vue init webpack-simple my-app cd my-app yarn install yarn upgrade yarn run dev","title":"Quick and dirty"},{"location":"vuejs/basics/#normal-development","text":"1 2 3 4 5 6 yarn global add vue-cli vue init webpack my-app cd my-app yarn install yarn upgrade yarn run dev When answering questions, choose standard installation (not airbnb) unless you like to fight with eslint and prefer to use semicolons everywhere.","title":"Normal Development"},{"location":"vuejs/basics/#avoid-vuejs-dom-templates","text":"This advice comes from the Anthony Gore\u2019s article: Why You Should Avoid Vue.js DOM Templates . The issue he writes about is that Vue.js DOM templates are not reliable in that they don\u2019t always render the DOM code you expect.","title":"Avoid Vue.js DOM templates"},{"location":"vuejs/basics/#in-short","text":"DOM templates are problematic as the DOM parser can mess with your markup. There\u2019s also a potential for clashes with templating engines and incompatibility with server-side rendering. To minimize your DOM template, abstract your markup into components. To completely eliminate your DOM template you\u2019ll need to mount your root-level component with a render function. So, how can you architect a Vue.js app without a DOM template, or at least a small one?","title":"In Short"},{"location":"vuejs/basics/#abstract-markup-to-components","text":"Your root instance can hold some state, but generally, you want any presentational logic and markup to be abstracted to components so it\u2019s out of your DOM template. Single-file components are the superior choice. If you\u2019re unable to include a build step in your project and don\u2019t like writing your templates as JavaScript strings (who does), you can try x-templates .","title":"Abstract markup to components"},{"location":"vuejs/basics/#x-templates","text":"With x-templates , your template is still defined in the page, but within a script tag, and will, therefore, avoid processing by the DOM parser. The script tag is marked with text/x-template and referenced by an id in your component definition. 1 2 3 4 5 6 7 Vue . component ( 'my-component' , { template : '#my-component' } < script type = \"text/x-template\" id = \"my-component\" > < div > My component template < /div> < NonStandardMarkupIsFineHere /> < /script>","title":"x-templates"},{"location":"vuejs/basics/#mount-to-an-empty-node-with-a-render-function","text":"Abstracting markup into components hits a wall when you realize you still need to declare your root-level component in the DOM template. 1 2 3 4 < div id = \"app\" > <!-- We still have a DOM template : ( --> < app >< /app> < /div> If you want to totally eliminate your DOM template, you can mount your root-level component(s) with a render function. Let\u2019s say you have one all-encompassing component that declares the other components called App . App can be declared with a render function and mounted to an empty node since render functions will replace their mount element. Autogenerated by vue-cli : 1 2 3 4 5 6 7 < div id = \"app\" >< /div> new Vue ({ el : '#app' , template : '<App/>' , components : { App } }) Replace with: 1 2 3 4 5 6 7 < div id = \"app\" >< /div> new Vue ({ el : '#app' , components : { App }, render : ( createElement ) => createElement ( App ) }) And with that, your app is free of any DOM templates! If you can eliminate all string and DOM templates from your app you can use the smaller runtime-only build of Vue. This is an ideal project architecture and is the one you\u2019ll see used in vue-cli templates.","title":"Mount to an empty node with a render function"},{"location":"webpack/basics/","text":"Webpack Basics \u00b6 Webpack 4 The notes hereunder are based on the latest (at the moment of writing) version 4 of Webpack. Webpack Architecture 101 \u00b6 Webpack is based on the Tapable Module . Here is a concise Webpack workflow description: the Compiler reads options and creates the Compilation the Compilation reads the entry property , and sends it through the Normal Module Factory (NMF) to the Resolver to find out if the file exists if it exists, the Resolver creates a Module Object from it with the source inside if some module is not in JavaScript , e.g. CSS, HTML, etc., the Loaders will transpile it into JavaScript then it goes through the Parser that converts it into an Abstract Syntax Tree (AST) to find all require s and import s, in other words all dependencies this process is recursively repeated for every dependency Taken from the Everything is a plugin! Mastering webpack from the inside out presentation by Sean Larkin at ng-conf 2017 in Salt Lake City (UT) More information can be found in the Concepts section of the Webpack documentation. In the Single Page Applications with Vue.js PluralSight course, Bill Stavroulakis shows step by step how to add webpack and build it out together with the Vue.js solution. To Build or Not to Build \u00b6 Webpack is often used with two separate configuations: one for Development and another one for Production . Mostly we use the Development mode to code our project and Production when we want to prepare files for the real deployment. There is, however, a subtle difference between these two modes if one wants to create a separate CSS file with all the styles. The difference is as follows: Out of the box, loading of the CSS bundle in Development mode does not work because Webpack treats the file as a MIME type text/html and not text/css What happens is that the Webpack loaders normally transpile everything into JavaScript. And all the resources are kept in RAM to speed up recompilations and DOM refreshment. As long as the CSS is transpiled, everything works fine. That is mostly what happens in the Development mode. However, if we force Webpack to create a separate CSS bundle using plugins like mini-css-extract-plugin or extract-text-webpack-plugin , and try to run that in Development mode, we will notice that styles are not loaded and the following error in the console: 1 Refused to apply style from `http://localhost:3000/style.css` because its MIME type (`text/html`) is not a supported stylesheet MIME type, and strict MIME checking is enabled. However, if we CD to our dist folder and run a dedicated Nodejs server like http-server or serve , the website will be loaded and the styles will be applied. This may also mean that we need to use two separate index.html files. One inside the src folder for Development, which does not create a separate CSS bundle. Another one in the public folder for Production, which load the separately created CSS bundle. In the later case, we also need to specify the public folder in the html-webpack-plugin configuration. 1 2 3 4 5 6 7 8 9 plugins : [ new HtmlWebpackPlugin ({ template : 'public/index.html' , favicon : 'public/favicon.ico' , inject : false , hash : true , }), ... ] Performance The overal time-to-load when building a separate CSS bundle is much longer than when not doing that.","title":"Webpack Basics"},{"location":"webpack/basics/#webpack-basics","text":"Webpack 4 The notes hereunder are based on the latest (at the moment of writing) version 4 of Webpack.","title":"Webpack Basics"},{"location":"webpack/basics/#webpack-architecture-101","text":"Webpack is based on the Tapable Module . Here is a concise Webpack workflow description: the Compiler reads options and creates the Compilation the Compilation reads the entry property , and sends it through the Normal Module Factory (NMF) to the Resolver to find out if the file exists if it exists, the Resolver creates a Module Object from it with the source inside if some module is not in JavaScript , e.g. CSS, HTML, etc., the Loaders will transpile it into JavaScript then it goes through the Parser that converts it into an Abstract Syntax Tree (AST) to find all require s and import s, in other words all dependencies this process is recursively repeated for every dependency Taken from the Everything is a plugin! Mastering webpack from the inside out presentation by Sean Larkin at ng-conf 2017 in Salt Lake City (UT) More information can be found in the Concepts section of the Webpack documentation. In the Single Page Applications with Vue.js PluralSight course, Bill Stavroulakis shows step by step how to add webpack and build it out together with the Vue.js solution.","title":"Webpack Architecture 101"},{"location":"webpack/basics/#to-build-or-not-to-build","text":"Webpack is often used with two separate configuations: one for Development and another one for Production . Mostly we use the Development mode to code our project and Production when we want to prepare files for the real deployment. There is, however, a subtle difference between these two modes if one wants to create a separate CSS file with all the styles. The difference is as follows: Out of the box, loading of the CSS bundle in Development mode does not work because Webpack treats the file as a MIME type text/html and not text/css What happens is that the Webpack loaders normally transpile everything into JavaScript. And all the resources are kept in RAM to speed up recompilations and DOM refreshment. As long as the CSS is transpiled, everything works fine. That is mostly what happens in the Development mode. However, if we force Webpack to create a separate CSS bundle using plugins like mini-css-extract-plugin or extract-text-webpack-plugin , and try to run that in Development mode, we will notice that styles are not loaded and the following error in the console: 1 Refused to apply style from `http://localhost:3000/style.css` because its MIME type (`text/html`) is not a supported stylesheet MIME type, and strict MIME checking is enabled. However, if we CD to our dist folder and run a dedicated Nodejs server like http-server or serve , the website will be loaded and the styles will be applied. This may also mean that we need to use two separate index.html files. One inside the src folder for Development, which does not create a separate CSS bundle. Another one in the public folder for Production, which load the separately created CSS bundle. In the later case, we also need to specify the public folder in the html-webpack-plugin configuration. 1 2 3 4 5 6 7 8 9 plugins : [ new HtmlWebpackPlugin ({ template : 'public/index.html' , favicon : 'public/favicon.ico' , inject : false , hash : true , }), ... ] Performance The overal time-to-load when building a separate CSS bundle is much longer than when not doing that.","title":"To Build or Not to Build"}]}